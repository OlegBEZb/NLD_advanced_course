{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"NLP advance course. HW3. Distributive semantic. Embeddings + sklearn models.ipynb","provenance":[],"collapsed_sections":["fSb8_JgExgM7","UVw8QpbSxvYR"],"toc_visible":true,"machine_shape":"hm"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KVRaU_zG-PaI","colab_type":"text"},"source":["## Embeddings to check\n","\n","* Word Embeddings (word2vec, GloVe, etc.)\n","* Starspace and other similarity learning embeddings\n","* char-gram embeddings (bpemb, fasttext etc.)\n","* doc and sentence embeddings (doc2vec, sent2vec etc.)\n","* specific context models (BERT, ELMo)\n","* Advanced: Poincare Embeddings concept"]},{"cell_type":"markdown","metadata":{"id":"30D0Scxk4kn3","colab_type":"text"},"source":["# Libs import"]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"ZnXUdrxQ3TAN","colab_type":"code","outputId":"0d487636-811d-4aaa-dca0-761db0f19fef","executionInfo":{"status":"ok","timestamp":1577357296068,"user_tz":-180,"elapsed":34145,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["%autosave 180\n","%load_ext autoreload\n","%autoreload 2\n","\n","import os, math, operator, csv, random, pickle, re, sys\n","import tensorflow as tf\n","from tqdm import tqdm\n","import pandas as pd\n","import gc\n","from collections import Counter\n","\n","import keras\n","from keras.models import Model\n","from keras.layers import MaxPooling1D, BatchNormalization, Permute, Lambda, \\\n","Activation, Conv1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, \\\n","Embedding, Dropout, Input, CuDNNGRU, merge, CuDNNLSTM, Flatten, \\\n","TimeDistributed, concatenate, SpatialDropout1D, Bidirectional\n","from nltk.util import pad_sequence\n","from keras.preprocessing.sequence import pad_sequences\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import gc\n","from keras import backend as K\n","\n","import nltk\n","nltk.download('stopwords');\n","from nltk.tokenize import TweetTokenizer\n","\n","from nltk.corpus import stopwords\n","\n","! pip install Unidecode;\n","from unidecode import unidecode\n","#! pip install pyspellchecker;\n","#from spellchecker import SpellChecker\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import KFold, train_test_split, cross_val_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from keras import backend as K\n","\n","# from spacy.symbols import nsubj, VERB, dobj\n","# import spacy\n","# nlp = spacy.load('en')\n","\n","! pip install embeddings;\n","from embeddings import GloveEmbedding, FastTextEmbedding\n","\n","import numpy as np\n","import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import Model\n","from keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n","from keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, CuDNNGRU, Conv1D\n","from keras.preprocessing import text\n","from keras.callbacks import LearningRateScheduler, Callback\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n","Requirement already satisfied: embeddings in /usr/local/lib/python3.6/dist-packages (0.0.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from embeddings) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from embeddings) (1.17.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from embeddings) (2.21.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->embeddings) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->embeddings) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->embeddings) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->embeddings) (2019.11.28)\n","1.15.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i673BlTJEazT","colab_type":"text"},"source":["# Global vars"]},{"cell_type":"code","metadata":{"id":"okymGz_lEjLC","colab_type":"code","colab":{}},"source":["COLAB = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VD2z8D2V7Dod","colab_type":"text"},"source":["# Authorization on Google drive (if needed) and configurings paths"]},{"cell_type":"code","metadata":{"id":"auzLnrdK51Rg","colab_type":"code","outputId":"7c49dd4b-a844-47c0-a65f-9ac23b36dd85","executionInfo":{"status":"ok","timestamp":1577357296070,"user_tz":-180,"elapsed":30926,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["if COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    data_folder = '/content/drive/My Drive/Advanced NLP/Homework 1: Classical classification task like Kaggle Toxic or Quora/Toxic data'\n","    embeddings_folder = '/content/drive/My Drive/Advanced NLP/Homework 1: Classical classification task like Kaggle Toxic or Quora'\n","    print('data found:', os.listdir(data_folder))\n","else:\n","    data_folder = '../input/jigsaw-toxic-comment-classification-challenge/'\n","    embeddings_folder = '../input/glove-global-vectors-for-word-representation'\n","    print('data found:', os.listdir(data_folder))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","data found: ['test.csv', 'test_labels.csv', 'train.csv', 'sample_submission.csv', 'submission.csv', 'submission_bidirectional_GRU.csv', 'submission_emb_sklearn.csv']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"UYdAXsdT3TAd","colab_type":"code","colab":{}},"source":["#pretrained_folder = \"../input/\"\n","train_filepath = os.path.join(data_folder,\"train.csv\")\n","test_filepath = os.path.join(data_folder,\"test.csv\")\n","test_labels_filepath = os.path.join(data_folder,\"test_labels.csv\")\n","\n","#path to a submission\n","submission_path = os.path.join(data_folder,\"sample_submission.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15GVrJYa717o","colab_type":"text"},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"jYljyuKTCm8r","colab_type":"text"},"source":["## Dicts and lists of useful words and transformations"]},{"cell_type":"code","metadata":{"id":"YjL5O731CtDD","colab_type":"code","colab":{}},"source":["#List of some words that often appear in toxic comments\n","#Sorry about the level of toxicity in it!\n","toxic_words = [\"poop\", \"crap\", \"prick\", \"twat\", \"wikipedia\", \"wiki\", \"hahahahaha\", \"lol\", \"bastard\", \"sluts\", \"slut\", \"douchebag\", \"douche\", \"blowjob\", \"nigga\", \"dumb\", \"jerk\", \"wanker\", \"wank\", \"penis\", \"motherfucker\", \"fucker\", \"fuk\", \"fucking\", \"fucked\", \"fuck\", \"bullshit\", \"shit\", \"stupid\", \"bitches\", \"bitch\", \"suck\", \"cunt\", \"dick\", \"cocks\", \"cock\", \"die\", \"kill\", \"gay\", \"jewish\", \"jews\", \"jew\", \"niggers\", \"nigger\", \"faggot\", \"fag\", \"asshole\"]\n","astericks_words = [('mother****ers', 'motherfuckers'), ('motherf*cking', 'motherfucking'), ('mother****er', 'motherfucker'), ('motherf*cker', 'motherfucker'), ('bullsh*t', 'bullshit'), ('f**cking', 'fucking'), ('f*ucking', 'fucking'), ('fu*cking', 'fucking'), ('****ing', 'fucking'), ('a**hole', 'asshole'), ('assh*le', 'asshole'), ('f******', 'fucking'), ('f*****g', 'fucking'), ('f***ing', 'fucking'), ('f**king', 'fucking'), ('f*cking', 'fucking'), ('fu**ing', 'fucking'), ('fu*king', 'fucking'), ('fuc*ers', 'fuckers'), ('f*****', 'fucking'), ('f***ed', 'fucked'), ('f**ker', 'fucker'), ('f*cked', 'fucked'), ('f*cker', 'fucker'), ('f*ckin', 'fucking'), ('fu*ker', 'fucker'), ('fuc**n', 'fucking'), ('ni**as', 'niggas'), ('b**ch', 'bitch'), ('b*tch', 'bitch'), ('c*unt', 'cunt'), ('f**ks', 'fucks'), ('f*ing', 'fucking'), ('ni**a', 'nigga'), ('c*ck', 'cock'), ('c*nt', 'cunt'), ('cr*p', 'crap'), ('d*ck', 'dick'), ('f***', 'fuck'), ('f**k', 'fuck'), ('f*ck', 'fuck'), ('fc*k', 'fuck'), ('fu**', 'fuck'), ('fu*k', 'fuck'), ('s***', 'shit'), ('s**t', 'shit'), ('sh**', 'shit'), ('sh*t', 'shit'), ('tw*t', 'twat')]\n","fasttext_misspelings = {\"'n'balls\": 'balls', \"-nazi's\": 'nazis', 'adminabuse': 'admin abuse', \"admins's\": 'admins', 'arsewipe': 'arse wipe', 'assfack': 'asshole', 'assholifity': 'asshole', 'assholivity': 'asshole', 'asshoul': 'asshole', 'asssholeee': 'asshole', 'belizeans': 'mexicans', \"blowing's\": 'blowing', 'bolivians': 'mexicans', 'celtofascists': 'fascists', 'censorshipmeisters': 'censor', 'chileans': 'mexicans', 'clerofascist': 'fascist', 'cowcrap': 'crap', 'crapity': 'crap', \"d'idiots\": 'idiots', 'deminazi': 'nazi', 'dftt': \"don't feed the troll\", 'dildohs': 'dildo', 'dramawhores': 'drama whores', 'edophiles': 'pedophiles', 'eurocommunist': 'communist', 'faggotkike': 'faggot', 'fantard': 'retard', 'fascismnazism': 'fascism', 'fascistisized': 'fascist', 'favremother': 'mother', 'fuxxxin': 'fucking', \"g'damn\": 'goddamn', 'harassmentat': 'harassment', 'harrasingme': 'harassing me', 'herfuc': 'motherfucker', 'hilterism': 'fascism', 'hitlerians': 'nazis', 'hitlerites': 'nazis', 'hubrises': 'pricks', 'idiotizing': 'idiotic', 'inadvandals': 'vandals', \"jackass's\": 'jackass', 'jiggabo': 'nigga', 'jizzballs': 'jizz balls', 'jmbass': 'dumbass', 'lejittament': 'legitimate', \"m'igger\": 'nigger', \"m'iggers\": 'niggers', 'motherfacking': 'motherfucker', 'motherfuckenkiwi': 'motherfucker', 'muthafuggas': 'niggas', 'nazisms': 'nazis', 'netsnipenigger': 'nigger', 'niggercock': 'nigger', 'niggerspic': 'nigger', 'nignog': 'nigga', 'niqqass': 'niggas', \"non-nazi's\": 'not a nazi', 'panamanians': 'mexicans', 'pedidiots': 'idiots', 'picohitlers': 'hitler', 'pidiots': 'idiots', 'poopia': 'poop', 'poopsies': 'poop', 'presumingly': 'obviously', 'propagandaanddisinformation': 'propaganda and disinformation', 'propagandaministerium': 'propaganda', 'puertoricans': 'mexicans', 'puertorricans': 'mexicans', 'pussiest': 'pussies', 'pussyitis': 'pussy', 'rayaridiculous': 'ridiculous', 'redfascists': 'fascists', 'retardzzzuuufff': 'retard', \"revertin'im\": 'reverting', 'scumstreona': 'scums', 'southamericans': 'mexicans', 'strasserism': 'fascism', 'stuptarded': 'retarded', \"t'nonsense\": 'nonsense', \"threatt's\": 'threat', 'titoists': 'communists', 'twatbags': 'douchebags', 'youbollocks': 'you bollocks'}\n","acronym_words = {\"btw\":\"by the way\", \"yo\": \"you\", \"u\": \"you\", \"r\": \"are\", \"ur\": \"your\", \"ima\": \"i am going to\", \"imma\": \"i am going to\", \"i'ma\":\"i am going to\", \"cos\":\"because\", \"coz\":\"because\", \"stfu\": \"shut the fuck up\", \"wat\": \"what\"}\n","CHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—'\n","\n","english_stopwords = set(stopwords.words('english'))\n","\n","#spell_checker = SpellChecker()\n","\n","cont_patterns = [\n","    (r'(W|w)on\\'t', r'will not'),\n","    (r'(C|c)an\\'t', r'can not'),\n","    (r'(I|i)\\'m', r'i am'),\n","    (r'(A|a)in\\'t', r'is not'),\n","    (r'(\\w+)\\'ll', r'\\g<1> will'),\n","    (r'(\\w+)n\\'t', r'\\g<1> not'),\n","    (r'(\\w+)\\'ve', r'\\g<1> have'),\n","    (r'(\\w+)\\'s', r'\\g<1> is'),\n","    (r'(\\w+)\\'re', r'\\g<1> are'),\n","    (r'(\\w+)\\'d', r'\\g<1> would'),\n","]\n","patterns = [(re.compile(regex), repl) for (regex, repl) in cont_patterns]\n","\n","#We will filter all characters except alphabet characters and some punctuation\n","valid_characters = \" \" + \"@$\" + \"'!?-\" + \"abcdefghijklmnopqrstuvwxyz\" + \"abcdefghijklmnopqrstuvwxyz\".upper()\n","valid_set = set(x for x in valid_characters)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cs_nlu1iILY1","colab_type":"text"},"source":["## Funcs for processing"]},{"cell_type":"code","metadata":{"id":"GfUaIP-wIKTZ","colab_type":"code","colab":{}},"source":["def replace_url(word):\n","    if \"http://\" in word or \"www.\" in word or \"https://\" in word or \"wikipedia.org\" in word:\n","        return \"\"\n","    return word\n","\n","\n","def word_tokenize(sentence, tokenizer):\n","    sentence = sentence.replace(\"$\", \"s\")\n","    sentence = sentence.replace(\"@\", \"a\")    \n","    sentence = sentence.replace(\"!\", \" ! \")\n","    sentence = sentence.replace(\"?\", \" ? \")\n","\n","    return tokenizer.tokenize(sentence)\n","\n","\n","def split_toxic_and_normal_parts(word, toxic_words):\n","    if word == \"\":\n","        return \"\"\n","    \n","    lower = word.lower()\n","    for toxic_word in toxic_words:\n","        start = lower.find(toxic_word)\n","        if start >= 0:\n","            end = start + len(toxic_word)\n","            result = \" \".join([word[0:start], word[start:end], split_toxic_and_normal_parts(word[end:], toxic_words)])\n","            return result.replace(\"  \", \" \").strip()\n","    return word\n","\n","\n","def normalize_by_dictionary(normalized_word, dictionary):\n","    result = []\n","    for word in normalized_word.split():\n","        if word == word.upper():\n","            if word.lower() in dictionary:\n","                result.append(dictionary[word.lower()].upper())\n","            else:\n","                result.append(word)\n","        else:\n","            if word.lower() in dictionary:\n","                result.append(dictionary[word.lower()])\n","            else:\n","                result.append(word)\n","    \n","    return \" \".join(result)\n","\n","\n","def normalize_comment(comment, tokenizer, max_comment_length):\n","    comment = unidecode(comment)\n","    comment = comment[:max_comment_length]\n","\n","    normalized_words = []\n","    \n","    # ('mother****ers', 'motherfuckers')\n","    # for w in astericks_words:\n","    #     if w[0] in comment:\n","    #         comment = comment.replace(w[0], w[1])\n","    #     if w[0].upper() in comment:\n","    #         comment = comment.replace(w[0].upper(), w[1].upper())\n","    \n","    for word in word_tokenize(comment, tokenizer):\n","        if word in english_stopwords: continue\n","\n","        # # '(W|w)on\\'t', r'will not'\n","        # for (pattern, repl) in patterns:\n","        #    word = re.sub(pattern, repl, word)\n","\n","        if word == \".\" or word == \",\":\n","            normalized_words.append(word)\n","            continue\n","        \n","        # drop url parts from links\n","        # word = replace_url(word)\n","\n","        # replace single dots to whitespaces\n","        if word.count(\".\") == 1:\n","            word = word.replace(\".\", \" \")\n","\n","        # leave only legalized symbols\n","        filtered_word = \"\".join([x for x in word if x in valid_set])\n","                    \n","        #Kind of hack: for every word check if it has a toxic word as a part of it\n","        #If so, split this word by swear and non-swear part.\n","        #normalized_word = split_toxic_and_normal_parts(filtered_word, toxic_words)\n","        normalized_word = filtered_word\n","\n","#         normalized_word = normalize_by_dictionary(normalized_word, hyphens_dict)\n","#         normalized_word = normalize_by_dictionary(normalized_word, merged_dict)\n","        \n","        # check misspellings\n","        # temp = []\n","        # for word in normalized_word.split():\n","        #   temp.append(spell_checker.correction(word))\n","        # normalized_word = \" \".join(temp)\n","          \n","        # normalized_word = normalize_by_dictionary(normalized_word, fasttext_misspelings)\n","        normalized_word = normalize_by_dictionary(normalized_word, acronym_words)\n","\n","        normalized_words.append(normalized_word)\n","        \n","    normalized_comment = \" \".join(normalized_words)\n","    \n","    result = []\n","    for word in normalized_comment.split():\n","        # if word is upper\n","        if word.upper() == word:\n","            result.append(word)\n","        else:\n","            result.append(word.lower())\n","    \n","    #apparently, people on wikipedia love to talk about sockpuppets :-)\n","    result = \" \".join(result)\n","    if \"sock puppet\" in result:\n","        result = result.replace(\"sock puppet\", \"sockpuppet\")\n","    \n","    if \"SOCK PUPPET\" in result:\n","        result = result.replace(\"SOCK PUPPET\", \"SOCKPUPPET\")\n","    \n","    return result\n","\n","\n","def preprocess_text(df, preprocessing_func, tokenizer, max_comment_length):\n","  text_ndarray = df.fillna('_na').values\n","  np_preprocessing_func = np.vectorize(preprocessing_func)\n","\n","  preprocessed_text = np_preprocessing_func(text_ndarray, tokenizer, max_comment_length)\n","\n","  print('Gained shape:', preprocessed_text.shape)\n","  return preprocessed_text\n","\n","\n","def tokenize_and_pad(text, tokenizer):\n","\n","  tokenized_text = tokenizer.texts_to_sequences(text)\n","  padded_text = pad_sequences(tokenized_text, maxlen=MAX_LEN, dtype='int', value=0)\n","\n","  print('Gained shape:', padded_text.shape)\n","  return padded_text"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tn1-XTZEIZ3y","colab_type":"text"},"source":["## Loading frames and processing them"]},{"cell_type":"code","metadata":{"id":"1AWRdxZsHG3B","colab_type":"code","colab":{}},"source":["TEXT_COLUMN = 'comment_text'\n","TARGET_COLS = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n","\n","MAX_LEN = 220\n","max_tokens = 20000\n","max_comment_length = 20000 #We are going to truncate a comment if its length > threshold"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BAe8xpV48CO1","colab_type":"code","outputId":"a1ca4226-c678-461a-ec18-c2d03ad08039","executionInfo":{"status":"ok","timestamp":1577357305189,"user_tz":-180,"elapsed":1900,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%%time\n","\n","train_df = pd.read_csv(train_filepath)\n","train_labels = train_df[TARGET_COLS].values"],"execution_count":11,"outputs":[{"output_type":"stream","text":["CPU times: user 701 ms, sys: 207 ms, total: 908 ms\n","Wall time: 1.04 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dxwo5A8VfRRL","colab_type":"code","outputId":"f12f84e2-7107-4c76-93bc-57193013f1fc","executionInfo":{"status":"ok","timestamp":1577357371055,"user_tz":-180,"elapsed":64439,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["%%time\n","\n","tknzr = TweetTokenizer(strip_handles=False, reduce_len=True)\n","\n","preprocessed_train = preprocess_text(train_df[TEXT_COLUMN], \n","                                     normalize_comment, \n","                                     tknzr,\n","                                     max_comment_length)\n","#preprocessed_train = train_df[TEXT_COLUMN].fillna(\"CVxTz\").values\n","print(preprocessed_train[:3])\n","\n","#del train_df, tknzr"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Gained shape: (159571,)\n","[\"explanation why edits made username hardcore metallica fan reverted ? they vandalisms , closure gas I voted new york dolls FAC . and please remove template talk page since i'm retired . .\"\n"," \"d'aww ! he matches background colour i'm seemingly stuck . thanks . talk , january , UTC\"\n"," \"hey man , i'm really trying edit war . it's guy constantly removing relevant information talking edits instead talk page . he seems care formatting actual info .\"]\n","CPU times: user 1min, sys: 2.92 s, total: 1min 3s\n","Wall time: 1min 3s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Waa0TI1tqpPt","colab_type":"code","outputId":"978edd2a-219d-4078-e251-05e9b036f98f","executionInfo":{"status":"ok","timestamp":1577356820494,"user_tz":-180,"elapsed":88601,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["%%time\n","\n","tokenizer = Tokenizer(num_words=max_tokens)\n","tokenizer.fit_on_texts(list(preprocessed_train))\n","\n","tokenized_train = tokenize_and_pad(preprocessed_train, tokenizer)\n","# list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n","# list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n","\n","#del preprocessed_train"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Gained shape: (159571, 220)\n","CPU times: user 22.5 s, sys: 289 ms, total: 22.8 s\n","Wall time: 22.7 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A_vBvRFjD1QH","colab_type":"code","outputId":"6fd7679d-1768-4701-bae6-8630259fbe9e","executionInfo":{"status":"ok","timestamp":1577357429109,"user_tz":-180,"elapsed":113214,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["%%time\n","\n","test_df = pd.read_csv(test_filepath)\n","\n","preprocessed_test = preprocess_text(test_df[TEXT_COLUMN], \n","                                    normalize_comment, \n","                                    tknzr,\n","                                    max_comment_length)\n","# preprocessed_test = test_df[TEXT_COLUMN].fillna(\"CVxTz\").values"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Gained shape: (153164,)\n","CPU times: user 55.2 s, sys: 2.71 s, total: 57.9 s\n","Wall time: 57.9 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"47_scMa5zBtR","colab_type":"code","outputId":"99cda786-ec30-4bbc-9ea1-577223c660c0","executionInfo":{"status":"ok","timestamp":1577356890984,"user_tz":-180,"elapsed":157205,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["tokenized_test = tokenize_and_pad(preprocessed_test, tokenizer)\n","\n","#del preprocessed_test\n","gc.collect()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Gained shape: (153164, 220)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"n8APgvUyskaf","colab_type":"text"},"source":["# Training model"]},{"cell_type":"markdown","metadata":{"id":"wCRY8qnNJTh_","colab_type":"text"},"source":["## Preparing features"]},{"cell_type":"code","metadata":{"id":"jSAJK0AYsdW2","colab_type":"code","outputId":"5f63f082-23ad-47b0-a46d-8a5d9eab6001","executionInfo":{"status":"ok","timestamp":1577268836977,"user_tz":-180,"elapsed":149319,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# embedding_len = 50\n","\n","# word_index = tokenizer.word_index\n","# print('Found %s unique tokens.' %len(word_index))\n","\n","# del tokenizer\n","# gc.collect()\n","\n","# num_words = min(max_tokens, len(word_index) + 1)\n","# embedding_matrix = np.zeros((num_words, embedding_len)) # zeroth row for UNK"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 184924 unique tokens.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fSb8_JgExgM7","colab_type":"text"},"source":["## GloVe"]},{"cell_type":"code","metadata":{"id":"xys_jQL_tOnx","colab_type":"code","outputId":"001a7323-1e5a-48ab-8ff2-b42a6a0cc25d","executionInfo":{"status":"ok","timestamp":1576679007130,"user_tz":-180,"elapsed":352408,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# embedding_len = 200\n","# words = pd.read_csv(os.path.join(embeddings_folder, \"glove.twitter.27B.{}d.txt\".format(embedding_len)), \n","#                     sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n","\n","# embedding_len = 300\n","# words = pd.read_csv(os.path.join(embeddings_folder, \"glove.840B.300d.txt\"), \n","#                     sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n","\n","\n","# vocab_words = words[words.index.isin(list(word_index.keys()))]\n","# print('vocab_words.shape', vocab_words.shape)\n","\n","# del words\n","# gc.collect()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["vocab_words.shape (98533, 300)\n","CPU times: user 2min 7s, sys: 25 s, total: 2min 32s\n","Wall time: 2min 58s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v64775F2tVj2","colab_type":"code","outputId":"ded77e7b-6154-45be-9f2e-378f65c26ed0","executionInfo":{"status":"ok","timestamp":1576679009853,"user_tz":-180,"elapsed":355120,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# def get_vec(word, words_df):\n","#     return words_df.loc[word].values\n","\n","\n","\n","# for word, i in word_index.items():\n","#   if i >= max_tokens:\n","#     continue\n","#   try:\n","#     embedding_vector = get_vec(word, vocab_words)\n","#   except:\n","#     continue\n","#   if embedding_vector is not None:\n","#     # words not found in embedding index will be all-zeros.\n","#     embedding_matrix[i] = embedding_vector\n","\n","# # %%time\n","# # embedding_matrix = np.load('../input/embedding-2/embedding_matrix_big.npy')\n","    \n","# print('embedding_matrix.shape', embedding_matrix.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["embedding_matrix.shape (20000, 300)\n","CPU times: user 2.69 s, sys: 18.9 ms, total: 2.71 s\n","Wall time: 2.71 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UQn8sI55-DOL","colab_type":"code","colab":{}},"source":["# %%time\n","\n","# def document_vector(doc, embedding_matrix=embedding_matrix):\n","#     \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n","#     doc = [embedding_matrix[index] for index in doc]\n","#     return np.mean(doc, axis=0)\n","\n","\n","# train_features = np.apply_along_axis(document_vector, 1, tokenized_train)\n","# test_features = np.apply_along_axis(document_vector, 1, tokenized_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UVw8QpbSxvYR","colab_type":"text"},"source":["## Doc2Vec"]},{"cell_type":"code","metadata":{"id":"xYrqUl4Jxw8t","colab_type":"code","colab":{}},"source":["#Import all the dependencies\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from nltk.tokenize import word_tokenize\n","\n","tagged_data = [TaggedDocument(_d, tags=[str(i)]) for i, _d in enumerate(np.concatenate([preprocessed_train, preprocessed_test]))]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Umd_nR0Dx0bB","colab_type":"code","outputId":"214e3274-ce75-485d-f621-47948cefeb82","executionInfo":{"status":"ok","timestamp":1577271661219,"user_tz":-180,"elapsed":2800841,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["%%time\n","\n","max_epochs = 10\n","alpha = 0.025\n","\n","model = Doc2Vec(size=embedding_len,\n","                alpha=alpha, \n","                min_alpha=0.00025,\n","                min_count=1,\n","                dm=1)\n","\n","model.build_vocab(tagged_data)\n","\n","for epoch in tqdm(range(max_epochs), total=max_epochs, mininterval=5):\n","    model.train(tagged_data,\n","                total_examples=model.corpus_count,\n","                epochs=model.iter)\n","    # decrease the learning rate\n","    model.alpha -= 0.0002\n","    # fix the learning rate, no decay\n","    model.min_alpha = model.alpha\n","\n","model.save(\"d2v.model\")\n","print(\"Model Saved\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n","  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n","  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n","100%|██████████| 10/10 [45:29<00:00, 272.86s/it]\n","/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["Model Saved\n","CPU times: user 1h 19min 25s, sys: 6min 18s, total: 1h 25min 43s\n","Wall time: 46min 40s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lMT1BYWZ9-LH","colab_type":"code","outputId":"67df2e44-7e23-42e0-da6e-9ae268a5ad77","executionInfo":{"status":"ok","timestamp":1577271662333,"user_tz":-180,"elapsed":2801943,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%%time\n","\n","train_len = len(preprocessed_train)\n","test_len = len(preprocessed_test)\n","\n","train_features = np.zeros((train_len, embedding_len))\n","for i in range(train_len):\n","    train_features[i,:] = model.docvecs[i]\n","    \n","test_features = np.zeros((test_len, embedding_len))\n","for i in range(test_len):\n","    test_features[i,:] = model.docvecs[train_len+i]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 659 ms, sys: 21.5 ms, total: 681 ms\n","Wall time: 680 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L4MgIJ4Yx8nc","colab_type":"text"},"source":["## Sent2Vec"]},{"cell_type":"code","metadata":{"id":"Lljd8zBVyBBq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"1b625af7-f841-4483-e77b-d8e3c5e31e53","executionInfo":{"status":"ok","timestamp":1577357209128,"user_tz":-180,"elapsed":21646,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["!pip install fasttext\n","!pip install Cython\n"," \n","!git clone https://github.com/epfml/sent2vec.git\n","!cd sent2vec/; python setup.py build_ext; pip install ."],"execution_count":21,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.17.4)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.4.3)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (42.0.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.14)\n","fatal: destination path 'sent2vec' already exists and is not an empty directory.\n","running build_ext\n","Processing /content/sent2vec\n","Building wheels for collected packages: sent2vec\n","  Building wheel for sent2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sent2vec: filename=sent2vec-0.0.0-cp36-cp36m-linux_x86_64.whl size=1125823 sha256=432acbc76c32c9d0075a03c2a8f8396f2ce336c5b50cf7f5c4e582be810254b4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-yzp8tbf9/wheels/b1/65/d7/f2c679e0086741bea69f0c4478303b6506bbf4c78dea82f565\n","Successfully built sent2vec\n","Installing collected packages: sent2vec\n","  Found existing installation: sent2vec 0.0.0\n","    Uninstalling sent2vec-0.0.0:\n","      Successfully uninstalled sent2vec-0.0.0\n","Successfully installed sent2vec-0.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4BJ1PD8zyDjX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"2b321bb8-82fd-4a34-8814-5eadf2d821b2","executionInfo":{"status":"ok","timestamp":1577357676902,"user_tz":-180,"elapsed":23825,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["%%time\n","\n","import sent2vec\n","model = sent2vec.Sent2vecModel()\n","model.load_model(os.path.join(embeddings_folder, 'torontobooks_unigrams.bin'))\n","\n","train_features = model.embed_sentences(preprocessed_train)\n","test_features = model.embed_sentences(preprocessed_test)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["CPU times: user 19 s, sys: 2.15 s, total: 21.1 s\n","Wall time: 22.2 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AslnHsTy0gCQ","colab_type":"text"},"source":["## Build and fit the model"]},{"cell_type":"code","metadata":{"id":"JBSKOOA63aR-","colab_type":"code","colab":{}},"source":["submission = pd.read_csv(submission_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W-GuOc0A0evP","colab_type":"code","colab":{}},"source":["models = {\n","    'RandomForestClassifier': RandomForestClassifier(),\n","    'LogisticRegression': LogisticRegression()\n","}\n","\n","# the optimisation parameters for each of the above models\n","params = {\n","    'RandomForestClassifier':{ \n","        \"n_estimators\": [50],\n","        \"max_features\": [\"auto\"],\n","        \"bootstrap\": [True],\n","        \"criterion\": ['gini', 'entropy'],\n","        \"oob_score\": [True]\n","            },\n","    'LogisticRegression': {\n","        'solver': ['newton-cg', 'sag', 'lbfgs'],\n","        'C': [0.01, 0.1, 1, 10]\n","        }  \n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCAI_v8uOabV","colab_type":"code","outputId":"fb6ed0c6-5a81-4007-9386-b53b6a3da7d3","executionInfo":{"status":"ok","timestamp":1577368698753,"user_tz":-180,"elapsed":11013357,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%time\n","\n","for i, class_name in enumerate(TARGET_COLS):\n","    print('**Processing {} comments...**'.format(class_name))\n","\n","    best_score = 0\n","    best_model_with_params = tuple()\n","\n","    for name in models.keys():\n","      print(' **Processing {} model...**'.format(name))\n","      est = models[name]\n","      est_params = params[name]\n","      gscv = GridSearchCV(estimator=est, param_grid=est_params, iid=False, cv=4, \n","                          verbose=10, n_jobs=-1, scoring='roc_auc')\n","      gscv.fit(train_features, train_labels[:, i])\n","      print(\"Best score for the model\\n{}\\nis:{}\".format(gscv.best_estimator_, gscv.best_score_))\n","\n","      if gscv.best_score_ > best_score:\n","        best_score = gscv.best_score_\n","        best_model = gscv.best_estimator_ \n","    \n","    best_model.fit(train_features, train_labels[:, i])\n","    submission[class_name] = best_model.predict_proba(test_features)[:, 1]\n","\n","    print(\"\\nBest score for the class {} is {}\\n\".format(class_name, best_score))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["**Processing toxic comments...**\n"," **Processing RandomForestClassifier model...**\n","Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  6.1min remaining: 18.4min\n","[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  6.1min remaining: 10.2min\n","[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:  6.2min remaining:  6.2min\n","[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed: 13.5min remaining:  8.1min\n","[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed: 13.6min remaining:  4.5min\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 13.7min remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 13.7min finished\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=50,\n","                       n_jobs=None, oob_score=True, random_state=None,\n","                       verbose=0, warm_start=False)\n","is:0.9103119012020913\n"," **Processing LogisticRegression model...**\n","Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  2.6min\n","/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n","[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.9min\n","[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  5.5min\n","[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  6.4min\n","[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  9.5min\n","[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed: 11.5min remaining:   30.1s\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 11.6min finished\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='warn', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n","                   warm_start=False)\n","is:0.9521774122867123\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Best score for the class toxic is 0.9521774122867123\n","\n","**Processing severe_toxic comments...**\n"," **Processing RandomForestClassifier model...**\n","Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  6.4min remaining: 19.1min\n","[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  6.4min remaining: 10.6min\n","[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:  6.4min remaining:  6.4min\n","[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed: 11.4min remaining:  6.8min\n","[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed: 11.5min remaining:  3.8min\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 11.6min finished\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 11.6min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=50,\n","                       n_jobs=None, oob_score=True, random_state=None,\n","                       verbose=0, warm_start=False)\n","is:0.92295984990552\n"," **Processing LogisticRegression model...**\n","Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.4min\n","/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n","[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.6min\n","[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.5min\n","[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  5.2min\n","[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  8.4min\n","[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed: 12.2min remaining:   31.9s\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 12.4min finished\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='warn', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)\n","is:0.9676373048000163\n","\n","Best score for the class severe_toxic is 0.9676373048000163\n","\n","**Processing obscene comments...**\n"," **Processing RandomForestClassifier model...**\n","Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  5.8min remaining: 17.3min\n","[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  5.8min remaining:  9.6min\n","[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:  5.8min remaining:  5.8min\n","[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed: 12.3min remaining:  7.4min\n","[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed: 12.3min remaining:  4.1min\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 12.4min finished\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 12.4min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=50,\n","                       n_jobs=None, oob_score=True, random_state=None,\n","                       verbose=0, warm_start=False)\n","is:0.9261875289348283\n"," **Processing LogisticRegression model...**\n","Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.1min\n","/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n","[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.7min\n","[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.3min\n","[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  5.4min\n","[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  8.3min\n","[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed: 10.9min remaining:   28.4s\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 11.1min finished\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='warn', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n","                   warm_start=False)\n","is:0.9619082218751999\n","\n","Best score for the class obscene is 0.9619082218751999\n","\n","**Processing threat comments...**\n"," **Processing RandomForestClassifier model...**\n","Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  4.7min remaining: 14.0min\n","[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  4.7min remaining:  7.9min\n","[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:  4.9min remaining:  4.9min\n","[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:  8.7min remaining:  5.2min\n","[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:  8.7min remaining:  2.9min\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  8.9min remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  8.9min finished\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=50,\n","                       n_jobs=None, oob_score=True, random_state=None,\n","                       verbose=0, warm_start=False)\n","is:0.8207924127957167\n"," **Processing LogisticRegression model...**\n","Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.4min\n","/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n","[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.6min\n","[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.6min\n","[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  5.3min\n","[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  8.4min\n","[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed: 12.1min remaining:   31.7s\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 12.3min finished\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='warn', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n","                   warm_start=False)\n","is:0.966412911289918\n","\n","Best score for the class threat is 0.966412911289918\n","\n","**Processing insult comments...**\n"," **Processing RandomForestClassifier model...**\n","Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  5.8min remaining: 17.3min\n","[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  5.8min remaining:  9.7min\n","[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:  5.9min remaining:  5.9min\n","/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n","[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed: 12.3min remaining:  7.4min\n","[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed: 12.3min remaining:  4.1min\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 12.5min finished\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 12.5min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=50,\n","                       n_jobs=None, oob_score=True, random_state=None,\n","                       verbose=0, warm_start=False)\n","is:0.9231771087556393\n"," **Processing LogisticRegression model...**\n","Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.4min\n","/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n","[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.9min\n","[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.7min\n","[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  5.5min\n","[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  8.6min\n","[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed: 11.0min remaining:   28.6s\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 11.1min finished\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='warn', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)\n","is:0.9566217639536576\n","\n","Best score for the class insult is 0.9566217639536576\n","\n","**Processing identity_hate comments...**\n"," **Processing RandomForestClassifier model...**\n","Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  5.3min remaining: 15.9min\n","[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  5.4min remaining:  9.0min\n","[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:  5.5min remaining:  5.5min\n","[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed: 10.2min remaining:  6.1min\n","[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed: 10.2min remaining:  3.4min\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 10.3min remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 10.3min finished\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=50,\n","                       n_jobs=None, oob_score=True, random_state=None,\n","                       verbose=0, warm_start=False)\n","is:0.873489060868871\n"," **Processing LogisticRegression model...**\n","Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.2min\n","/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n","[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.5min\n","[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.2min\n","[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  5.0min\n","[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  7.9min\n","[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed: 11.6min remaining:   30.2s\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 11.7min finished\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Best score for the model\n","LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='warn', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n","                   warm_start=False)\n","is:0.9497768986559555\n","\n","Best score for the class identity_hate is 0.9497768986559555\n","\n","CPU times: user 45min 22s, sys: 44 s, total: 46min 6s\n","Wall time: 3h 3min 31s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SQeEcE3N8oL8","colab_type":"code","outputId":"7022c398-0863-4d05-e826-830d0156f0b7","executionInfo":{"status":"ok","timestamp":1577368698768,"user_tz":-180,"elapsed":10969014,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["submission"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00001cee341fdb12</td>\n","      <td>0.966263</td>\n","      <td>0.054183</td>\n","      <td>0.831525</td>\n","      <td>0.011145</td>\n","      <td>0.604859</td>\n","      <td>0.075418</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0000247867823ef7</td>\n","      <td>0.016774</td>\n","      <td>0.008855</td>\n","      <td>0.019123</td>\n","      <td>0.002713</td>\n","      <td>0.022219</td>\n","      <td>0.006187</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00013b17ad220c46</td>\n","      <td>0.015831</td>\n","      <td>0.001117</td>\n","      <td>0.007040</td>\n","      <td>0.000455</td>\n","      <td>0.008738</td>\n","      <td>0.002202</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00017563c3f7919a</td>\n","      <td>0.001216</td>\n","      <td>0.000236</td>\n","      <td>0.001330</td>\n","      <td>0.000328</td>\n","      <td>0.001082</td>\n","      <td>0.000201</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00017695ad8997eb</td>\n","      <td>0.032473</td>\n","      <td>0.000742</td>\n","      <td>0.014291</td>\n","      <td>0.000145</td>\n","      <td>0.007183</td>\n","      <td>0.000405</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>153159</th>\n","      <td>fffcd0960ee309b5</td>\n","      <td>0.285402</td>\n","      <td>0.006920</td>\n","      <td>0.140624</td>\n","      <td>0.001801</td>\n","      <td>0.073401</td>\n","      <td>0.016968</td>\n","    </tr>\n","    <tr>\n","      <th>153160</th>\n","      <td>fffd7a9a6eb32c16</td>\n","      <td>0.069394</td>\n","      <td>0.004645</td>\n","      <td>0.021491</td>\n","      <td>0.005622</td>\n","      <td>0.038148</td>\n","      <td>0.010129</td>\n","    </tr>\n","    <tr>\n","      <th>153161</th>\n","      <td>fffda9e8d6fafa9e</td>\n","      <td>0.004855</td>\n","      <td>0.000457</td>\n","      <td>0.002205</td>\n","      <td>0.000246</td>\n","      <td>0.002180</td>\n","      <td>0.000996</td>\n","    </tr>\n","    <tr>\n","      <th>153162</th>\n","      <td>fffe8f1340a79fc2</td>\n","      <td>0.005788</td>\n","      <td>0.001509</td>\n","      <td>0.002793</td>\n","      <td>0.001553</td>\n","      <td>0.004078</td>\n","      <td>0.007899</td>\n","    </tr>\n","    <tr>\n","      <th>153163</th>\n","      <td>ffffce3fb183ee80</td>\n","      <td>0.814659</td>\n","      <td>0.012580</td>\n","      <td>0.303884</td>\n","      <td>0.005748</td>\n","      <td>0.269990</td>\n","      <td>0.013707</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>153164 rows × 7 columns</p>\n","</div>"],"text/plain":["                      id     toxic  ...    insult  identity_hate\n","0       00001cee341fdb12  0.966263  ...  0.604859       0.075418\n","1       0000247867823ef7  0.016774  ...  0.022219       0.006187\n","2       00013b17ad220c46  0.015831  ...  0.008738       0.002202\n","3       00017563c3f7919a  0.001216  ...  0.001082       0.000201\n","4       00017695ad8997eb  0.032473  ...  0.007183       0.000405\n","...                  ...       ...  ...       ...            ...\n","153159  fffcd0960ee309b5  0.285402  ...  0.073401       0.016968\n","153160  fffd7a9a6eb32c16  0.069394  ...  0.038148       0.010129\n","153161  fffda9e8d6fafa9e  0.004855  ...  0.002180       0.000996\n","153162  fffe8f1340a79fc2  0.005788  ...  0.004078       0.007899\n","153163  ffffce3fb183ee80  0.814659  ...  0.269990       0.013707\n","\n","[153164 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"ujanlBVs61IJ","colab_type":"text"},"source":["## Cheaty evaluating on test labels"]},{"cell_type":"code","metadata":{"id":"YUF4Uxrl8pXr","colab_type":"code","colab":{}},"source":["# labels for the test data; value of -1 indicates it was not used for scoring; (Note: file added after competition close!)\n","test_labels_df = pd.read_csv(test_labels_filepath)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6crgLcLx7X-p","colab_type":"code","outputId":"7ba540e2-708a-46a8-863a-89068299c319","executionInfo":{"status":"ok","timestamp":1577368700643,"user_tz":-180,"elapsed":10968849,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_labels_df = test_labels_df[(test_labels_df[\"toxic\"] != -1) &\n","                                (test_labels_df[\"severe_toxic\"] != -1) &\n","                                (test_labels_df[\"obscene\"] != -1) &\n","                                (test_labels_df[\"threat\"] != -1) &\n","                                (test_labels_df[\"insult\"] != -1) &\n","                                (test_labels_df[\"identity_hate\"] != -1)]\n","test_labels_df.shape                               "],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(63978, 7)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"-ymumFOQ9sA1","colab_type":"code","outputId":"db06df0b-032b-43a3-fe26-7db52a11a5a7","executionInfo":{"status":"ok","timestamp":1577368700644,"user_tz":-180,"elapsed":10968497,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["submission_to_evaluate = submission[submission['id'].isin(test_labels_df['id'].values)]\n","submission_to_evaluate.shape"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(63978, 7)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"C3r8VTCK_TaM","colab_type":"code","outputId":"4efcc581-fc5d-49b8-fd57-5e7e3a50f708","executionInfo":{"status":"ok","timestamp":1577368700645,"user_tz":-180,"elapsed":10967193,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["scores = []\n","for class_name in TARGET_COLS:\n","    train_target = test_labels_df[class_name]\n","    train_predicted = submission_to_evaluate[class_name]\n","\n","    cv_score = np.mean(roc_auc_score(train_target.values, train_predicted.values))\n","    scores.append(cv_score)\n","    print('CV score for class {} is {}'.format(class_name, cv_score))\n","\n","print('Total CV score is {}'.format(np.mean(scores)))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["CV score for class toxic is 0.9375341268252789\n","CV score for class severe_toxic is 0.9498586799525744\n","CV score for class obscene is 0.9426970760475595\n","CV score for class threat is 0.9719721985483732\n","CV score for class insult is 0.9370787074676544\n","CV score for class identity_hate is 0.9377735462930369\n","Total CV score is 0.9461523891890796\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"YKsSnwkd3TBJ","colab_type":"code","colab":{}},"source":["submission.to_csv(os.path.join(data_folder,\"submission_emb_sklearn.csv\"), index = False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U9dbhDwB2GG3","colab_type":"text"},"source":["kaggle 0.92095\n","\n","glove.840B.300d.txt 0.94798  \n","Dov2Vec max_epochs = 10 embedding_len = 50 alpha = 0.025  0.65755   \n","sent2vec 'torontobooks_unigrams.bin' 700dim, trained on the BookCorpus dataset  0.94586"]},{"cell_type":"code","metadata":{"id":"Liwabi_J5RMQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}