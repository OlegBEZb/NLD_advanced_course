{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"NLP advance course. HW3. Distributive semantic. Embedings_+_Bidirectional_GRU.ipynb","provenance":[],"collapsed_sections":["GRh7ig80jk3s","1_nWe7O-jqak","TGzxJch3juGy","sWmhQEFAj1VE","_yDXCBmqtkPl","0hTlPvNY8gi1"],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KVRaU_zG-PaI","colab_type":"text"},"source":["## Embeddings to check\n","\n","* Word Embeddings (word2vec, GloVe, etc.)\n","* Starspace and other similarity learning embeddings\n","* char-gram embeddings (bpemb, fasttext etc.)\n","* doc and sentence embeddings (doc2vec, sent2vec etc.)\n","* specific context models (BERT, ELMo)\n","* Advanced: Poincare Embeddings concept"]},{"cell_type":"markdown","metadata":{"id":"30D0Scxk4kn3","colab_type":"text"},"source":["# Libs import"]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"ZnXUdrxQ3TAN","colab_type":"code","outputId":"3b37cdd6-5f95-40d0-8cbe-36931013f31b","executionInfo":{"status":"ok","timestamp":1578587431289,"user_tz":-180,"elapsed":9355,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":216}},"source":["import os, math, operator, csv, random, pickle, re, sys\n","import tensorflow as tf\n","from tqdm import tqdm\n","import pandas as pd\n","import gc\n","from collections import Counter\n","\n","import keras\n","from keras.models import Model\n","from keras.layers import MaxPooling1D, BatchNormalization, Permute, Lambda, \\\n","Activation, Conv1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, \\\n","Embedding, Dropout, Input, CuDNNGRU, merge, CuDNNLSTM, Flatten, \\\n","TimeDistributed, concatenate, SpatialDropout1D, Bidirectional\n","from nltk.util import pad_sequence\n","from keras.preprocessing.sequence import pad_sequences\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import gensim\n","from gensim.models import KeyedVectors\n","\n","import gc\n","from keras import backend as K\n","\n","import nltk\n","nltk.download('stopwords');\n","from nltk.tokenize import TweetTokenizer\n","\n","from nltk.corpus import stopwords\n","\n","! pip install Unidecode;\n","from unidecode import unidecode\n","#! pip install pyspellchecker;\n","#from spellchecker import SpellChecker\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import KFold, train_test_split, cross_val_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from keras import backend as K\n","\n","import numpy as np\n","import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import Model\n","from keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n","from keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, CuDNNGRU, Conv1D\n","from keras.preprocessing import text\n","from keras.callbacks import LearningRateScheduler, Callback\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Collecting Unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n","\u001b[?25hInstalling collected packages: Unidecode\n","Successfully installed Unidecode-1.1.1\n","1.15.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ypZqfsNI6-Ne","colab_type":"text"},"source":["# Check GPU"]},{"cell_type":"code","metadata":{"id":"3JtxOKtA35gA","colab_type":"code","trusted":true,"outputId":"c1e39e2d-1cf3-4dfe-fa03-1b7b121abf56","executionInfo":{"status":"ok","timestamp":1578587432777,"user_tz":-180,"elapsed":10484,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if tf.test.is_gpu_available(\n","    cuda_only=False,\n","    min_cuda_compute_capability=None\n","):\n","    print(tf.test.gpu_device_name())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i673BlTJEazT","colab_type":"text"},"source":["# Global vars"]},{"cell_type":"code","metadata":{"id":"okymGz_lEjLC","colab_type":"code","trusted":true,"colab":{}},"source":["COLAB = True\n","\n","BATCH_SIZE = 512\n","LSTM_UNITS = 128\n","DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n","GLOBAL_EPOCHS = 2\n","EPOCHS = 5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VD2z8D2V7Dod","colab_type":"text"},"source":["# Authorization on Google drive and configurings paths"]},{"cell_type":"code","metadata":{"id":"auzLnrdK51Rg","colab_type":"code","trusted":true,"outputId":"8d2eefc1-57c7-421c-d06a-9113c1d7d210","executionInfo":{"status":"ok","timestamp":1578587460156,"user_tz":-180,"elapsed":37283,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["if COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    homework_folder = os.path.join('/content/drive/My Drive', 'Advanced NLP/Homework 1: Classical classification task like Kaggle Toxic or Quora')\n","    data_folder = '/content/drive/My Drive/Advanced NLP/Homework 1: Classical classification task like Kaggle Toxic or Quora/Toxic data'\n","    embeddings_folder = '/content/drive/My Drive/Advanced NLP/Homework 1: Classical classification task like Kaggle Toxic or Quora' # make embs folder\n","    print('data found:', os.listdir(data_folder))\n","else:\n","    data_folder = '../input/jigsaw-toxic-comment-classification-challenge/'\n","    embeddings_folder = '../input/glove-global-vectors-for-word-representation'\n","    print('data found:', os.listdir(data_folder))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","data found: ['test.csv', 'test_labels.csv', 'train.csv', 'sample_submission.csv', 'submission.csv', 'submission_emb_sklearn.csv', 'submission_bidirectional_GRU.csv']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"UYdAXsdT3TAd","colab_type":"code","colab":{}},"source":["#pretrained_folder = \"../input/\"\n","train_filepath = os.path.join(data_folder,\"train.csv\")\n","test_filepath = os.path.join(data_folder,\"test.csv\")\n","test_labels_filepath = os.path.join(data_folder,\"test_labels.csv\")\n","\n","#path to a submission\n","submission_path = os.path.join(data_folder,\"sample_submission.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15GVrJYa717o","colab_type":"text"},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"jYljyuKTCm8r","colab_type":"text"},"source":["## Dicts and lists of useful words and transformations"]},{"cell_type":"code","metadata":{"id":"YjL5O731CtDD","colab_type":"code","trusted":true,"colab":{}},"source":["#List of some words that often appear in toxic comments\n","#Sorry about the level of toxicity in it!\n","toxic_words = [\"poop\", \"crap\", \"prick\", \"twat\", \"wikipedia\", \"wiki\", \"hahahahaha\", \"lol\", \"bastard\", \"sluts\", \"slut\", \"douchebag\", \"douche\", \"blowjob\", \"nigga\", \"dumb\", \"jerk\", \"wanker\", \"wank\", \"penis\", \"motherfucker\", \"fucker\", \"fuk\", \"fucking\", \"fucked\", \"fuck\", \"bullshit\", \"shit\", \"stupid\", \"bitches\", \"bitch\", \"suck\", \"cunt\", \"dick\", \"cocks\", \"cock\", \"die\", \"kill\", \"gay\", \"jewish\", \"jews\", \"jew\", \"niggers\", \"nigger\", \"faggot\", \"fag\", \"asshole\"]\n","astericks_words = [('mother****ers', 'motherfuckers'), ('motherf*cking', 'motherfucking'), ('mother****er', 'motherfucker'), ('motherf*cker', 'motherfucker'), ('bullsh*t', 'bullshit'), ('f**cking', 'fucking'), ('f*ucking', 'fucking'), ('fu*cking', 'fucking'), ('****ing', 'fucking'), ('a**hole', 'asshole'), ('assh*le', 'asshole'), ('f******', 'fucking'), ('f*****g', 'fucking'), ('f***ing', 'fucking'), ('f**king', 'fucking'), ('f*cking', 'fucking'), ('fu**ing', 'fucking'), ('fu*king', 'fucking'), ('fuc*ers', 'fuckers'), ('f*****', 'fucking'), ('f***ed', 'fucked'), ('f**ker', 'fucker'), ('f*cked', 'fucked'), ('f*cker', 'fucker'), ('f*ckin', 'fucking'), ('fu*ker', 'fucker'), ('fuc**n', 'fucking'), ('ni**as', 'niggas'), ('b**ch', 'bitch'), ('b*tch', 'bitch'), ('c*unt', 'cunt'), ('f**ks', 'fucks'), ('f*ing', 'fucking'), ('ni**a', 'nigga'), ('c*ck', 'cock'), ('c*nt', 'cunt'), ('cr*p', 'crap'), ('d*ck', 'dick'), ('f***', 'fuck'), ('f**k', 'fuck'), ('f*ck', 'fuck'), ('fc*k', 'fuck'), ('fu**', 'fuck'), ('fu*k', 'fuck'), ('s***', 'shit'), ('s**t', 'shit'), ('sh**', 'shit'), ('sh*t', 'shit'), ('tw*t', 'twat')]\n","fasttext_misspelings = {\"'n'balls\": 'balls', \"-nazi's\": 'nazis', 'adminabuse': 'admin abuse', \"admins's\": 'admins', 'arsewipe': 'arse wipe', 'assfack': 'asshole', 'assholifity': 'asshole', 'assholivity': 'asshole', 'asshoul': 'asshole', 'asssholeee': 'asshole', 'belizeans': 'mexicans', \"blowing's\": 'blowing', 'bolivians': 'mexicans', 'celtofascists': 'fascists', 'censorshipmeisters': 'censor', 'chileans': 'mexicans', 'clerofascist': 'fascist', 'cowcrap': 'crap', 'crapity': 'crap', \"d'idiots\": 'idiots', 'deminazi': 'nazi', 'dftt': \"don't feed the troll\", 'dildohs': 'dildo', 'dramawhores': 'drama whores', 'edophiles': 'pedophiles', 'eurocommunist': 'communist', 'faggotkike': 'faggot', 'fantard': 'retard', 'fascismnazism': 'fascism', 'fascistisized': 'fascist', 'favremother': 'mother', 'fuxxxin': 'fucking', \"g'damn\": 'goddamn', 'harassmentat': 'harassment', 'harrasingme': 'harassing me', 'herfuc': 'motherfucker', 'hilterism': 'fascism', 'hitlerians': 'nazis', 'hitlerites': 'nazis', 'hubrises': 'pricks', 'idiotizing': 'idiotic', 'inadvandals': 'vandals', \"jackass's\": 'jackass', 'jiggabo': 'nigga', 'jizzballs': 'jizz balls', 'jmbass': 'dumbass', 'lejittament': 'legitimate', \"m'igger\": 'nigger', \"m'iggers\": 'niggers', 'motherfacking': 'motherfucker', 'motherfuckenkiwi': 'motherfucker', 'muthafuggas': 'niggas', 'nazisms': 'nazis', 'netsnipenigger': 'nigger', 'niggercock': 'nigger', 'niggerspic': 'nigger', 'nignog': 'nigga', 'niqqass': 'niggas', \"non-nazi's\": 'not a nazi', 'panamanians': 'mexicans', 'pedidiots': 'idiots', 'picohitlers': 'hitler', 'pidiots': 'idiots', 'poopia': 'poop', 'poopsies': 'poop', 'presumingly': 'obviously', 'propagandaanddisinformation': 'propaganda and disinformation', 'propagandaministerium': 'propaganda', 'puertoricans': 'mexicans', 'puertorricans': 'mexicans', 'pussiest': 'pussies', 'pussyitis': 'pussy', 'rayaridiculous': 'ridiculous', 'redfascists': 'fascists', 'retardzzzuuufff': 'retard', \"revertin'im\": 'reverting', 'scumstreona': 'scums', 'southamericans': 'mexicans', 'strasserism': 'fascism', 'stuptarded': 'retarded', \"t'nonsense\": 'nonsense', \"threatt's\": 'threat', 'titoists': 'communists', 'twatbags': 'douchebags', 'youbollocks': 'you bollocks'}\n","acronym_words = {\"btw\":\"by the way\", \"yo\": \"you\", \"u\": \"you\", \"r\": \"are\", \"ur\": \"your\", \"ima\": \"i am going to\", \"imma\": \"i am going to\", \"i'ma\":\"i am going to\", \"cos\":\"because\", \"coz\":\"because\", \"stfu\": \"shut the fuck up\", \"wat\": \"what\"}\n","CHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—'\n","\n","english_stopwords = set(stopwords.words('english'))\n","\n","#spell_checker = SpellChecker()\n","\n","cont_patterns = [\n","    (r'(W|w)on\\'t', r'will not'),\n","    (r'(C|c)an\\'t', r'can not'),\n","    (r'(I|i)\\'m', r'i am'),\n","    (r'(A|a)in\\'t', r'is not'),\n","    (r'(\\w+)\\'ll', r'\\g<1> will'),\n","    (r'(\\w+)n\\'t', r'\\g<1> not'),\n","    (r'(\\w+)\\'ve', r'\\g<1> have'),\n","    (r'(\\w+)\\'s', r'\\g<1> is'),\n","    (r'(\\w+)\\'re', r'\\g<1> are'),\n","    (r'(\\w+)\\'d', r'\\g<1> would'),\n","]\n","patterns = [(re.compile(regex), repl) for (regex, repl) in cont_patterns]\n","\n","#We will filter all characters except alphabet characters and some punctuation\n","valid_characters = \" \" + \"@$\" + \"'!?-\" + \"abcdefghijklmnopqrstuvwxyz\" + \"abcdefghijklmnopqrstuvwxyz\".upper()\n","valid_set = set(x for x in valid_characters)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cs_nlu1iILY1","colab_type":"text"},"source":["## Funcs for processing"]},{"cell_type":"code","metadata":{"id":"GfUaIP-wIKTZ","colab_type":"code","trusted":true,"colab":{}},"source":["def replace_url(word):\n","    if \"http://\" in word or \"www.\" in word or \"https://\" in word or \"wikipedia.org\" in word:\n","        return \"\"\n","    return word\n","\n","\n","def word_tokenize(sentence, tokenizer):\n","    sentence = sentence.replace(\"$\", \"s\")\n","    sentence = sentence.replace(\"@\", \"a\")    \n","    sentence = sentence.replace(\"!\", \" ! \")\n","    sentence = sentence.replace(\"?\", \" ? \")\n","\n","    return tokenizer.tokenize(sentence)\n","\n","\n","def split_toxic_and_normal_parts(word, toxic_words):\n","    if word == \"\":\n","        return \"\"\n","    \n","    lower = word.lower()\n","    for toxic_word in toxic_words:\n","        start = lower.find(toxic_word)\n","        if start >= 0:\n","            end = start + len(toxic_word)\n","            result = \" \".join([word[0:start], word[start:end], split_toxic_and_normal_parts(word[end:], toxic_words)])\n","            return result.replace(\"  \", \" \").strip()\n","    return word\n","\n","\n","def normalize_by_dictionary(normalized_word, dictionary):\n","    result = []\n","    for word in normalized_word.split():\n","        if word == word.upper():\n","            if word.lower() in dictionary:\n","                result.append(dictionary[word.lower()].upper())\n","            else:\n","                result.append(word)\n","        else:\n","            if word.lower() in dictionary:\n","                result.append(dictionary[word.lower()])\n","            else:\n","                result.append(word)\n","    \n","    return \" \".join(result)\n","\n","\n","def normalize_comment(comment, tokenizer, max_comment_length):\n","    comment = unidecode(comment)\n","    comment = comment[:max_comment_length]\n","\n","    normalized_words = []\n","    \n","    # ('mother****ers', 'motherfuckers')\n","    # for w in astericks_words:\n","    #     if w[0] in comment:\n","    #         comment = comment.replace(w[0], w[1])\n","    #     if w[0].upper() in comment:\n","    #         comment = comment.replace(w[0].upper(), w[1].upper())\n","    \n","    for word in word_tokenize(comment, tokenizer):\n","        if word in english_stopwords: continue\n","\n","        # # '(W|w)on\\'t', r'will not'\n","        # for (pattern, repl) in patterns:\n","        #    word = re.sub(pattern, repl, word)\n","\n","        if word == \".\" or word == \",\":\n","            normalized_words.append(word)\n","            continue\n","        \n","        # drop url parts from links\n","        # word = replace_url(word)\n","\n","        # replace single dots to whitespaces\n","        if word.count(\".\") == 1:\n","            word = word.replace(\".\", \" \")\n","\n","        # leave only legalized symbols\n","        filtered_word = \"\".join([x for x in word if x in valid_set])\n","                    \n","        #Kind of hack: for every word check if it has a toxic word as a part of it\n","        #If so, split this word by swear and non-swear part.\n","        #normalized_word = split_toxic_and_normal_parts(filtered_word, toxic_words)\n","        normalized_word = filtered_word\n","\n","#         normalized_word = normalize_by_dictionary(normalized_word, hyphens_dict)\n","#         normalized_word = normalize_by_dictionary(normalized_word, merged_dict)\n","        \n","        # check misspellings\n","        # temp = []\n","        # for word in normalized_word.split():\n","        #   temp.append(spell_checker.correction(word))\n","        # normalized_word = \" \".join(temp)\n","          \n","        # normalized_word = normalize_by_dictionary(normalized_word, fasttext_misspelings)\n","        normalized_word = normalize_by_dictionary(normalized_word, acronym_words)\n","\n","        normalized_words.append(normalized_word)\n","        \n","    normalized_comment = \" \".join(normalized_words)\n","    \n","    result = []\n","    for word in normalized_comment.split():\n","        # if word is upper\n","        if word.upper() == word:\n","            result.append(word)\n","        else:\n","            result.append(word.lower())\n","    \n","    #apparently, people on wikipedia love to talk about sockpuppets :-)\n","    result = \" \".join(result)\n","    if \"sock puppet\" in result:\n","        result = result.replace(\"sock puppet\", \"sockpuppet\")\n","    \n","    if \"SOCK PUPPET\" in result:\n","        result = result.replace(\"SOCK PUPPET\", \"SOCKPUPPET\")\n","    \n","    return result\n","\n","\n","def preprocess_text(df, preprocessing_func, tokenizer, max_comment_length):\n","  text_ndarray = df.fillna('_na').values\n","  np_preprocessing_func = np.vectorize(preprocessing_func)\n","\n","  preprocessed_text = np_preprocessing_func(text_ndarray, tokenizer, max_comment_length)\n","\n","  print('Gained shape:', preprocessed_text.shape)\n","  return preprocessed_text\n","\n","\n","def tokenize_and_pad(text, tokenizer):\n","\n","  tokenized_text = tokenizer.texts_to_sequences(text)\n","  padded_text = pad_sequences(tokenized_text, maxlen=MAX_LEN, dtype='int', value=0)\n","\n","  print('Gained shape:', padded_text.shape)\n","  return padded_text"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tn1-XTZEIZ3y","colab_type":"text"},"source":["## Loading frames and processing them"]},{"cell_type":"code","metadata":{"id":"1AWRdxZsHG3B","colab_type":"code","trusted":true,"colab":{}},"source":["TEXT_COLUMN = 'comment_text'\n","TARGET_COLS = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n","\n","MAX_LEN = 220\n","max_tokens = 20000\n","max_comment_length = 20000 #We are going to truncate a comment if its length > threshold"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BAe8xpV48CO1","colab_type":"code","trusted":true,"outputId":"eb5480d6-5190-4cff-8f7e-49f7c3d0c9b8","executionInfo":{"status":"ok","timestamp":1578591374895,"user_tz":-180,"elapsed":1365,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%%time\n","\n","train_df = pd.read_csv(train_filepath)\n","train_labels = train_df[TARGET_COLS].values"],"execution_count":44,"outputs":[{"output_type":"stream","text":["CPU times: user 668 ms, sys: 95.1 ms, total: 763 ms\n","Wall time: 798 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dxwo5A8VfRRL","colab_type":"code","trusted":true,"outputId":"9b2848ff-aba9-40a7-bd61-90c94bd05764","executionInfo":{"status":"ok","timestamp":1578590348129,"user_tz":-180,"elapsed":64083,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["%%time\n","\n","tknzr = TweetTokenizer(strip_handles=False, reduce_len=True)\n","\n","preprocessed_train = preprocess_text(train_df[TEXT_COLUMN], \n","                                     normalize_comment, \n","                                     tknzr,\n","                                     max_comment_length)\n","# # preprocessed_train = train_df[TEXT_COLUMN].fillna(\"CVxTz\").values\n","# print(preprocessed_train[:3])\n","# preprocessed_train = train_df[TEXT_COLUMN]\n","\n","del train_df"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Gained shape: (159571,)\n","CPU times: user 1min, sys: 2.85 s, total: 1min 3s\n","Wall time: 1min 3s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Waa0TI1tqpPt","colab_type":"code","trusted":true,"outputId":"28817b84-7fbd-449e-d052-065e440a44ec","executionInfo":{"status":"ok","timestamp":1578587547904,"user_tz":-180,"elapsed":87608,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["%%time\n","\n","tokenizer = Tokenizer(num_words=max_tokens)\n","tokenizer.fit_on_texts(list(preprocessed_train))\n","\n","tokenized_train = tokenize_and_pad(preprocessed_train, tokenizer)\n","# list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n","# list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n","#print(tokenized_train[:3])\n","\n","del preprocessed_train"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Gained shape: (159571, 220)\n","CPU times: user 21.8 s, sys: 399 ms, total: 22.2 s\n","Wall time: 22.2 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_h3CsFuN9TpL","colab_type":"code","trusted":true,"outputId":"8c2e6b84-8692-4b98-fd5a-e482adbcf4d5","executionInfo":{"status":"ok","timestamp":1578590407811,"user_tz":-180,"elapsed":59661,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["%%time\n","\n","test_df = pd.read_csv(test_filepath)\n","\n","preprocessed_test = preprocess_text(test_df[TEXT_COLUMN], \n","                                    normalize_comment, \n","                                    tknzr,\n","                                    max_comment_length)\n","# preprocessed_test = test_df[TEXT_COLUMN].fillna(\"CVxTz\").values\n","# preprocessed_test = test_df[TEXT_COLUMN]\n","\n","\n","\n","#del preprocessed_test\n","del test_df\n","gc.collect()"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Gained shape: (153164,)\n","CPU times: user 56.1 s, sys: 2.97 s, total: 59.1 s\n","Wall time: 59.1 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cjsjwMkWvVCo","colab_type":"code","outputId":"6668902d-b4e1-4deb-bd64-ca53a53f075c","executionInfo":{"status":"ok","timestamp":1578587618205,"user_tz":-180,"elapsed":157878,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["tokenized_test = tokenize_and_pad(preprocessed_test, tokenizer)\n","\n","del preprocessed_test\n","gc.collect()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Gained shape: (153164, 220)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"n8APgvUyskaf","colab_type":"text"},"source":["# Training model"]},{"cell_type":"markdown","metadata":{"id":"wCRY8qnNJTh_","colab_type":"text"},"source":["## Preparing features"]},{"cell_type":"code","metadata":{"id":"3jqSUK8Dpd3Q","colab_type":"code","outputId":"3d43d16b-2699-43e9-ebd9-ca298ab894c0","executionInfo":{"status":"ok","timestamp":1578587618207,"user_tz":-180,"elapsed":157864,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["embedding_len = 1536\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' %len(word_index))\n","\n","#del tokenizer\n","gc.collect()\n","\n","num_words = min(max_tokens, len(word_index) + 1)\n","embedding_matrix = np.zeros((num_words, embedding_len)) # zeroth row for UNK\n","print('embedding matrix shape', embedding_matrix.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 184924 unique tokens.\n","embedding matrix shape (20000, 1536)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GRh7ig80jk3s","colab_type":"text"},"source":["### GloVe"]},{"cell_type":"code","metadata":{"trusted":true,"id":"BNjZiXPZEYvX","colab_type":"code","colab":{}},"source":["# embedding_len = 200\n","# words = pd.read_csv(os.path.join(embeddings_folder, \"glove.twitter.27B.{}d.txt\".format(embedding_len)), \n","#                     sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n","\n","# embedding_len = 300\n","# words = pd.read_csv(os.path.join(embeddings_folder, \"glove.840B.300d.txt\"), \n","#                     sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n","\n","\n","# vocab_words = words[words.index.isin(list(word_index.keys()))]\n","# print('vocab_words.shape', vocab_words.shape)\n","\n","# del words\n","# gc.collect()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m0-ZU5VYq-Kh","colab_type":"code","colab":{}},"source":["# def get_vec(word, words_df):\n","#     return words_df.loc[word].values\n","\n","\n","\n","# for word, i in word_index.items():\n","#   if i >= max_tokens:\n","#     continue\n","#   try:\n","#     embedding_vector = get_vec(word, vocab_words)\n","#   except:\n","#     continue\n","#   if embedding_vector is not None:\n","#     # words not found in embedding index will be all-zeros.\n","#     embedding_matrix[i] = embedding_vector\n","\n","# # %%time\n","# # embedding_matrix = np.load('../input/embedding-2/embedding_matrix_big.npy')\n","    \n","# print('embedding_matrix.shape', embedding_matrix.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1_nWe7O-jqak","colab_type":"text"},"source":["### StarSpace"]},{"cell_type":"code","metadata":{"id":"OD8SO8xXfsVz","colab_type":"code","colab":{}},"source":["# Starspace attempt\n","\n","# from sklearn.feature_extraction.text import CountVectorizer\n","# count_vectorizer = CountVectorizer(min_df=0, max_df=0.99, max_features=10000)\n","# X_train = count_vectorizer.fit_transform(article_contents.main_content.iloc[0:train_row])\n","# X_train = count_vectorizer.inverse_transform(X_train)\n","# label_prefix = '__label__'\n","# with open(\"train_starspace.txt\", 'w+') as file:\n","#     for i in range(10):\n","#         file.write(' '.join(preprocessed_train[i].split(' ')) + ' ' + label_prefix + train_labels[i])\n","#         file.write('\\n')\n","# file.close()\n","\n","# The result file will look like this (all separeted by space, and label will have prefix __label__)\n","# how are you ... __label__b\n","# this is just an example ... __label__c"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TGzxJch3juGy","colab_type":"text"},"source":["### FastText"]},{"cell_type":"code","metadata":{"id":"voep54c6Q-I-","colab_type":"code","outputId":"64afe0b8-56c3-40e5-87f5-7372096ffc2b","executionInfo":{"status":"ok","timestamp":1577351733548,"user_tz":-180,"elapsed":3847,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!pip install fasttext"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.1)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (42.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.17.4)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SBeehRN-oS9V","colab_type":"code","colab":{}},"source":["# import codecs\n","\n","# #load embeddings\n","# print('loading word embeddings...')\n","# embeddings_index = {}\n","# f = codecs.open(os.path.join(embeddings_folder, 'crawl-300d-2M-subword.vec'), encoding='utf-8')\n","# for line in tqdm(f, mininterval=5):\n","#     values = line.rstrip().rsplit(' ')\n","#     word = values[0]\n","#     coefs = np.asarray(values[1:], dtype='float32')\n","#     embeddings_index[word] = coefs\n","# f.close()\n","# print('found %s word vectors' % len(embeddings_index))\n","# print('preparing embedding matrix...')\n","# words_not_found = []\n","\n","\n","# for word, i in word_index.items():\n","#     if i >= max_tokens:\n","#         continue\n","#     embedding_vector = embeddings_index.get(word)\n","#     if (embedding_vector is not None) and len(embedding_vector) > 0:\n","#         # words not found in embedding index will be all-zeros.\n","#         embedding_matrix[i] = embedding_vector\n","#     else:\n","#         words_not_found.append(word)\n","# print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n","\n","\n","# words_not_found[:10]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sWmhQEFAj1VE","colab_type":"text"},"source":["### BPEmb"]},{"cell_type":"code","metadata":{"id":"MdMBN-HPjjek","colab_type":"code","colab":{}},"source":["# !pip install bpemb;\n","# from bpemb import BPEmb\n","# # load English BPEmb model with default vocabulary size of max_tokens\n","# bpemb_en = BPEmb(lang=\"en\", dim=embedding_len, vs=max_tokens)\n","# bpemb_en.vectors.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JQn_7WjrNP1","colab_type":"code","colab":{}},"source":["# # mean vector of word parts\n","# def get_vec(word):\n","#     vec = bpemb_en.embed(word)\n","#     return vec.mean(axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSAJK0AYsdW2","colab_type":"code","trusted":true,"outputId":"bd9383ce-edd7-4c2f-b258-1dea1d46675c","executionInfo":{"status":"ok","timestamp":1577171539556,"user_tz":-180,"elapsed":1612,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# %%time\n","\n","# for word, i in word_index.items():\n","#   if i >= max_tokens:\n","#     continue\n","#   try:\n","#     embedding_vector = get_vec(word)\n","#   except:\n","#     continue\n","#   if embedding_vector is not None:\n","#     # words not found in embedding index will be all-zeros.\n","#     embedding_matrix[i] = embedding_vector\n","\n","# print('embedding_matrix.shape', embedding_matrix.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["embedding_matrix.shape (20000, 300)\n","CPU times: user 504 ms, sys: 18.1 ms, total: 522 ms\n","Wall time: 520 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W2ezEW492Nnj","colab_type":"text"},"source":["### Flair"]},{"cell_type":"code","metadata":{"id":"ScKTCXs-trr_","colab_type":"code","outputId":"01af3e73-bbbf-4cbf-9253-3a2dd3befe54","executionInfo":{"status":"ok","timestamp":1578587705711,"user_tz":-180,"elapsed":87257,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["! pip install tiny-tokenizer\n","! pip install flair\n","\n","import flair\n","from flair.data import Sentence\n","import torch"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Collecting tiny-tokenizer\n","  Downloading https://files.pythonhosted.org/packages/8d/0f/aa52c227c5af69914be05723b3deaf221805a4ccbce87643194ef2cdde43/tiny_tokenizer-3.1.0.tar.gz\n","Building wheels for collected packages: tiny-tokenizer\n","  Building wheel for tiny-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tiny-tokenizer: filename=tiny_tokenizer-3.1.0-cp36-none-any.whl size=10550 sha256=aa15269699b787314d1c790861bba985df9096ce9ad75c95d32baf09b8b5ec6d\n","  Stored in directory: /root/.cache/pip/wheels/d1/c8/36/334497a689fab90128232e86b5829b800dd271a3d5d5959c53\n","Successfully built tiny-tokenizer\n","Installing collected packages: tiny-tokenizer\n","Successfully installed tiny-tokenizer-3.1.0\n","Collecting flair\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/22/8fc8e5978ec05b710216735ca47415700e83f304dec7e4281d61cefb6831/flair-0.4.4-py3-none-any.whl (193kB)\n","\u001b[K     |████████████████████████████████| 194kB 2.8MB/s \n","\u001b[?25hCollecting bpemb>=0.2.9\n","  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n","Collecting transformers>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n","\u001b[K     |████████████████████████████████| 450kB 48.1MB/s \n","\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n","Collecting langdetect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n","\u001b[K     |████████████████████████████████| 1.0MB 51.4MB/s \n","\u001b[?25hRequirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from flair) (3.10.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.6)\n","Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n","Collecting segtok>=1.5.7\n","  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.2)\n","Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from flair) (0.2.0)\n","Requirement already satisfied: tiny-tokenizer[all] in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.0)\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n","Collecting deprecated>=1.2.4\n","  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n","Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n","Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.3.1)\n","Collecting sqlitedict>=1.6.0\n","  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.2)\n","Collecting ipython==7.6.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n","\u001b[K     |████████████████████████████████| 778kB 35.3MB/s \n","\u001b[?25hCollecting mpld3==0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n","\u001b[K     |████████████████████████████████| 798kB 43.1MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 35.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (2.21.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (1.17.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (1.10.47)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 47.0MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.22.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect->flair) (1.12.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (42.0.2)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (8.0.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.3.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.6.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n","Collecting SudachiDict-core@ https://object-storage.tyo2.conoha.io/v1/nc_2520839e1f9641b08211a5c85243124a/sudachi/SudachiDict_core-20190927.tar.gz ; extra == \"all\"\n","\u001b[?25l  Downloading https://object-storage.tyo2.conoha.io/v1/nc_2520839e1f9641b08211a5c85243124a/sudachi/SudachiDict_core-20190927.tar.gz (70.7MB)\n","\u001b[K     |████████████████████████████████| 70.7MB 44kB/s \n","\u001b[?25hCollecting SudachiPy; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/c9/40bfb291a7995ad218451ef97083432f998b822e3ecbd9f586f593d2cfb6/SudachiPy-0.4.2-py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n","\u001b[?25hCollecting janome; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/f0/bd7f90806132d7d9d642d418bdc3e870cfdff5947254ea3cab27480983a7/Janome-0.3.10-py2.py3-none-any.whl (21.5MB)\n","\u001b[K     |████████████████████████████████| 21.5MB 158kB/s \n","\u001b[?25hCollecting natto-py; extra == \"all\"\n","  Downloading https://files.pythonhosted.org/packages/f1/14/1d4258247a00b7b8a115563effb1d0bd30501d69580629d36593ce0af92d/natto-py-0.9.2.tar.gz\n","Collecting kytea; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/bc/702d01a96d5d094bd9f3c2eb1d12153daf8edf7bf5d78b9a2dae1202df07/kytea-0.1.4-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 30.9MB/s \n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->flair) (6.2.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.4.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.1.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.1.3)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.7.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.7.5)\n","Collecting prompt-toolkit<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/61/2dfea88583d5454e3a64f9308a686071d58d59a55db638268a6413e1eb6d/prompt_toolkit-2.0.10-py3-none-any.whl (340kB)\n","\u001b[K     |████████████████████████████████| 348kB 44.2MB/s \n","\u001b[?25hRequirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.15.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.3.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.2.1)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (1.13.47)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.9.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (0.14.1)\n","Collecting dartsclone~=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/7d/4d/45acbe9d0795d8ceef0fee1f9ac2dcbf27dca3a0578a023fcdc3fef6fd89/dartsclone-0.6.tar.gz\n","Requirement already satisfied: sortedcontainers~=2.1.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (2.1.0)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (1.13.2)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.8)\n","Requirement already satisfied: parso>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.5.2)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers>=2.0.0->flair) (0.15.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from dartsclone~=0.6.0->SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (0.29.14)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (2.19)\n","Building wheels for collected packages: langdetect, segtok, sqlitedict, mpld3, sacremoses, SudachiDict-core, natto-py, dartsclone\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=65bda05c34cc4f7d2803f6893027a63e2645e041b68e14522d5c50dedfda6109\n","  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=a6068dca9b07d0d23c5b2578cd91ef376e73852632a166e378c7b110177d5e19\n","  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=db59b3364116b169a671b96c7c5deb471b6d402d4b0645175eef90fb39422521\n","  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=787a055e5a4ff87af3e8b3181f09441fbba207b4b392baa00e0a0b7d410c92ed\n","  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=a9bc6ff7947fee6ea9cb980e90406dbce3648c3047162a4fd6e55e8e9c6fca29\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","  Building wheel for SudachiDict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for SudachiDict-core: filename=SudachiDict_core-20190927-cp36-none-any.whl size=70878518 sha256=928042bfce672ea42c8ee0a4c92767c51249df8109d969ad92eeb9979adfd8fd\n","  Stored in directory: /root/.cache/pip/wheels/22/d8/6e/b107d7fef6e80915aa1e46db741b98a3da011f567526347ccc\n","  Building wheel for natto-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for natto-py: filename=natto_py-0.9.2-cp36-none-any.whl size=45164 sha256=b575b15b9aef2c24bc8e25450742d03fcbf00a323ecc3ac97ccd477615c70910\n","  Stored in directory: /root/.cache/pip/wheels/ce/51/dd/67f87608b124a23eecf5c1fc3557cc0b7ffdeae33fe6ee89df\n","  Building wheel for dartsclone (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dartsclone: filename=dartsclone-0.6-cp36-cp36m-linux_x86_64.whl size=413251 sha256=4b52a1db155cf8b637be04577552e255282764ba767ae7c523150b48026fbe49\n","  Stored in directory: /root/.cache/pip/wheels/be/cd/70/fe43307bf7398243155108f4f5a258ef336923d65ec4af93cd\n","Successfully built langdetect segtok sqlitedict mpld3 sacremoses SudachiDict-core natto-py dartsclone\n","\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.6.1 which is incompatible.\u001b[0m\n","Installing collected packages: sentencepiece, bpemb, sacremoses, transformers, langdetect, segtok, deprecated, sqlitedict, prompt-toolkit, ipython, mpld3, flair, dartsclone, SudachiPy, SudachiDict-core, janome, natto-py, kytea\n","  Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","Successfully installed SudachiDict-core-20190927 SudachiPy-0.4.2 bpemb-0.3.0 dartsclone-0.6 deprecated-1.2.7 flair-0.4.4 ipython-7.6.1 janome-0.3.10 kytea-0.1.4 langdetect-1.0.7 mpld3-0.3 natto-py-0.9.2 prompt-toolkit-2.0.10 sacremoses-0.0.38 segtok-1.5.7 sentencepiece-0.1.85 sqlitedict-1.6.0 transformers-2.3.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"_yDXCBmqtkPl","colab_type":"text"},"source":["#### ELMo"]},{"cell_type":"code","metadata":{"id":"iVZ4xx34vSmd","colab_type":"code","colab":{}},"source":["! pip install allennlp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uNDAZuOvt4wR","colab_type":"code","outputId":"306e7fb8-db28-4628-ea6e-c06cc0ae1183","executionInfo":{"status":"ok","timestamp":1578491395630,"user_tz":-180,"elapsed":142869,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from flair.embeddings import ELMoEmbeddings\n","\n","# init embedding\n","embedding = ELMoEmbeddings('medium')\n","\n","# create a sentence #\n","sentence = Sentence('test sent')\n","# embed words in sentence #\n","embedding.embed(sentence)\n","embedding_len = sentence[0].embedding.size()[0]\n","print('embedding len', embedding_len)\n","\n","\n","def get_comment_emb(comment):\n","  sentence = Sentence(comment)\n","  embedding.embed(sentence)\n","  emb_list = []\n","  for word in sentence:\n","    emb_list.append(word.embedding)\n","  return emb_list\n","\n","get_comment_emb_vec = np.vectorize(get_comment_emb)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["embedding len 1536\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FFD8Xd565HgQ","colab_type":"code","outputId":"aaea15ab-6a6f-4f01-c47f-7d111ebd707c","executionInfo":{"status":"ok","timestamp":1578491577805,"user_tz":-180,"elapsed":323293,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["for word, i in tqdm(word_index.items(), total=len(word_index)):\n","    if i >= max_tokens:\n","        continue\n","    try:\n","        word_sent = Sentence(word)\n","        embedding.embed(word_sent)\n","        embedding_vector = word_sent[0].embedding.cpu().detach().numpy()\n","        if (embedding_vector is not None) and len(embedding_vector) > 0:\n","           embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","        pass\n","        #embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 184924/184924 [03:02<00:00, 1014.44it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"F6tfsIpFJ6YG","colab_type":"code","outputId":"c515518f-a7ce-4831-cf0e-713070b8baf6","executionInfo":{"status":"ok","timestamp":1578491578061,"user_tz":-180,"elapsed":322746,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["del embedding\n","gc.collect()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["648"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"5I7VZVVF69Fh","colab_type":"code","colab":{}},"source":["# # creating a tensor for storing sentence embeddings #\n","# s = torch.zeros(0, embedding_len)\n","\n","# # iterating Sentence (tqdm tracks progress) #\n","# for tweet in tqdm(preprocessed_train[10]):   \n","#   # empty tensor for words #\n","#   w = torch.zeros(0, embedding_len)   \n","#   sentence = Sentence(tweet)\n","#   embedding.embed(sentence)\n","#   # for every word #\n","#   for token in sentence:\n","#     # storing word Embeddings of each word in a sentence #\n","#     w = torch.cat((w,token.embedding.view(-1, embedding_len)),0)\n","#   # storing sentence Embeddings (mean of embeddings of all words)   #\n","#   s = torch.cat((s, w.mean(dim = 0).view(-1, embedding_len)),0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hTlPvNY8gi1","colab_type":"text"},"source":["#### RoBERTa"]},{"cell_type":"code","metadata":{"id":"1gEnMtmwooBE","colab_type":"code","colab":{}},"source":["from flair.embeddings import RoBERTaEmbeddings"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvXWeyYWo0J9","colab_type":"code","outputId":"0c27d2a0-5e69-4428-fed4-20262dc73bc8","executionInfo":{"status":"ok","timestamp":1578511279777,"user_tz":-180,"elapsed":21711,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# init embedding\n","embedding = RoBERTaEmbeddings('roberta-base')\n","\n","# create a sentence #\n","sentence = Sentence('test sent')\n","# embed words in sentence #\n","embedding.embed(sentence)\n","embedding_len = sentence[0].embedding.size()[0]\n","print('embedding len', embedding_len)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["embedding len 768\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sDdLhAjJqY-G","colab_type":"code","outputId":"5cf088ff-3fd9-4e44-f690-e37eb45c37db","executionInfo":{"status":"ok","timestamp":1578511713577,"user_tz":-180,"elapsed":392563,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["for word, i in tqdm(word_index.items(), total=len(word_index)):\n","    if i >= max_tokens:\n","        continue\n","    try:\n","        word_sent = Sentence(word)\n","        embedding.embed(word_sent)\n","        embedding_vector = word_sent[0].embedding.cpu().detach().numpy()\n","        if (embedding_vector is not None) and len(embedding_vector) > 0:\n","           embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","        pass\n","        #embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n","\n","del embedding\n","gc.collect()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 184924/184924 [04:29<00:00, 685.45it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["648"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"McJb1Sn5tw4a","colab_type":"text"},"source":["#### RoBERTa + ELMo"]},{"cell_type":"code","metadata":{"id":"ztnGoOlrt3PR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d20a26ac-4b11-4470-f2c1-c6aa75777e4e","executionInfo":{"status":"ok","timestamp":1578587769320,"user_tz":-180,"elapsed":150843,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["! pip install allennlp\n","from flair.embeddings import StackedEmbeddings, RoBERTaEmbeddings, ELMoEmbeddings"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Collecting allennlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/bb/041115d8bad1447080e5d1e30097c95e4b66e36074277afce8620a61cee3/allennlp-0.9.0-py3-none-any.whl (7.6MB)\n","\u001b[K     |████████████████████████████████| 7.6MB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n","Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.17.5)\n","Collecting ftfy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n","\u001b[?25hCollecting responses>=0.7\n","  Downloading https://files.pythonhosted.org/packages/3e/0c/940781dd49710f4b1f0650c450c9fd8491db0e1bffd99ebc36355607f96d/responses-0.10.9-py2.py3-none-any.whl\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.1)\n","Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n","Collecting word2number>=1.1\n","  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n","Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n","Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.10.47)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n","Collecting parsimonious>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n","\u001b[?25hCollecting tensorboardX>=1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 41.9MB/s \n","\u001b[?25hCollecting pytorch-transformers==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n","\u001b[K     |████████████████████████████████| 163kB 47.1MB/s \n","\u001b[?25hCollecting jsonnet>=0.10.0; sys_platform != \"win32\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/a6/e69e38f1f259fcf8532d8bd2c4bc88764f42d7b35a41423a7f4b035cc5ce/jsonnet-0.14.0.tar.gz (253kB)\n","\u001b[K     |████████████████████████████████| 256kB 48.1MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n","Collecting jsonpickle\n","  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n","Collecting numpydoc>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/b0/70/4d8c3f9f6783a57ac9cc7a076e5610c0cc4a96af543cafc9247ac307fbfe/numpydoc-0.9.2.tar.gz\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.1.2)\n","Collecting flaky\n","  Downloading https://files.pythonhosted.org/packages/fe/12/0f169abf1aa07c7edef4855cca53703d2e6b7ecbded7829588ac7e7e3424/flaky-3.6.1-py2.py3-none-any.whl\n","Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.1)\n","Collecting flask-cors>=3.0.7\n","  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n","Collecting conllu==1.3.1\n","  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n","Collecting pytorch-pretrained-bert>=0.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 38.7MB/s \n","\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n","Collecting overrides\n","  Downloading https://files.pythonhosted.org/packages/72/dd/ac49f9c69540d7e09210415801a05d0a54d4d0ca8401503c46847dacd3a0/overrides-2.8.0.tar.gz\n","Requirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1.9)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (0.16.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (2.10.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from responses>=0.7->allennlp) (1.12.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.14.1)\n","Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (42.0.2)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.0.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.13.47)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.2.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (0.1.85)\n","Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.6.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n","Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.4)\n","Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.1)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.9.6)\n","Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.6.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.3)\n","Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (7.0.8)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask>=1.0.2->allennlp) (1.1.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->allennlp) (0.15.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (20.0)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.2)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.0)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.8.0)\n","Building wheels for collected packages: ftfy, word2number, parsimonious, jsonnet, numpydoc, overrides\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-5.6-cp36-none-any.whl size=44553 sha256=b3f980b1fa21ef09cecc9e11b86fe9a70ffd3ce8448c576fadc74ee72bcfd97f\n","  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=28ef29c36fdd8ada185944a4c0dc5264fbbbe9202de28e2954fc039017f7b635\n","  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n","  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42709 sha256=448d20658f75e6f658555ee6c219b1c006213f4b617544335b85e72d23654059\n","  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.14.0-cp36-cp36m-linux_x86_64.whl size=3320372 sha256=c85b78a65b540f712775637c8f9b20a6e4d304eda65425ec35037bad5f5baf61\n","  Stored in directory: /root/.cache/pip/wheels/5b/b7/83/985f0f758fbb34f14989a0fab86d18890d1cc5ae12f26967bc\n","  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for numpydoc: filename=numpydoc-0.9.2-cp36-none-any.whl size=31894 sha256=140aa1e238894e0fc10d79080dae24d93ec34781422e903e9205cd2ee2833a37\n","  Stored in directory: /root/.cache/pip/wheels/96/f3/52/25c8e1f40637661d27feebc61dae16b84c7cdd93b8bc3d7486\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-2.8.0-cp36-none-any.whl size=5608 sha256=10d6b5578d374574d2b98becf970ce6a88324bc3213a3ed2144d0b0efe0e1ae4\n","  Stored in directory: /root/.cache/pip/wheels/df/f1/ba/eaf6cd7d284d2f257dc71436ce72d25fd3be5a5813a37794ab\n","Successfully built ftfy word2number parsimonious jsonnet numpydoc overrides\n","Installing collected packages: ftfy, responses, word2number, parsimonious, tensorboardX, pytorch-transformers, jsonnet, jsonpickle, numpydoc, flaky, flask-cors, conllu, pytorch-pretrained-bert, overrides, allennlp\n","Successfully installed allennlp-0.9.0 conllu-1.3.1 flaky-3.6.1 flask-cors-3.0.8 ftfy-5.6 jsonnet-0.14.0 jsonpickle-1.2 numpydoc-0.9.2 overrides-2.8.0 parsimonious-0.8.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.10.9 tensorboardX-2.0 word2number-1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6_4YEiP1t5-n","colab_type":"code","outputId":"7009dff1-41c1-45be-b19b-bae803e40e0c","executionInfo":{"status":"ok","timestamp":1578587804825,"user_tz":-180,"elapsed":186330,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["elmo_embeddings = ELMoEmbeddings('small')\n","roberta_embeddings = RoBERTaEmbeddings('roberta-base')\n","stacked_embeddings = StackedEmbeddings([\n","                                        elmo_embeddings,\n","                                        roberta_embeddings,\n","                                       ])\n","\n","# create a sentence #\n","sentence = Sentence('test sent')\n","# embed words in sentence #\n","stacked_embeddings.embed(sentence)\n","embedding_len = sentence[0].embedding.size()[0]\n","print('embedding len', embedding_len)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["100%|██████████| 336/336 [00:00<00:00, 742511.14B/s]\n","100%|██████████| 54402456/54402456 [00:02<00:00, 20212502.71B/s]\n"],"name":"stderr"},{"output_type":"stream","text":["embedding len 1536\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MJNcWzMduAtb","colab_type":"code","outputId":"c878817b-90ae-40ce-a383-cd2934362b5d","executionInfo":{"status":"ok","timestamp":1578588513549,"user_tz":-180,"elapsed":895038,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["for word, i in tqdm(word_index.items(), total=len(word_index)):\n","    if i >= max_tokens:\n","        continue\n","    try:\n","        word_sent = Sentence(word)\n","        stacked_embeddings.embed(word_sent)\n","        embedding_vector = word_sent[0].embedding.cpu().detach().numpy()\n","        if (embedding_vector is not None) and len(embedding_vector) > 0:\n","           embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","        pass\n","        #embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["100%|██████████| 184924/184924 [11:48<00:00, 260.89it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"aMl76miAyRyI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3f1eae01-4bf3-4e00-ec66-7ec4bf4c2c87","executionInfo":{"status":"ok","timestamp":1578588513782,"user_tz":-180,"elapsed":895258,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["del stacked_embeddings\n","gc.collect()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["549"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"eyxmTYb4Q2dp","colab_type":"text"},"source":["### BERT fine-tuned"]},{"cell_type":"code","metadata":{"id":"CE-uRZUmQ4d9","colab_type":"code","colab":{}},"source":["import tensorflow_hub as hub"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahIw1Ve5RilL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"cadbba34-545e-43b6-8740-1a11063e5e67","executionInfo":{"status":"ok","timestamp":1578589849460,"user_tz":-180,"elapsed":4771,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["#Installing BERT module\n","!pip install bert-tensorflow"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Collecting bert-tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n","\r\u001b[K     |████▉                           | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.2MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jpD98b1FRnvd","colab_type":"code","colab":{}},"source":["#Importing BERT modules\n","import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dP_DlOkSZkx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"99bbc1cc-091f-4252-e7ce-a0ec2adc2b53","executionInfo":{"status":"ok","timestamp":1578590114436,"user_tz":-180,"elapsed":572,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["OUTPUT_DIR = os.path.join(homework_folder, 'bert_output')\n","tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["***** Model output directory: /content/drive/My Drive/Advanced NLP/Homework 1: Classical classification task like Kaggle Toxic or Quora/bert_output *****\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BKbCft6OYhKW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e493dc83-5fe2-4ee2-9696-680af6ef7134","executionInfo":{"status":"ok","timestamp":1578592171495,"user_tz":-180,"elapsed":731,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["preprocessed_train.shape"],"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(159571,)"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"Qd5R-lyxbbgM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d87d0a3c-86bb-4a31-b206-ccf6f2b4e4e9","executionInfo":{"status":"ok","timestamp":1578592244231,"user_tz":-180,"elapsed":572,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["preprocessed_train.reshape((preprocessed_train.shape[0],1))"],"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(159571, 1)"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"gWGhqqlhaBho","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"206260b1-f0ca-43c6-a719-2860dbb5fe7d","executionInfo":{"status":"ok","timestamp":1578592171497,"user_tz":-180,"elapsed":437,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["train_labels.shape"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(159571, 6)"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"0bbbJb2BaG06","colab_type":"code","colab":{}},"source":["np.hstack((preprocessed_train.reshape((preprocessed_train.shape[0],1)), train_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TK5jQCzjYyrV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"outputId":"2fd06809-edd3-40c7-aa50-37536d2b74e4","executionInfo":{"status":"ok","timestamp":1578591841260,"user_tz":-180,"elapsed":2919,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["pd.DataFrame({'preprocessed_train':preprocessed_train, 'train_labels': train_labels}, \n","             columns=['preprocessed_train'] + TARGET_COLS\n","             )"],"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preprocessed_train</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>explanation why edits made username hardcore m...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>d'aww ! he matches background colour i'm seemi...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>hey man , i'm really trying edit war . it's gu...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>more I can't make real suggestions improvement...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>you , sir , hero . any chance remember page th...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>159566</th>\n","      <td>and second time asking , view completely contr...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>159567</th>\n","      <td>you ashamed that horrible thing put talk page . .</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>159568</th>\n","      <td>spitzer umm , theres actual article prostituti...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>159569</th>\n","      <td>and looks like actually put speedy first versi...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>159570</th>\n","      <td>and I really think understand . I came idea ba...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>159571 rows × 7 columns</p>\n","</div>"],"text/plain":["                                       preprocessed_train  ... identity_hate\n","0       explanation why edits made username hardcore m...  ...           NaN\n","1       d'aww ! he matches background colour i'm seemi...  ...           NaN\n","2       hey man , i'm really trying edit war . it's gu...  ...           NaN\n","3       more I can't make real suggestions improvement...  ...           NaN\n","4       you , sir , hero . any chance remember page th...  ...           NaN\n","...                                                   ...  ...           ...\n","159566  and second time asking , view completely contr...  ...           NaN\n","159567  you ashamed that horrible thing put talk page . .  ...           NaN\n","159568  spitzer umm , theres actual article prostituti...  ...           NaN\n","159569  and looks like actually put speedy first versi...  ...           NaN\n","159570  and I really think understand . I came idea ba...  ...           NaN\n","\n","[159571 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"SMoU4oQJW8yi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"7a9fea7f-b218-47ae-a8ee-de73c9c882fb","executionInfo":{"status":"error","timestamp":1578591522886,"user_tz":-180,"elapsed":1190,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["preprocessed_train_with_labels = pd.concat([preprocessed_train, pd.DataFrame(train_labels, columns=TARGET_COLS)], axis=1)\n","preprocessed_train_with_labels"],"execution_count":50,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-cdbe0f7198ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocessed_train_with_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreprocessed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_COLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreprocessed_train_with_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    330\u001b[0m                     \u001b[0;34m\" only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 )\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"]}]},{"cell_type":"code","metadata":{"id":"WRZQwoHwXDmn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"194ede61-5534-4b5d-e15c-c1736905376d","executionInfo":{"status":"ok","timestamp":1578591080137,"user_tz":-180,"elapsed":622,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["train_labels"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0],\n","       ...,\n","       [0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"G5_wLERFT5EG","colab_type":"code","colab":{}},"source":["train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n","\n","val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AslnHsTy0gCQ","colab_type":"text"},"source":["## Build and fit the model"]},{"cell_type":"code","metadata":{"id":"0m6GDvsd3WRX","colab_type":"code","trusted":true,"outputId":"fdac63b2-b009-4c48-a5dd-127d8436cdfe","executionInfo":{"status":"ok","timestamp":1578588514003,"user_tz":-180,"elapsed":895465,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["x_train, x_valid, y_train, y_valid = train_test_split(tokenized_train, \n","                                                      train_labels, \n","                                                      test_size = 0.1,\n","                                                      shuffle=True)\n","\n","print('x_train shape:', x_train.shape)\n","print('x_valid shape:', x_valid.shape)\n","print('y_train shape:', y_train.shape)\n","print('y_valid shape:', y_valid.shape)\n","\n","del tokenized_train\n","gc.collect()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["x_train shape: (143613, 220)\n","x_valid shape: (15958, 220)\n","y_train shape: (143613, 6)\n","y_valid shape: (15958, 6)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"6306i8ha3TBF","colab_type":"code","trusted":true,"colab":{}},"source":["def build_model(embedding_matrix):\n","    words = Input(shape=(MAX_LEN,))\n","    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n","    #x = Input(batch_shape=(batch_size, max_comment_length, embedding_len))\n","    \n","    x = SpatialDropout1D(0.2)(x)\n","    x = Bidirectional(CuDNNGRU(LSTM_UNITS, return_sequences=True))(x)\n","    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n","\n","    hidden = concatenate([\n","        GlobalMaxPooling1D()(x),\n","        GlobalAveragePooling1D()(x),\n","    ])\n","    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n","    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n","    result = Dense(len(TARGET_COLS), activation='sigmoid')(hidden)\n","    \n","    \n","    model = Model(inputs=words, outputs=result)\n","    model.compile(loss='binary_crossentropy', optimizer='adam')\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HuPRFfOJf-tH","colab_type":"code","trusted":true,"colab":{}},"source":["# class RocAucEvaluation(Callback):\n","#     def __init__(self, validation_data=(), interval=1):\n","#         super(Callback, self).__init__()\n","\n","#         self.interval = interval\n","#         self.X_val, self.y_val = validation_data\n","\n","#     def on_epoch_end(self, epoch, logs={}):\n","#         if epoch % self.interval == 0:\n","#             y_pred = self.model.predict(self.X_val, verbose=0)\n","#             score = 0\n","#             for i in range(6):\n","#              score += roc_auc_score(self.y_val[:,i], y_pred[:,i])/6.\n","#             print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n","\n","# RocAuc_val = RocAucEvaluation(validation_data=(x_valid, y_valid), interval = 1)\n","\n","class RocAucEarlyStopping(Callback):\n","    \"\"\"Callback for early stopping based on roc auc on the validation set\"\"\"\n","\n","    def __init__(self, validation_data, patience=0, digits=3):\n","        super().__init__()\n","        self.X_val, self.y_val = validation_data\n","        self.best = 0\n","        self.patience = patience\n","        self.digits = digits\n","        self.current_patience = patience\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        y_pred = self.model.predict(self.X_val, verbose=0)\n","        score = 0\n","        for i in range(6):\n","          score += roc_auc_score(self.y_val[:,i], y_pred[:,i])/6.\n","\n","        score = round(score, self.digits)\n","        print(\"ROC-AUC - epoch: {:d} - score: {}\\n\".format(epoch+1, score))\n","\n","        # check digits\n","        if np.greater(score, self.best):\n","            self.best = score\n","            self.current_patience = self.patience\n","        else:\n","            print('\\nbest:{}\\ncurrent:{}'.format(self.best, score))\n","            self.current_patience -= 1\n","            if self.current_patience < 0:\n","              self.model.stop_training = True\n","              print('Early stopping due to lower roc auc')\n","              self.current_patience = self.patience\n","            else:\n","              print('{} patience remained'.format(self.current_patience))\n","\n","RocAuc_ES = RocAucEarlyStopping(validation_data=(x_valid, y_valid), patience=1, digits=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"TRvdcnky3TBH","colab_type":"code","outputId":"24f73e36-a368-4a42-fe8b-2bb0901d3766","executionInfo":{"status":"ok","timestamp":1578589642610,"user_tz":-180,"elapsed":2024040,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%time\n","\n","SEEDS = 2\n","pred = 0\n","\n","for ii in tqdm(range(SEEDS), total=SEEDS):\n","\n","    model = build_model(embedding_matrix)\n","    for global_epoch in range(GLOBAL_EPOCHS):\n","        print('\\nglobal_epoch', global_epoch)\n","\n","\n","        model.fit(\n","                    x_train,\n","                    y_train,\n","                    validation_data = (x_valid, y_valid),\n","                    batch_size=BATCH_SIZE,\n","                    epochs=EPOCHS,\n","                    verbose=1,\n","                    callbacks=[\n","                        LearningRateScheduler(lambda _: 1e-3 * (0.5 ** global_epoch)),\n","                        #RocAuc_val\n","                        RocAuc_ES\n","                    ]\n","                )\n","        print('fitted')    \n","\n","    pred += model.predict(tokenized_test, batch_size = 1024, verbose = 1)/SEEDS\n","    np.save('pred', pred)\n","    model.save_weights('model_weights_'+str(ii)+'.h5')\n","    os.system('gzip '+'model_weights_'+str(ii)+'.h5')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/2 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","\n","global_epoch 0\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 143613 samples, validate on 15958 samples\n","Epoch 1/5\n","143613/143613 [==============================] - 87s 605us/step - loss: 0.0700 - val_loss: 0.0497\n","ROC-AUC - epoch: 1 - score: 0.9787\n","\n","Epoch 2/5\n","143613/143613 [==============================] - 82s 569us/step - loss: 0.0473 - val_loss: 0.0446\n","ROC-AUC - epoch: 2 - score: 0.9856\n","\n","Epoch 3/5\n","143613/143613 [==============================] - 82s 569us/step - loss: 0.0429 - val_loss: 0.0445\n","ROC-AUC - epoch: 3 - score: 0.9868\n","\n","Epoch 4/5\n","143613/143613 [==============================] - 82s 568us/step - loss: 0.0402 - val_loss: 0.0428\n","ROC-AUC - epoch: 4 - score: 0.9879\n","\n","Epoch 5/5\n","143613/143613 [==============================] - 82s 569us/step - loss: 0.0382 - val_loss: 0.0447\n","ROC-AUC - epoch: 5 - score: 0.9881\n","\n","fitted\n","\n","global_epoch 1\n","Train on 143613 samples, validate on 15958 samples\n","Epoch 1/5\n","143613/143613 [==============================] - 82s 569us/step - loss: 0.0340 - val_loss: 0.0440\n","ROC-AUC - epoch: 1 - score: 0.9878\n","\n","\n","best:0.9881\n","current:0.9878\n","0 patience remained\n","Epoch 2/5\n","143613/143613 [==============================] - 82s 570us/step - loss: 0.0321 - val_loss: 0.0443\n","ROC-AUC - epoch: 2 - score: 0.9877\n","\n","\n","best:0.9881\n","current:0.9877\n","Early stopping due to lower roc auc\n","fitted\n","153164/153164 [==============================] - 33s 213us/step\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 1/2 [11:51<11:51, 711.77s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","global_epoch 0\n","Train on 143613 samples, validate on 15958 samples\n","Epoch 1/5\n","143613/143613 [==============================] - 82s 570us/step - loss: 0.0693 - val_loss: 0.0518\n","ROC-AUC - epoch: 1 - score: 0.98\n","\n","\n","best:0.9881\n","current:0.98\n","0 patience remained\n","Epoch 2/5\n","143613/143613 [==============================] - 81s 567us/step - loss: 0.0469 - val_loss: 0.0469\n","ROC-AUC - epoch: 2 - score: 0.9854\n","\n","\n","best:0.9881\n","current:0.9854\n","Early stopping due to lower roc auc\n","fitted\n","\n","global_epoch 1\n","Train on 143613 samples, validate on 15958 samples\n","Epoch 1/5\n","143613/143613 [==============================] - 81s 567us/step - loss: 0.0417 - val_loss: 0.0426\n","ROC-AUC - epoch: 1 - score: 0.9873\n","\n","\n","best:0.9881\n","current:0.9873\n","0 patience remained\n","Epoch 2/5\n","143613/143613 [==============================] - 81s 566us/step - loss: 0.0395 - val_loss: 0.0427\n","ROC-AUC - epoch: 2 - score: 0.9878\n","\n","\n","best:0.9881\n","current:0.9878\n","Early stopping due to lower roc auc\n","fitted\n","153164/153164 [==============================] - 33s 213us/step\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 2/2 [18:48<00:00, 623.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["CPU times: user 10min 36s, sys: 4min, total: 14min 36s\n","Wall time: 18min 48s\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ujanlBVs61IJ","colab_type":"text"},"source":["## Cheaty evaluating on test labels"]},{"cell_type":"code","metadata":{"id":"cIOGCjO11DrT","colab_type":"code","trusted":true,"colab":{}},"source":["submission = pd.read_csv(submission_path)\n","submission[TARGET_COLS] = (pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CCukoB8QB2Rz","colab_type":"code","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":359},"outputId":"3f589780-ac61-459f-d5ef-067a6170fdc5","executionInfo":{"status":"ok","timestamp":1578589643756,"user_tz":-180,"elapsed":2025164,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["submission.head(10)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00001cee341fdb12</td>\n","      <td>0.998985</td>\n","      <td>4.945387e-01</td>\n","      <td>0.987257</td>\n","      <td>0.097632</td>\n","      <td>0.974627</td>\n","      <td>0.440083</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0000247867823ef7</td>\n","      <td>0.007164</td>\n","      <td>2.753735e-05</td>\n","      <td>0.001133</td>\n","      <td>0.000093</td>\n","      <td>0.000974</td>\n","      <td>0.000146</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00013b17ad220c46</td>\n","      <td>0.007884</td>\n","      <td>1.225024e-04</td>\n","      <td>0.002532</td>\n","      <td>0.000309</td>\n","      <td>0.002714</td>\n","      <td>0.000617</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00017563c3f7919a</td>\n","      <td>0.000261</td>\n","      <td>8.791685e-07</td>\n","      <td>0.000062</td>\n","      <td>0.000005</td>\n","      <td>0.000044</td>\n","      <td>0.000008</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00017695ad8997eb</td>\n","      <td>0.007049</td>\n","      <td>2.688169e-05</td>\n","      <td>0.001406</td>\n","      <td>0.000199</td>\n","      <td>0.000862</td>\n","      <td>0.000122</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0001ea8717f6de06</td>\n","      <td>0.000263</td>\n","      <td>5.960464e-07</td>\n","      <td>0.000046</td>\n","      <td>0.000005</td>\n","      <td>0.000044</td>\n","      <td>0.000006</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>00024115d4cbde0f</td>\n","      <td>0.002175</td>\n","      <td>3.531575e-06</td>\n","      <td>0.000255</td>\n","      <td>0.000021</td>\n","      <td>0.000245</td>\n","      <td>0.000028</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>000247e83dcc1211</td>\n","      <td>0.594126</td>\n","      <td>4.024178e-03</td>\n","      <td>0.067739</td>\n","      <td>0.007929</td>\n","      <td>0.081680</td>\n","      <td>0.004874</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>00025358d4737918</td>\n","      <td>0.117647</td>\n","      <td>1.052022e-04</td>\n","      <td>0.007950</td>\n","      <td>0.000294</td>\n","      <td>0.020561</td>\n","      <td>0.001072</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>00026d1092fe71cc</td>\n","      <td>0.001731</td>\n","      <td>6.213784e-06</td>\n","      <td>0.000261</td>\n","      <td>0.000031</td>\n","      <td>0.000221</td>\n","      <td>0.000039</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id     toxic  severe_toxic  ...    threat    insult  identity_hate\n","0  00001cee341fdb12  0.998985  4.945387e-01  ...  0.097632  0.974627       0.440083\n","1  0000247867823ef7  0.007164  2.753735e-05  ...  0.000093  0.000974       0.000146\n","2  00013b17ad220c46  0.007884  1.225024e-04  ...  0.000309  0.002714       0.000617\n","3  00017563c3f7919a  0.000261  8.791685e-07  ...  0.000005  0.000044       0.000008\n","4  00017695ad8997eb  0.007049  2.688169e-05  ...  0.000199  0.000862       0.000122\n","5  0001ea8717f6de06  0.000263  5.960464e-07  ...  0.000005  0.000044       0.000006\n","6  00024115d4cbde0f  0.002175  3.531575e-06  ...  0.000021  0.000245       0.000028\n","7  000247e83dcc1211  0.594126  4.024178e-03  ...  0.007929  0.081680       0.004874\n","8  00025358d4737918  0.117647  1.052022e-04  ...  0.000294  0.020561       0.001072\n","9  00026d1092fe71cc  0.001731  6.213784e-06  ...  0.000031  0.000221       0.000039\n","\n","[10 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"YUF4Uxrl8pXr","colab_type":"code","trusted":true,"colab":{}},"source":["# labels for the test data; value of -1 indicates it was not used for scoring; (Note: file added after competition close!)\n","test_labels_df = pd.read_csv(test_labels_filepath)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6crgLcLx7X-p","colab_type":"code","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5970545a-b755-49b4-a855-84c23902e39b","executionInfo":{"status":"ok","timestamp":1578589645434,"user_tz":-180,"elapsed":2026834,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["test_labels_df = test_labels_df[(test_labels_df[\"toxic\"] != -1) &\n","                                (test_labels_df[\"severe_toxic\"] != -1) &\n","                                (test_labels_df[\"obscene\"] != -1) &\n","                                (test_labels_df[\"threat\"] != -1) &\n","                                (test_labels_df[\"insult\"] != -1) &\n","                                (test_labels_df[\"identity_hate\"] != -1)]\n","test_labels_df.shape                               "],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(63978, 7)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"-ymumFOQ9sA1","colab_type":"code","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b17e62bd-a222-40dd-b4f9-ce21078f2d70","executionInfo":{"status":"ok","timestamp":1578589645435,"user_tz":-180,"elapsed":2026831,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["submission_to_evaluate = submission[submission['id'].isin(test_labels_df['id'].values)]\n","submission_to_evaluate.shape"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(63978, 7)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"C3r8VTCK_TaM","colab_type":"code","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"c282089b-22a1-49d9-f3f4-f288a67e664f","executionInfo":{"status":"ok","timestamp":1578589645642,"user_tz":-180,"elapsed":2027035,"user":{"displayName":"Олег Литвинов","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8rY4OprXFCt_FxC9zp02Jpl3SMZAtMJxOocMO=s64","userId":"10665736335049067601"}}},"source":["scores = []\n","for class_name in TARGET_COLS:\n","    train_target = test_labels_df[class_name]\n","    train_predicted = submission_to_evaluate[class_name]\n","\n","    cv_score = np.mean(roc_auc_score(train_target.values, train_predicted.values))\n","    scores.append(cv_score)\n","    print('CV score for class {} is {}'.format(class_name, cv_score))\n","\n","print('Total CV score is {}'.format(np.mean(scores)))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["CV score for class toxic is 0.967239853233377\n","CV score for class severe_toxic is 0.9892108184637406\n","CV score for class obscene is 0.9771303428007556\n","CV score for class threat is 0.991811197712763\n","CV score for class insult is 0.9751569740998813\n","CV score for class identity_hate is 0.9831161975458\n","Total CV score is 0.9806108973093862\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"YKsSnwkd3TBJ","colab_type":"code","colab":{}},"source":["submission.to_csv(os.path.join(data_folder,\"submission_bidirectional_GRU.csv\"), index = False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tNf0KsAHCSJB","colab_type":"text"},"source":["Жирный шрифт означает изменения в процессе валидации и оценивания и при изменении действует начиная со строчки указания и ниже\n","\n","glove twitter 200:  0.98052\n","\n","**С поднятием колва epochs и global_epochs + RocAucEarlyStopping** скор упал с 0.98052 до 0.97573\n","\n","GLOBAL_EPOCHS = 2, EPOCHS = 5, glove.840B.300d.txt   0.97994  \n","BPEmb(lang=\"en\", dim=25, vs=20000)   0.97375  \n","BPEmb(lang=\"en\", dim=300, vs=20000) without preprocessing   0.97699  \n","BPEmb(lang=\"en\", dim=300, vs=20000)   0.97865   \n","fasttext crawl-300d-2M-subword 0.95732  \n","BPEmb(lang=\"en\", dim=300, vs=20000) **Patience 2->1 SEEDS 1->1**  0.98041   \n","flair ELMoEmbeddings('small') embedding len 768  0.98005  \n","flair ELMoEmbeddings('medium') embedding len 1536  0.98038  \n","flair RoBERTaEmbeddings('roberta-base') embedding len 768  0.97413  \n","flair stack of ELMoEmbeddings('small') + RoBERTaEmbeddings('roberta-base') embedding len 1536  0.98069      \n"]}]}