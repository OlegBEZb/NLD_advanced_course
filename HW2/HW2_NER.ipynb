{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1. NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "384px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4a84f1c06b34227b75d128a51a82d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95fb0b243e234e989e5f166489e3bc88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fccf7ed036694d76b071e11d1179a492",
              "IPY_MODEL_d092bae32bdb48389c8b9c25df13d1a1"
            ]
          }
        },
        "95fb0b243e234e989e5f166489e3bc88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fccf7ed036694d76b071e11d1179a492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b6eab54021140d69405a6deedac5f9b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 8,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b8c015059d540a7b0780e7d78bb18c0"
          }
        },
        "d092bae32bdb48389c8b9c25df13d1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1eff841162c54139bfaf5ba8aedd08f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/8 [02:28&lt;00:00, 18.50s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40617a7d172a4536be5451cb810adafa"
          }
        },
        "5b6eab54021140d69405a6deedac5f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b8c015059d540a7b0780e7d78bb18c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1eff841162c54139bfaf5ba8aedd08f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40617a7d172a4536be5451cb810adafa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f45ce16602f54f3ba34d3e95afbca514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_023bd140826c4d7daa3576bd1a691033",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26e43c5b2e874934b0c7c4494a71494c",
              "IPY_MODEL_856486a7bef543e894694d65b869b1da"
            ]
          }
        },
        "023bd140826c4d7daa3576bd1a691033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26e43c5b2e874934b0c7c4494a71494c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a30bf3cfb5534b84932bb22b491d131f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a65114dca834a2bb32e23cac42cc27d"
          }
        },
        "856486a7bef543e894694d65b869b1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ba9e31825084b01be3c246ce85d674f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.73s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94ef18e73685457a99107a8f35a691fa"
          }
        },
        "a30bf3cfb5534b84932bb22b491d131f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a65114dca834a2bb32e23cac42cc27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ba9e31825084b01be3c246ce85d674f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94ef18e73685457a99107a8f35a691fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f656a91824324958a7ca8f8a22eb36fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03534413eeed48ea8e359ca1695a644f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3127767d1df49b5b2ba9bb345c9fa23",
              "IPY_MODEL_9f608d24e8984e7d928787c01e8bcd63"
            ]
          }
        },
        "03534413eeed48ea8e359ca1695a644f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3127767d1df49b5b2ba9bb345c9fa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f357ac82ef704829ac8a6308bd8c4b0f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcbf26ca360b49a5849428b4f82ea9cf"
          }
        },
        "9f608d24e8984e7d928787c01e8bcd63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19b8e6d8d4ce478582ac51f569dc414e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.65s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93c1e2c856004760910461e1c1eaa81f"
          }
        },
        "f357ac82ef704829ac8a6308bd8c4b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcbf26ca360b49a5849428b4f82ea9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19b8e6d8d4ce478582ac51f569dc414e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93c1e2c856004760910461e1c1eaa81f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c762f72c0d74610971f14419eb1f77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e25ec04478248e89547194e43865bbb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_258a1f291fde4a40829cb581e10da680",
              "IPY_MODEL_82c5f91a9d10441ba2ae035eb9de2936"
            ]
          }
        },
        "2e25ec04478248e89547194e43865bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "258a1f291fde4a40829cb581e10da680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9ec6e1dcb984412bfb75bc16850cadf",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da7bf79f5d4a49299f0d0c9970a62e9b"
          }
        },
        "82c5f91a9d10441ba2ae035eb9de2936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f247b1d89fc457eb87ec1a18eb30be4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.70s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca79a346472743068eb779252473c487"
          }
        },
        "e9ec6e1dcb984412bfb75bc16850cadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da7bf79f5d4a49299f0d0c9970a62e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f247b1d89fc457eb87ec1a18eb30be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca79a346472743068eb779252473c487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ef95639863848f586957fa4823e5da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_941e276d3b124f8e8f6d6451edd9f4d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09e6562e30ff41a58c2dcd06089b1529",
              "IPY_MODEL_4c6fbe7617844969a03f099c6cf329f3"
            ]
          }
        },
        "941e276d3b124f8e8f6d6451edd9f4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09e6562e30ff41a58c2dcd06089b1529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3a33c390c5a4581bac946a16fa1eb9e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_415762ee983b44bdba02e9c3f62f59fa"
          }
        },
        "4c6fbe7617844969a03f099c6cf329f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b50024e4380498693d9c73e1ed61010",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.65s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f1fdfe150cf49d38178680dd1428ec4"
          }
        },
        "c3a33c390c5a4581bac946a16fa1eb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "415762ee983b44bdba02e9c3f62f59fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b50024e4380498693d9c73e1ed61010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f1fdfe150cf49d38178680dd1428ec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd85ee4310054709aa8c856a2e53419d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9bdacedde394392a26acc7aff38792e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5bc090a8379b4cd6b97132dbceb1f09e",
              "IPY_MODEL_7340797a41284319b19537f7fd03f5f5"
            ]
          }
        },
        "a9bdacedde394392a26acc7aff38792e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bc090a8379b4cd6b97132dbceb1f09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b071173e66bf4adcb618d0bd6a2a1413",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_506f8fbe830b40b787b2a192ac7e1343"
          }
        },
        "7340797a41284319b19537f7fd03f5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93c9a83ceb654e00bb90981a8f0c1f5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.72s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d15bd90075f741138938b5aaa54319a2"
          }
        },
        "b071173e66bf4adcb618d0bd6a2a1413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "506f8fbe830b40b787b2a192ac7e1343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93c9a83ceb654e00bb90981a8f0c1f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d15bd90075f741138938b5aaa54319a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ffde3a620b04824a654d45a691a79ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e6b3b99f72d4a37af3779a308a7a04c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d0c85b3844847129b622807d516f3f0",
              "IPY_MODEL_00b9587b903e41cb84180009bd409df9"
            ]
          }
        },
        "7e6b3b99f72d4a37af3779a308a7a04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d0c85b3844847129b622807d516f3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a52761a5d5e4fac98121e01fb376fd5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_510186523d2544f6a2aff4376e2387e3"
          }
        },
        "00b9587b903e41cb84180009bd409df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92609aa187a9427493e2afe938f0c528",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.65s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7a5845caf60444389c56007f48631b9"
          }
        },
        "1a52761a5d5e4fac98121e01fb376fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "510186523d2544f6a2aff4376e2387e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92609aa187a9427493e2afe938f0c528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7a5845caf60444389c56007f48631b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf55f18efc6748cb8a0b954fc02a3fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8f241b5c3d74f4da440208e8c21b066",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5520c24070a409e899d40bab89eb22f",
              "IPY_MODEL_810f5040b3c348cd8b0c3e34dccb7895"
            ]
          }
        },
        "d8f241b5c3d74f4da440208e8c21b066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5520c24070a409e899d40bab89eb22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_551d39b97c96417d818b3cf2615e7777",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eaf12f3480934de994f71a09006ccb2f"
          }
        },
        "810f5040b3c348cd8b0c3e34dccb7895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d94082cab95d4868a4236f81e429d44b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.68s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db4359d585bc4157b3beea372b160458"
          }
        },
        "551d39b97c96417d818b3cf2615e7777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eaf12f3480934de994f71a09006ccb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d94082cab95d4868a4236f81e429d44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db4359d585bc4157b3beea372b160458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acbbe65d0025430d901ebc72ff226a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1522f8813be74dd1a4c9a7f814f80f00",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_730c83053c964a80b8bbe6e0a17a1078",
              "IPY_MODEL_eb07ca7501504304ba77f3562ba1e786"
            ]
          }
        },
        "1522f8813be74dd1a4c9a7f814f80f00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "730c83053c964a80b8bbe6e0a17a1078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_507719b20a9d4132bed5a478413ff1f5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee87667c7eeb4b449bc8f73c3922f166"
          }
        },
        "eb07ca7501504304ba77f3562ba1e786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_23036e6b27d546bc8a262b6228dcb35c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.63s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd184f0c8f7c44da85298b9c2ca47a19"
          }
        },
        "507719b20a9d4132bed5a478413ff1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee87667c7eeb4b449bc8f73c3922f166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23036e6b27d546bc8a262b6228dcb35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd184f0c8f7c44da85298b9c2ca47a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlegBEZb/NLP_advanced_course/blob/master/HW2/HW2_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "KVRaU_zG-PaI"
      },
      "source": [
        "# About notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "gjCnYYETSLxd"
      },
      "source": [
        "Dataset\n",
        "*\tGroningen Meaning Bank (version 2.2.0)\n",
        "*\tTask: named entity recognition\n",
        "*\tTarget – named entity tags (BIO + entity type)\n",
        "*\tInput data: \n",
        "  * Use “en.met” files to extract the subcorpus\n",
        "  corpus = 'Voice of America' (for honogeneity of the input data set)\n",
        "  * Use \"en.tags\" files for the main input data:\n",
        "      *\traw tokens + may use the lemmas and the POS-tags \n",
        "  (i.e. take the “golden” POS-tagging);\n",
        "      *\twhich means:\n",
        "        *\tfirst three columns for input: ['word', 'pos', 'lemma']\n",
        "        *\tthe fourth column for target variable (‘ne_tags’)\n",
        "        (BIO annotation + the named-entity type in one tag)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K5QmPxPgSLxf"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pK9ZLcizSLxg"
      },
      "source": [
        "1.\tThe most trivial model = supervised HMM:\n",
        "  *\tTake hmmlearn (former sklearn), modify MultinomialHMM (I.e. inherit a new class from _BaseHMM making it a modified copy of the latter) to allow for supervised HMM training. The states of the HMM model = the NE tags.\n",
        "  *\tNOTE: may use NaiveBayes to learn emission probabilities in a supervized manner.\n",
        "  *\tOr implement from scratch (with Viterbi for prediction).\n",
        "  *\tNOTE: use tuples of features for X (not just the word, but additional info).\n",
        "  *\tNOTE: use smoothing for state transitions.\n",
        "2.\tCRF\n",
        "  *\tModify the input features;\n",
        "  *\tUse CRFSuite.\n",
        "3.\tBi-LSTM:\n",
        "  *\tUse keras or tensorflow;\n",
        "  *\thttps://github.com/hse-aml/natural-language-processing/blob/master/week2/week2-NER.ipynb\n",
        "  *\tA plus for incorporating CNN-layers;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9jHB1yCYSLxh"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uqBWS_YOSLxi"
      },
      "source": [
        "* normalized confusion matrices, precision, recall, F-score \n",
        "(macro- and micro-) \n",
        "* (token level, entity level, partial matching (i.e. boundary-detection problem), binary).  \n",
        "NOTE: taking into account vocabulary transfer is a plus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9JfSarnSLxk",
        "colab_type": "text"
      },
      "source": [
        "http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/  \n",
        "http://larsmans.github.io/seqlearn/reference.html#module-seqlearn.datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "x0bjDrHYSLxm"
      },
      "source": [
        "# Evaluation Criteria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "8mJvCwaRSLxo"
      },
      "source": [
        "Scoring (14.5 max):  \n",
        "*\tDataset overview – 0.5\n",
        "  *\ttext lengths, vocabulary size, frequencies of patterns (<UNK-type-i>) \n",
        "  *\tstats over the target tags\n",
        "*\tFeature engineering – 2 (1+1)\n",
        "  *\tgrammatical words = closed set (~ stop words)\n",
        "  *\tStemming + POS\n",
        "  *\tWord shape\n",
        "  *\tAd hoc features ( +1)  \n",
        "*\tWord patterns -> encode types of unknown words +0.5\n",
        "*\tSmoothing in HMM – 0.5 \n",
        "  *\tIn HMM: for state transitions.\n",
        "*\tIncorporating tupled features in HMM (on top of tokens) – 1\n",
        "*\tThe correct HMM implementation – 1\n",
        "*\tMore fine-grained feature engineering for the Neural Network + 0.5\n",
        "  *\tDifferentiate between POS-relevancy for the word and the context, etc.\n",
        "  *\tSentence-level features (may use “golden” sentence-splitting)\n",
        "*\tEvaluation (on all levels) – 1\n",
        "*\tConclusion on HMM deficiency (as a model) – 1\n",
        "*\tCRF: 1 point for use and evaluation, + 0.5 points for comparison and conclusions;\n",
        "*\tNN:\n",
        "  *\tMain network: 4\n",
        "  *\tCNN layers: +2  \n",
        "\n",
        "Libraries: hmmlearn, crfsuite, tensorflow, keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "30D0Scxk4kn3"
      },
      "source": [
        "# Libs import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUftFhCTmV_w",
        "colab_type": "text"
      },
      "source": [
        "## Downloading, upgrading libs, fixing bugs in seqlearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8MF1D8wS7dO",
        "colab_type": "code",
        "outputId": "7b523e6f-abbf-46f3-8e4f-0a2142ddd1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "!pip install sklearn-crfsuite\n",
        "!pip install -U scipy\n",
        "!pip install seqlearn\n",
        "!pip install seqeval\n",
        "!pip install hmmlearn==0.2.2"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.12.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Requirement already up-to-date: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.2)\n",
            "Requirement already satisfied: seqlearn in /usr/local/lib/python3.6/dist-packages (0.2)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: hmmlearn==0.2.2 in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn==0.2.2) (1.18.2)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn==0.2.2) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn==0.2.2) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn==0.2.2) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU9D7GLjmvut",
        "colab_type": "text"
      },
      "source": [
        "There is unsolved issue https://github.com/larsmans/seqlearn/issues/45  \n",
        "And there is no opportunity to use lower version of scipy because of other dependencies  \n",
        "Also there is a [bug](https://github.com/larsmans/seqlearn/pull/29) with calculating final probabilities which is fixed below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur3f4jJ4kinE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm /usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoLpi_3vkjmP",
        "colab_type": "code",
        "outputId": "6dfe4b0e-27ac-4842-97b9-7a4f610aca44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile /usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py\n",
        "\n",
        "\"\"\"Hidden Markov models (HMMs) with supervised training.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "#from scipy.misc import logsumexp\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "from .base import BaseSequenceClassifier\n",
        "from ._utils import atleast2d_or_csr, count_trans, safe_sparse_dot\n",
        "\n",
        "\n",
        "class MultinomialHMM(BaseSequenceClassifier):\n",
        "    \"\"\"First-order hidden Markov model with multinomial event model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    decode : string, optional\n",
        "        Decoding algorithm, either \"bestfirst\" or \"viterbi\" (default).\n",
        "        Best-first decoding is also called posterior decoding in the HMM\n",
        "        literature.\n",
        "\n",
        "    alpha : float\n",
        "        Lidstone (additive) smoothing parameter.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, decode=\"viterbi\", alpha=.01):\n",
        "        self.alpha = alpha\n",
        "        self.decode = decode\n",
        "\n",
        "    def fit(self, X, y, lengths):\n",
        "        \"\"\"Fit HMM model to data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "\n",
        "        y : array-like, shape (n_samples,)\n",
        "            Target labels.\n",
        "\n",
        "        lengths : array-like of integers, shape (n_sequences,)\n",
        "            Lengths of the individual sequences in X, y. The sum of these\n",
        "            should be n_samples.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        Make sure the training set (X) is one-hot encoded; if more than one\n",
        "        feature in X is on, the emission probabilities will be multiplied.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : MultinomialHMM\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.alpha\n",
        "        if alpha <= 0:\n",
        "            raise ValueError(\"alpha should be >0, got {0!r}\".format(alpha))\n",
        "\n",
        "        X = atleast2d_or_csr(X)\n",
        "        classes, y = np.unique(y, return_inverse=True)\n",
        "        lengths = np.asarray(lengths)\n",
        "        Y = y.reshape(-1, 1) == np.arange(len(classes))\n",
        "\n",
        "        end = np.cumsum(lengths)\n",
        "        start = end - lengths\n",
        "\n",
        "        init_prob = np.log(Y[start].sum(axis=0) + alpha)\n",
        "        init_prob -= logsumexp(init_prob)\n",
        "        #final_prob = np.log(Y[start].sum(axis=0) + alpha)\n",
        "        final_prob = np.log(Y[end - 1].sum(axis=0) + alpha)\n",
        "        final_prob -= logsumexp(final_prob)\n",
        "\n",
        "        feature_prob = np.log(safe_sparse_dot(Y.T, X) + alpha)\n",
        "        feature_prob -= logsumexp(feature_prob, axis=0)\n",
        "\n",
        "        trans_prob = np.log(count_trans(y, len(classes)) + alpha)\n",
        "        trans_prob -= logsumexp(trans_prob, axis=0)\n",
        "\n",
        "        self.coef_ = feature_prob\n",
        "        self.intercept_init_ = init_prob\n",
        "        self.intercept_final_ = final_prob\n",
        "        self.intercept_trans_ = trans_prob\n",
        "\n",
        "        self.classes_ = classes\n",
        "\n",
        "        return self"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzGIALzmnHyB",
        "colab_type": "text"
      },
      "source": [
        "## Importing libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab_type": "code",
        "id": "ZnXUdrxQ3TAN",
        "outputId": "b4511a65-32e5-4f57-c33b-c6aa82584c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%autosave 180\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "import sys\n",
        "from copy import deepcopy\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import codecs\n",
        "from collections import Counter\n",
        "import re\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import chain\n",
        "from functools import wraps\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_validate, KFold, ParameterGrid, RandomizedSearchCV    \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn_crfsuite import CRF\n",
        "\n",
        "from seqlearn.hmm import MultinomialHMM as seqlearn_MHMM\n",
        "from hmmlearn.hmm import MultinomialHMM as hmmlearn_MHMM\n",
        "from seqlearn.evaluation import SequenceKFold, bio_f_score\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.metrics import recall_score, roc_auc_score, make_scorer, f1_score, fbeta_score, classification_report\n",
        "from seqeval.metrics import classification_report as entity_classification_report\n",
        "\n",
        "import keras.backend as k\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Masking\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)-9s [%(asctime)s] : %(message)s', stream=sys.stdout)\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(180000)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Autosaving every 180 seconds\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VD2z8D2V7Dod"
      },
      "source": [
        "# Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okymGz_lEjLC",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "COLAB = True\n",
        "test_size = 0.2\n",
        "subcorpus = 'Voice of America'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORjyFpGXUgLw",
        "colab_type": "text"
      },
      "source": [
        "The raw data was preprocessed on my own PC bacause of google drive limitations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "trusted": true,
        "id": "oEOxPSZASzMt",
        "outputId": "f9eadcbd-3459-43f6-b0a9-408f7ba71f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    data_folder = '/content/drive/My Drive/Advanced NLP/Homework 2: Named entity recognition on Groningen Meaning Bank dataset'\n",
        "else:\n",
        "    data_folder = 'D:\\Data\\gmb-2.2.0\\data'\n",
        "    print('data found:', os.listdir(data_folder))\n",
        "    \n",
        "print('data found:', os.listdir(data_folder))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "data found: ['HW1. NER.ipynb', 'Voice of America.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "yeZfDywxSLx6",
        "colab_type": "text"
      },
      "source": [
        "# Data extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "tgwhO8ngi-A4"
      },
      "source": [
        "Parsing data from \"Voice of America\" subcorpus. According to the instructions we take first four columns and additional column to separate data on texts, sentences or words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "-UBeZ_eui-A5",
        "outputId": "5308f75a-eaa2-42e3-ecae-4f6aa512ec36",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "voa_data = pd.DataFrame(columns=['word', 'pos', 'lemma', 'ne_tags', 'text_id'])\n",
        "\n",
        "os.chdir(data_path)\n",
        "part_paths = os.listdir()\n",
        "\n",
        "for part_path in tqdm(part_paths, total=len(part_paths)):\n",
        "    os.chdir(part_path)\n",
        "    document_paths = os.listdir()\n",
        "    for document_path in document_paths:\n",
        "        os.chdir(document_path)\n",
        "        f = codecs.open(\"en.met\", 'r', \"utf_8_sig\")\n",
        "        file_met = f.read()\n",
        "        if ('subcorpus: {}'.format(subcorpus) in file_met):\n",
        "            tags_df = pd.read_csv('en.tags',\n",
        "                                  sep='\\t',\n",
        "                                  header=None,\n",
        "                                  names=['word', 'pos', 'lemma', 'ne_tags'],\n",
        "                                  usecols=[0, 1, 2, 3],\n",
        "                                  error_bad_lines=False)\n",
        "            tags_df['text_id'] = str(part_path) + '_' + str(document_path)\n",
        "            voa_data = voa_data.append(tags_df, ignore_index=True)\n",
        "        f.close()\n",
        "        os.chdir('..')\n",
        "    os.chdir('..')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [08:55<00:00,  5.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wall time: 8min 55s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "JYpE1dtnSLyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_memory_usage(df):\n",
        "    print(\"memory usage: \", df.memory_usage().sum()/1024/1024, \" MB\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "UX1ViqnKi-A-",
        "outputId": "c391cb23-3288-4f4f-db22-f5afc86f4fa2",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "show_memory_usage(voa_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "memory usage:  46.969688415527344  MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "RYMlRwEcSLyO",
        "colab_type": "code",
        "outputId": "83f64eb0-ef62-46d1-bc84-475a0310520b",
        "colab": {}
      },
      "source": [
        "voa_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>march</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            word  pos         lemma ne_tags    text_id\n",
              "0      Thousands  NNS      thousand       O  p00_d0018\n",
              "1             of   IN            of       O  p00_d0018\n",
              "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
              "3           have  VBP          have       O  p00_d0018\n",
              "4        marched  VBN         march       O  p00_d0018"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "kUrX7pvxi-BB",
        "outputId": "f42abe57-ad1b-4a64-a7b3-6bf93acb5155",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "voa_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1231279, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "8vWQ-w4Qi-BF"
      },
      "source": [
        "Number of tokens coincided with the declared in README file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJLE7LWKSLyv",
        "colab_type": "text"
      },
      "source": [
        "## Make BIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjC-2hcvSLyw",
        "colab_type": "text"
      },
      "source": [
        "Classificators work better if avoid redundant granularity. Also such detailed fragmentation has no value for the task of only finding named entities. Thus, we can combine subcategories and leave only first part of tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBAE5CEJSLyy",
        "colab_type": "code",
        "outputId": "443869f8-8853-4861-ea03-e398e47ab086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "voa_data['ne_tags'] = voa_data['ne_tags'].apply(lambda x: x.split('-')[0])\n",
        "\n",
        "voa_data['ne_tags'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O      1032479\n",
              "geo      55480\n",
              "org      44659\n",
              "per      43168\n",
              "tim      30097\n",
              "gpe      19685\n",
              "[]        4064\n",
              "art        790\n",
              "eve        577\n",
              "nat        280\n",
              "Name: ne_tags, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1RJCoftSLy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def use_prev_value_decorator(func):\n",
        "    prev_tag = \"O\"\n",
        "\n",
        "    def wrapper(curr_tag, **kwargs):\n",
        "        nonlocal prev_tag\n",
        "        bio_tag = func(curr_tag, prev_tag)\n",
        "        prev_tag = curr_tag\n",
        "        return bio_tag\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "@use_prev_value_decorator\n",
        "# Tag tokens with standard NLP BIO tags\n",
        "def bio_tagger(curr_tag, prev_tag):\n",
        "    if curr_tag == \"O\":  #O\n",
        "        return curr_tag\n",
        "    elif curr_tag != \"O\" and prev_tag == \"O\":  # Begin NE\n",
        "        return \"B-\" + curr_tag\n",
        "    elif prev_tag != \"O\" and prev_tag == curr_tag:  # Inside NE\n",
        "        return \"I-\" + curr_tag\n",
        "    elif prev_tag != \"O\" and prev_tag != curr_tag:  # Adjacent NE\n",
        "        return \"B-\" + curr_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1aST79f1SLy6",
        "colab_type": "code",
        "outputId": "7d41a9e1-b7b2-4365-95f2-3584c2d021b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "voa_data['bio_tag'] = voa_data['ne_tags'].apply(bio_tagger, axis=1)\n",
        "\n",
        "print(voa_data['bio_tag'].value_counts().head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O        1032479\n",
            "B-geo      46622\n",
            "B-org      24133\n",
            "B-tim      23302\n",
            "I-per      21799\n",
            "Name: bio_tag, dtype: int64\n",
            "CPU times: user 762 ms, sys: 6.99 ms, total: 769 ms\n",
            "Wall time: 769 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJX8dQw8oxD1",
        "colab_type": "code",
        "outputId": "311a3149-4dba-4eb5-8dd6-bedb79746a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "voa_data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "      <th>bio_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        word  pos     lemma ne_tags    text_id bio_tag\n",
              "0  Thousands  NNS  thousand       O  p00_d0018       O\n",
              "1         of   IN        of       O  p00_d0018       O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Yl_enYrKSLyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voa_data.to_csv(os.path.join(data_folder,'{}.csv'.format(subcorpus)), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaKxWL7ASLzA",
        "colab_type": "text"
      },
      "source": [
        "Possible investigation: check if loop for column would be faster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDWnjmrRSbi0",
        "colab_type": "text"
      },
      "source": [
        "#Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "o0tal3WpSLyc",
        "colab_type": "code",
        "outputId": "0e4b2bbe-ebf2-4742-b6e7-de4ba88250ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "if COLAB:\n",
        "    voa_data = pd.read_csv(os.path.join(data_folder,'{}.csv'.format(subcorpus)))\n",
        "else:\n",
        "    voa_data = pd.read_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus))\n",
        "voa_data.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "      <th>bio_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>march</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            word  pos         lemma ne_tags    text_id bio_tag\n",
              "0      Thousands  NNS      thousand       O  p00_d0018       O\n",
              "1             of   IN            of       O  p00_d0018       O\n",
              "2  demonstrators  NNS  demonstrator       O  p00_d0018       O\n",
              "3           have  VBP          have       O  p00_d0018       O\n",
              "4        marched  VBN         march       O  p00_d0018       O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "15GVrJYa717o"
      },
      "source": [
        "# EDA and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "b1Y2cJhli-BG",
        "outputId": "ba12aeda-c416-4604-8608-6d861f91dc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def average_text_length(text_id):\n",
        "    doc_lengths = list(dict(Counter(text_id)).values())\n",
        "    sum = 0\n",
        "    for length in doc_lengths:\n",
        "        sum += length\n",
        "    return sum/len(doc_lengths)\n",
        "\n",
        "print(\"average text length: \", average_text_length(voa_data['text_id']))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average text length:  134.31646121959201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "OARm2L-aSLyj",
        "colab_type": "code",
        "outputId": "09c36751-d7ba-4631-9660-c3660d4b8b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "voa_data.describe()"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "      <th>bio_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>35154</td>\n",
              "      <td>48</td>\n",
              "      <td>27209</td>\n",
              "      <td>9</td>\n",
              "      <td>9167</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0090</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>61398</td>\n",
              "      <td>168817</td>\n",
              "      <td>74941</td>\n",
              "      <td>1036543</td>\n",
              "      <td>388</td>\n",
              "      <td>1036543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           word      pos    lemma  ne_tags    text_id  bio_tag\n",
              "count   1231279  1231279  1231279  1231279    1231279  1231279\n",
              "unique    35154       48    27209        9       9167       17\n",
              "top         the       NN      the        O  p00_d0090        O\n",
              "freq      61398   168817    74941  1036543        388  1036543"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "DCIKki2uSLyq",
        "colab_type": "code",
        "outputId": "a4588465-35ce-4c5f-80b8-513fcb655e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "voa_data['ne_tags'].value_counts()"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O      1036543\n",
              "geo      55480\n",
              "org      44659\n",
              "per      43168\n",
              "tim      30097\n",
              "gpe      19685\n",
              "art        790\n",
              "eve        577\n",
              "nat        280\n",
              "Name: ne_tags, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMN2b4zujvpW",
        "colab_type": "text"
      },
      "source": [
        "Let's check what does the [] tag mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpH766G2iB49",
        "colab_type": "code",
        "outputId": "32c19275-eaa8-48d5-f9b4-2e6a965b865d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "voa_data[voa_data['ne_tags'] == '[]']['word'].value_counts()"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], Name: word, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wurgKOpRi-d7",
        "colab_type": "code",
        "outputId": "b9e0c820-3349-4102-92e7-57982dba3779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "' '.join(voa_data[voa_data['text_id'] == 'p00_d0018']['word'].values)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country . Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \\tLQU\\t Bush Number One Terrorist \\tRQU\\t and \\tLQU\\t Stop the Bombings . \\tLQU\\t They marched from the Houses of Parliament to a rally in Hyde Park . Police put the number of marchers at 10,000 while organizers claimed it was 100,000 . The protest comes on the eve of the annual conference of Britain 's ruling Labor Party in the southern English seaside resort of Brighton . The party is divided over Britain 's participation in the Iraq conflict and the continued deployment of 8,500 British troops in that country . The London march came ahead of anti-war protests today in other cities , including Rome , Paris , and Madrid .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwoWJqMQj6fn",
        "colab_type": "text"
      },
      "source": [
        "Comparison with the raw text shew that these values mean quotes. We can use this fact as a feature but quotes are not considered here as named entities so we convert them to O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdk1HCD6lbyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voa_data.loc[voa_data['ne_tags'] == '[]', ['ne_tags', 'bio_tag']] = 'O', 'O'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96IP1SG7piIB",
        "colab_type": "code",
        "outputId": "18a6a832-d760-4a7a-f2d8-be6b04df8c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "voa_data['bio_tag'].value_counts()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        1036543\n",
              "B-geo      46622\n",
              "B-org      24133\n",
              "B-tim      23302\n",
              "I-per      21799\n",
              "B-per      21369\n",
              "I-org      20526\n",
              "B-gpe      19469\n",
              "I-geo       8858\n",
              "I-tim       6795\n",
              "B-art        455\n",
              "I-art        335\n",
              "B-eve        316\n",
              "I-eve        261\n",
              "B-nat        225\n",
              "I-gpe        216\n",
              "I-nat         55\n",
              "Name: bio_tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33WDK75S1kHp",
        "colab_type": "code",
        "outputId": "f4dd4373-98d2-4717-fe9e-6c49fb59ba17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "unique_labels = voa_data['bio_tag'].unique()\n",
        "unique_labels, len(unique_labels)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "        'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "        'I-eve', 'I-nat'], dtype=object), 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVeoAGgfbowZ",
        "colab_type": "code",
        "outputId": "c8f3c833-0d82-4881-9a9e-55c4b9ca9a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "#Words distribution across Tags without O tag\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(15, 5))\n",
        "ax = sns.countplot('bio_tag', data=voa_data.loc[voa_data['bio_tag'] != 'O'])\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ju3cG1P137k",
        "colab_type": "text"
      },
      "source": [
        "todo: add wordshape. from spacy for example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "nkdjfnBqSLzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentences(df, word_col='word', pos_col='pos', \n",
        "                  tag_col='bio_tag', id_col='text_id'):\n",
        "    \"\"\"func to get the sentences in this format:\n",
        "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_n, Tag_n)]\"\"\"\n",
        "    \n",
        "    agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[word_col].values.tolist(),\n",
        "                                                       s[pos_col].values.tolist(),\n",
        "                                                       s[tag_col].values.tolist())]\n",
        "    grouped = df.groupby(id_col).apply(agg_func)\n",
        "    sentences = [s for s in grouped]\n",
        "    \n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "w1HlGz6hSLzI",
        "colab_type": "code",
        "outputId": "990e3ab9-7d98-44da-ee00-9cbeece594c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "word_pos_tag_sentences = get_sentences(voa_data)\n",
        "\n",
        "#Lets visualize how the sentences are distributed by their length\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.hist([len(s) for s in word_pos_tag_sentences], bins=50)\n",
        "plt.show()"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.84 s, sys: 60.2 ms, total: 1.9 s\n",
            "Wall time: 1.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "QGG9Ugo_SLzR",
        "colab_type": "text"
      },
      "source": [
        "create featuretfransformer like in https://www.depends-on-the-definition.com/introduction-named-entity-recognition-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls0zsDyVFtXV",
        "colab_type": "text"
      },
      "source": [
        "Feature engineering – 2 (1+1) \n",
        "* add quotes before and after as features  \n",
        " \n",
        "grammatical words = closed set (~ stop words)  \n",
        "Stemming + POS  \n",
        "Word shape  \n",
        "Ad hoc features ( +1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "n6vL4H0uSLzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        # 'word[-3:]': word[-3:], #replace with BPE\n",
        "        # 'word[-2:]': word[-2:],\n",
        "        # 'word.isupper()': word.isupper(),\n",
        "        # 'word.istitle()': word.istitle(),\n",
        "        # 'word.isdigit()': word.isdigit(),\n",
        "        # 'postag': postag,\n",
        "        # 'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        # features.update({\n",
        "        #     '-1:word.lower()': word1.lower(),\n",
        "        #     '-1:word.istitle()': word1.istitle(),\n",
        "        #     '-1:word.isupper()': word1.isupper(),\n",
        "        #     '-1:postag': postag1,\n",
        "        #     '-1:postag[:2]': postag1[:2],\n",
        "        # })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        # postag1 = sent[i+1][1]\n",
        "        # features.update({\n",
        "        #     '+1:word.lower()': word1.lower(),\n",
        "        #     '+1:word.istitle()': word1.istitle(),\n",
        "        #     '+1:word.isupper()': word1.isupper(),\n",
        "        #     '+1:postag': postag1,\n",
        "        #     '+1:postag[:2]': postag1[:2],\n",
        "        # })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def get_sent_labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "DEWQp8ecSLzU",
        "colab_type": "code",
        "outputId": "63f1b101-92c3-453e-ccb5-588d5778e84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "X = [sent2features(s) for s in word_pos_tag_sentences]\n",
        "y = [get_sent_labels(s) for s in word_pos_tag_sentences]\n",
        "\n",
        "#make a split while the data is still sequential\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=False, random_state=42)\n",
        "\n",
        "def get_flatten_and_lengths(X, y):\n",
        "    lengths = [len(x) for x in X]\n",
        "    flatten_X = [item for sublist in X for item in sublist]\n",
        "    flatten_y = [item for sublist in y for item in sublist]\n",
        "    assert len(flatten_X) == np.array(lengths).sum()\n",
        "    return flatten_X, flatten_y, lengths\n",
        "X_train_flatten, y_train_flatten, lengths_train = get_flatten_and_lengths(X_train, y_train)\n",
        "X_test_flatten, y_test_flatten, lengths_test = get_flatten_and_lengths(X_test, y_test)\n",
        "\n",
        "# check values for both: train and test\n",
        "voa_train_test = pd.concat([pd.Series(y_train_flatten).value_counts().rename('bio_tag_train'), \n",
        "                            pd.Series(y_test_flatten).value_counts().rename('bio_tag_test')], \n",
        "                            axis=1)\n",
        "print(voa_train_test.sort_values(by='bio_tag_train', ascending=False))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       bio_tag_train  bio_tag_test\n",
            "O             829429        207114\n",
            "B-geo          37235          9387\n",
            "B-org          19134          4999\n",
            "B-tim          18611          4691\n",
            "I-per          17456          4343\n",
            "B-per          17078          4291\n",
            "I-org          16252          4274\n",
            "B-gpe          15626          3843\n",
            "I-geo           7114          1744\n",
            "I-tim           5380          1415\n",
            "B-art            383            72\n",
            "I-art            281            54\n",
            "B-eve            261            55\n",
            "I-eve            220            41\n",
            "B-nat            195            30\n",
            "I-gpe            180            36\n",
            "I-nat             47             8\n",
            "CPU times: user 1.55 s, sys: 258 ms, total: 1.81 s\n",
            "Wall time: 1.81 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4iDcFD5SLzi",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz-7GAisF3pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(y):\n",
        "    return list(chain.from_iterable(y))\n",
        "\n",
        "def _flattens_y(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(y_true, y_pred, *args, **kwargs):\n",
        "        y_true_flat = flatten(y_true)\n",
        "        y_pred_flat = flatten(y_pred)\n",
        "        return func(y_true_flat, y_pred_flat, *args, **kwargs)\n",
        "    return wrapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPpcblmfSLzn",
        "colab_type": "code",
        "outputId": "a38ee754-3276-40fc-83df-53d2c021c94f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "def f1_macro(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "def fbeta_macro(y_true, y_pred, beta=2):\n",
        "    return fbeta_score(y_true, y_pred, average='macro', beta=beta)\n",
        "\n",
        "scoring = [bio_f_score, f1_macro, fbeta_macro]\n",
        "cv = KFold(n_splits=5, shuffle=False, random_state=42)\n",
        "sequence_cv = SequenceKFold(lengths_train, n_folds=5, n_iter=1, shuffle=False, random_state=42, yield_lengths=True)\n",
        "\n",
        "def evaluate_bio_clf_report(y_test, y_pred, labels, remove_O=True,\n",
        "                            do_flatten=False):\n",
        "    if remove_O:\n",
        "        labels.remove('O') # remove 'O' label from evaluation\n",
        "    sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
        "    if do_flatten:\n",
        "        report = flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3)\n",
        "    else:\n",
        "        report = classification_report(y_test, y_pred, labels=sorted_labels, digits=3)\n",
        "    return report\n",
        "\n",
        "def evaluate_entity_clf_report(y_test, y_pred, lengths_test):\n",
        "    \n",
        "    if len(y_pred) != len(y_test):\n",
        "        logging.info(\"lengths of y_pred and y_test are not equal. trying to unflat predictions via lengths\")\n",
        "        assert sum(lengths_test) == len(y_pred)\n",
        "        \n",
        "        y_pred_copy = deepcopy(y_pred)\n",
        "        y_pred_unflatten = []\n",
        "        for length in lengths_test:\n",
        "            y_pred_unflatten.append(y_pred_copy[:length].tolist())\n",
        "            y_pred_copy = np.delete(y_pred_copy, range(length))\n",
        "    else:\n",
        "        y_pred_unflatten = y_pred\n",
        "        \n",
        "    return entity_classification_report(y_test, y_pred_unflatten)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLB6GHZZWNx-",
        "colab_type": "text"
      },
      "source": [
        "todo: add classification report on entities and bio_tag levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n8APgvUyskaf"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEOKnlyZSLzs",
        "colab_type": "text"
      },
      "source": [
        "## HMM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFMRezuzaZPC",
        "colab_type": "text"
      },
      "source": [
        "###Supervised\n",
        "Given an observation sequence and the associated hidden states (real tags) we can learn the HMM parameters, that is, the matrices A and B.\n",
        "\n",
        "In a HHM supervised scenario this is done by applying the Maximum Likelihood Estimation principle, which will compute the matrices.\n",
        "\n",
        "This is achieved by counting how many times each event occurs in the corpus and normalizing the counts to form proper probability distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dNNFC2v_SL0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline([('vectorizer', DictVectorizer(sparse=True)),\n",
        "                 ('seq_clf', seqlearn_MHMM())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTw2uVfgO8u3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_seq_cross_validate(estimator, X, y, cv, scoring):\n",
        "    scores = dict((metric.__name__, []) for metric in scoring)\n",
        "    for train, lengths_train, test, lengths_test in tqdm(list(cv), total=len(list(cv))):\n",
        "        estimator_copy = deepcopy(estimator)\n",
        "        model_name = estimator_copy.steps[-1][0]\n",
        "        estimator_copy.fit(X[train], y[train], **{model_name+'__lengths': lengths_train})\n",
        "        pred = estimator_copy.predict(X[test], **{'lengths': lengths_test})\n",
        "        for metric in scoring:\n",
        "            scores[metric.__name__].append(metric(y_true=y[test], y_pred=pred))\n",
        "    \n",
        "    scores_df = pd.DataFrame.from_dict(scores)\n",
        "    scores_df.loc['mean'] = scores_df.mean()\n",
        "    return scores_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjOJdoBeY5O3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grid_seq_cross_validate(parameter_dict, pipe, **kwargs):\n",
        "    scores_dict = dict()\n",
        "    grid_params_list = list(ParameterGrid(parameter_dict))\n",
        "    for param_set in tqdm(grid_params_list, total=len(grid_params_list)):\n",
        "        pipe_copy = deepcopy(pipe)\n",
        "        # assuming that last step of pipeline is model\n",
        "        pipe_copy[-1].__dict__.update(param_set)\n",
        "        scores = my_seq_cross_validate(pipe_copy, **kwargs)\n",
        "        scores_dict[str(pipe_copy[-1])] = scores\n",
        "    return scores_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_7p4Jxheuw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameter_dict = {\n",
        "    #Given a trained HMM i.e., the transition matrixes A and B, and a new observation sequence W=w1,w2,…,wN we want to find the sequence of states T=t1,t2,…,tN that best explains it.\n",
        "    #This is can be achieved by using the Viterbi algorithm, that finds the best state assignment to the sequence T1…TN as a whole. \n",
        "    #There is another algorithm, Posterior Decoding (best-first) which consists in picking the highest state posterior for each position i in the sequence independently.\n",
        "    'decode':['viterbi', 'bestfirst'], \n",
        "    'alpha':[0.001, 0.01, 0.1, 1.0]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q4P4gNxf51n",
        "colab_type": "code",
        "outputId": "9c9dde7e-5f51-49ed-f8dd-e3347ebf3091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            "a4a84f1c06b34227b75d128a51a82d2f",
            "95fb0b243e234e989e5f166489e3bc88",
            "fccf7ed036694d76b071e11d1179a492",
            "d092bae32bdb48389c8b9c25df13d1a1",
            "5b6eab54021140d69405a6deedac5f9b",
            "0b8c015059d540a7b0780e7d78bb18c0",
            "1eff841162c54139bfaf5ba8aedd08f2",
            "40617a7d172a4536be5451cb810adafa",
            "f45ce16602f54f3ba34d3e95afbca514",
            "023bd140826c4d7daa3576bd1a691033",
            "26e43c5b2e874934b0c7c4494a71494c",
            "856486a7bef543e894694d65b869b1da",
            "a30bf3cfb5534b84932bb22b491d131f",
            "7a65114dca834a2bb32e23cac42cc27d",
            "1ba9e31825084b01be3c246ce85d674f",
            "94ef18e73685457a99107a8f35a691fa",
            "f656a91824324958a7ca8f8a22eb36fc",
            "03534413eeed48ea8e359ca1695a644f",
            "f3127767d1df49b5b2ba9bb345c9fa23",
            "9f608d24e8984e7d928787c01e8bcd63",
            "f357ac82ef704829ac8a6308bd8c4b0f",
            "fcbf26ca360b49a5849428b4f82ea9cf",
            "19b8e6d8d4ce478582ac51f569dc414e",
            "93c1e2c856004760910461e1c1eaa81f",
            "0c762f72c0d74610971f14419eb1f77d",
            "2e25ec04478248e89547194e43865bbb",
            "258a1f291fde4a40829cb581e10da680",
            "82c5f91a9d10441ba2ae035eb9de2936",
            "e9ec6e1dcb984412bfb75bc16850cadf",
            "da7bf79f5d4a49299f0d0c9970a62e9b",
            "3f247b1d89fc457eb87ec1a18eb30be4",
            "ca79a346472743068eb779252473c487",
            "3ef95639863848f586957fa4823e5da6",
            "941e276d3b124f8e8f6d6451edd9f4d9",
            "09e6562e30ff41a58c2dcd06089b1529",
            "4c6fbe7617844969a03f099c6cf329f3",
            "c3a33c390c5a4581bac946a16fa1eb9e",
            "415762ee983b44bdba02e9c3f62f59fa",
            "4b50024e4380498693d9c73e1ed61010",
            "1f1fdfe150cf49d38178680dd1428ec4",
            "fd85ee4310054709aa8c856a2e53419d",
            "a9bdacedde394392a26acc7aff38792e",
            "5bc090a8379b4cd6b97132dbceb1f09e",
            "7340797a41284319b19537f7fd03f5f5",
            "b071173e66bf4adcb618d0bd6a2a1413",
            "506f8fbe830b40b787b2a192ac7e1343",
            "93c9a83ceb654e00bb90981a8f0c1f5e",
            "d15bd90075f741138938b5aaa54319a2",
            "2ffde3a620b04824a654d45a691a79ac",
            "7e6b3b99f72d4a37af3779a308a7a04c",
            "9d0c85b3844847129b622807d516f3f0",
            "00b9587b903e41cb84180009bd409df9",
            "1a52761a5d5e4fac98121e01fb376fd5",
            "510186523d2544f6a2aff4376e2387e3",
            "92609aa187a9427493e2afe938f0c528",
            "a7a5845caf60444389c56007f48631b9",
            "bf55f18efc6748cb8a0b954fc02a3fd5",
            "d8f241b5c3d74f4da440208e8c21b066",
            "c5520c24070a409e899d40bab89eb22f",
            "810f5040b3c348cd8b0c3e34dccb7895",
            "551d39b97c96417d818b3cf2615e7777",
            "eaf12f3480934de994f71a09006ccb2f",
            "d94082cab95d4868a4236f81e429d44b",
            "db4359d585bc4157b3beea372b160458",
            "acbbe65d0025430d901ebc72ff226a4c",
            "1522f8813be74dd1a4c9a7f814f80f00",
            "730c83053c964a80b8bbe6e0a17a1078",
            "eb07ca7501504304ba77f3562ba1e786",
            "507719b20a9d4132bed5a478413ff1f5",
            "ee87667c7eeb4b449bc8f73c3922f166",
            "23036e6b27d546bc8a262b6228dcb35c",
            "bd184f0c8f7c44da85298b9c2ca47a19"
          ]
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "scores_dict = grid_seq_cross_validate(parameter_dict, \n",
        "                                      pipe, \n",
        "                                      X=np.array(X_train_flatten),\n",
        "                                      y=np.array(y_train_flatten),\n",
        "                                      cv=sequence_cv,\n",
        "                                      scoring=scoring)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4a84f1c06b34227b75d128a51a82d2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f45ce16602f54f3ba34d3e95afbca514",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f656a91824324958a7ca8f8a22eb36fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c762f72c0d74610971f14419eb1f77d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ef95639863848f586957fa4823e5da6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd85ee4310054709aa8c856a2e53419d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ffde3a620b04824a654d45a691a79ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf55f18efc6748cb8a0b954fc02a3fd5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acbbe65d0025430d901ebc72ff226a4c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "CPU times: user 2min 26s, sys: 1.59 s, total: 2min 28s\n",
            "Wall time: 2min 28s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTVgWv3juGMF",
        "colab_type": "code",
        "outputId": "a6b6a291-85f7-45ad-e97c-d928081dd9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "scores_df = pd.concat(scores_dict.values(), keys=scores_dict.keys(), axis=1)\n",
        "scores_df.T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.001, decode='viterbi')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.602240</td>\n",
              "      <td>0.592532</td>\n",
              "      <td>0.598458</td>\n",
              "      <td>0.600242</td>\n",
              "      <td>0.615618</td>\n",
              "      <td>0.601818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.286838</td>\n",
              "      <td>0.283691</td>\n",
              "      <td>0.286242</td>\n",
              "      <td>0.288546</td>\n",
              "      <td>0.291031</td>\n",
              "      <td>0.287269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.258712</td>\n",
              "      <td>0.254595</td>\n",
              "      <td>0.256610</td>\n",
              "      <td>0.258267</td>\n",
              "      <td>0.264240</td>\n",
              "      <td>0.258485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.001, decode='bestfirst')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.675595</td>\n",
              "      <td>0.662932</td>\n",
              "      <td>0.678801</td>\n",
              "      <td>0.679100</td>\n",
              "      <td>0.676098</td>\n",
              "      <td>0.674505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.402382</td>\n",
              "      <td>0.369598</td>\n",
              "      <td>0.364784</td>\n",
              "      <td>0.394159</td>\n",
              "      <td>0.383193</td>\n",
              "      <td>0.382823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.358670</td>\n",
              "      <td>0.330615</td>\n",
              "      <td>0.327697</td>\n",
              "      <td>0.352449</td>\n",
              "      <td>0.342234</td>\n",
              "      <td>0.342333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.01, decode='viterbi')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.569115</td>\n",
              "      <td>0.560307</td>\n",
              "      <td>0.564312</td>\n",
              "      <td>0.572064</td>\n",
              "      <td>0.584976</td>\n",
              "      <td>0.570155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.262675</td>\n",
              "      <td>0.260466</td>\n",
              "      <td>0.262267</td>\n",
              "      <td>0.263444</td>\n",
              "      <td>0.267787</td>\n",
              "      <td>0.263328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.233159</td>\n",
              "      <td>0.229876</td>\n",
              "      <td>0.231222</td>\n",
              "      <td>0.232294</td>\n",
              "      <td>0.238680</td>\n",
              "      <td>0.233046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.01, decode='bestfirst')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.675015</td>\n",
              "      <td>0.662304</td>\n",
              "      <td>0.679298</td>\n",
              "      <td>0.679219</td>\n",
              "      <td>0.675771</td>\n",
              "      <td>0.674321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.379256</td>\n",
              "      <td>0.335258</td>\n",
              "      <td>0.357550</td>\n",
              "      <td>0.376763</td>\n",
              "      <td>0.365923</td>\n",
              "      <td>0.362950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.340797</td>\n",
              "      <td>0.305155</td>\n",
              "      <td>0.322880</td>\n",
              "      <td>0.339774</td>\n",
              "      <td>0.329308</td>\n",
              "      <td>0.327583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.1, decode='viterbi')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.458375</td>\n",
              "      <td>0.450819</td>\n",
              "      <td>0.455397</td>\n",
              "      <td>0.462918</td>\n",
              "      <td>0.467546</td>\n",
              "      <td>0.459011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.202655</td>\n",
              "      <td>0.196163</td>\n",
              "      <td>0.198286</td>\n",
              "      <td>0.201613</td>\n",
              "      <td>0.206395</td>\n",
              "      <td>0.201022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.173546</td>\n",
              "      <td>0.168147</td>\n",
              "      <td>0.169579</td>\n",
              "      <td>0.172336</td>\n",
              "      <td>0.176715</td>\n",
              "      <td>0.172065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.1, decode='bestfirst')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.663210</td>\n",
              "      <td>0.653199</td>\n",
              "      <td>0.667042</td>\n",
              "      <td>0.667492</td>\n",
              "      <td>0.665416</td>\n",
              "      <td>0.663272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.333049</td>\n",
              "      <td>0.317296</td>\n",
              "      <td>0.321897</td>\n",
              "      <td>0.351280</td>\n",
              "      <td>0.339980</td>\n",
              "      <td>0.332700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.298961</td>\n",
              "      <td>0.285813</td>\n",
              "      <td>0.290552</td>\n",
              "      <td>0.312855</td>\n",
              "      <td>0.303870</td>\n",
              "      <td>0.298410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=1.0, decode='viterbi')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.161203</td>\n",
              "      <td>0.158475</td>\n",
              "      <td>0.154462</td>\n",
              "      <td>0.174607</td>\n",
              "      <td>0.153814</td>\n",
              "      <td>0.160512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.090295</td>\n",
              "      <td>0.088205</td>\n",
              "      <td>0.085900</td>\n",
              "      <td>0.090717</td>\n",
              "      <td>0.088769</td>\n",
              "      <td>0.088777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.082487</td>\n",
              "      <td>0.081023</td>\n",
              "      <td>0.079363</td>\n",
              "      <td>0.083036</td>\n",
              "      <td>0.081287</td>\n",
              "      <td>0.081439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=1.0, decode='bestfirst')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.599918</td>\n",
              "      <td>0.589508</td>\n",
              "      <td>0.605466</td>\n",
              "      <td>0.605281</td>\n",
              "      <td>0.607337</td>\n",
              "      <td>0.601502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.280395</td>\n",
              "      <td>0.273444</td>\n",
              "      <td>0.281261</td>\n",
              "      <td>0.284272</td>\n",
              "      <td>0.280005</td>\n",
              "      <td>0.279875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.244576</td>\n",
              "      <td>0.237947</td>\n",
              "      <td>0.246202</td>\n",
              "      <td>0.247634</td>\n",
              "      <td>0.245019</td>\n",
              "      <td>0.244275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                    0  ...      mean\n",
              "MultinomialHMM(alpha=0.001, decode='viterbi')   bio_f_score  0.602240  ...  0.601818\n",
              "                                                f1_macro     0.286838  ...  0.287269\n",
              "                                                fbeta_macro  0.258712  ...  0.258485\n",
              "MultinomialHMM(alpha=0.001, decode='bestfirst') bio_f_score  0.675595  ...  0.674505\n",
              "                                                f1_macro     0.402382  ...  0.382823\n",
              "                                                fbeta_macro  0.358670  ...  0.342333\n",
              "MultinomialHMM(alpha=0.01, decode='viterbi')    bio_f_score  0.569115  ...  0.570155\n",
              "                                                f1_macro     0.262675  ...  0.263328\n",
              "                                                fbeta_macro  0.233159  ...  0.233046\n",
              "MultinomialHMM(alpha=0.01, decode='bestfirst')  bio_f_score  0.675015  ...  0.674321\n",
              "                                                f1_macro     0.379256  ...  0.362950\n",
              "                                                fbeta_macro  0.340797  ...  0.327583\n",
              "MultinomialHMM(alpha=0.1, decode='viterbi')     bio_f_score  0.458375  ...  0.459011\n",
              "                                                f1_macro     0.202655  ...  0.201022\n",
              "                                                fbeta_macro  0.173546  ...  0.172065\n",
              "MultinomialHMM(alpha=0.1, decode='bestfirst')   bio_f_score  0.663210  ...  0.663272\n",
              "                                                f1_macro     0.333049  ...  0.332700\n",
              "                                                fbeta_macro  0.298961  ...  0.298410\n",
              "MultinomialHMM(alpha=1.0, decode='viterbi')     bio_f_score  0.161203  ...  0.160512\n",
              "                                                f1_macro     0.090295  ...  0.088777\n",
              "                                                fbeta_macro  0.082487  ...  0.081439\n",
              "MultinomialHMM(alpha=1.0, decode='bestfirst')   bio_f_score  0.599918  ...  0.601502\n",
              "                                                f1_macro     0.280395  ...  0.279875\n",
              "                                                fbeta_macro  0.244576  ...  0.244275\n",
              "\n",
              "[24 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD69jlYw43Jy",
        "colab_type": "text"
      },
      "source": [
        "Less alpha show better result. Ceteris paribus, bestfirst performs better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcZxLpOauX0F",
        "colab_type": "code",
        "outputId": "67dd430b-fdfe-443f-a981-6b670d4a20e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "%%time\n",
        "pipe = Pipeline([('vectorizer', DictVectorizer(sparse=True)),\n",
        "                 ('seq_clf', seqlearn_MHMM(alpha=0.001, decode='bestfirst'))])\n",
        "pipe.fit(X_train_flatten, y_train_flatten, **{'seq_clf__lengths': lengths_train})\n",
        "y_pred_flatten = pipe.predict(X_test_flatten, **{'lengths': lengths_test})\n",
        "print(y_pred_flatten[:15], '\\n', y_test_flatten[:15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'] \n",
            " ['O', 'B-org', 'O', 'B-per', 'I-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O']\n",
            "CPU times: user 4.14 s, sys: 25.8 ms, total: 4.16 s\n",
            "Wall time: 4.17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EzSsxeXYmY",
        "colab_type": "code",
        "outputId": "38b0f9e6-0712-4cd1-f678-1a2b6c523af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.unique(y_pred_flatten)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r41neoOIXcGg",
        "colab_type": "code",
        "outputId": "870a3c2e-92c1-435b-81b0-8f0ffa8fa169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "np.unique(y_test_flatten)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per',\n",
              "       'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org',\n",
              "       'I-per', 'I-tim', 'O'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8TSTKM0TJZ6",
        "colab_type": "code",
        "outputId": "05a6f05b-95f7-413f-f5fb-687713263c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bio_f_score(y_test_flatten, y_pred_flatten)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pkkTUSolvS2",
        "colab_type": "code",
        "outputId": "ddd0e9cc-d0c6-4085-cfc7-1ae51e91e9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bio_clf_report = evaluate_bio_clf_report(y_test_flatten, y_pred_flatten, \n",
        "                                         labels=list(estimator.classes_),\n",
        "                                         do_flatten=False)\n",
        "entity_clf_report = evaluate_entity_clf_report(y_test, y_pred_flatten, lengths_test)\n",
        "print('*****BIO-tag LEVEL*****\\n', bio_clf_report, '\\n*****ENTITY LEVEL*****\\n', entity_clf_report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*****BIO-tag LEVEL*****\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       B-art      0.000     0.000     0.000        72\n",
            "       I-art      0.000     0.000     0.000        54\n",
            "       B-eve      0.800     0.218     0.343        55\n",
            "       I-eve      0.000     0.000     0.000        41\n",
            "       B-geo      0.763     0.793     0.778      9387\n",
            "       I-geo      0.771     0.319     0.451      1744\n",
            "       B-gpe      0.979     0.816     0.890      3843\n",
            "       I-gpe      1.000     0.306     0.468        36\n",
            "       B-nat      0.625     0.167     0.263        30\n",
            "       I-nat      0.000     0.000     0.000         8\n",
            "       B-org      0.788     0.257     0.388      4999\n",
            "       I-org      0.468     0.020     0.039      4274\n",
            "       B-per      0.694     0.514     0.591      4291\n",
            "       I-per      0.873     0.544     0.670      4343\n",
            "       B-tim      0.913     0.678     0.778      4691\n",
            "       I-tim      0.991     0.081     0.150      1415\n",
            "\n",
            "   micro avg      0.816     0.519     0.635     39283\n",
            "   macro avg      0.604     0.295     0.363     39283\n",
            "weighted avg      0.783     0.519     0.585     39283\n",
            " \n",
            "*****ENTITY LEVEL*****\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "      geo       0.75      0.78      0.76      9387\n",
            "      tim       0.82      0.61      0.70      4691\n",
            "      org       0.72      0.24      0.35      4999\n",
            "      per       0.62      0.46      0.53      4291\n",
            "      gpe       0.98      0.81      0.89      3843\n",
            "      art       0.00      0.00      0.00        72\n",
            "      eve       0.80      0.22      0.34        55\n",
            "      nat       0.62      0.17      0.26        30\n",
            "\n",
            "micro avg       0.77      0.60      0.68     27368\n",
            "macro avg       0.77      0.60      0.65     27368\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--xswwSlfIJf",
        "colab_type": "text"
      },
      "source": [
        "###Handmade\n",
        "The most trivial model = supervised HMM:\n",
        "Take hmmlearn (former sklearn), modify MultinomialHMM (I.e. inherit a new class from _BaseHMM making it a modified copy of the latter) to allow for supervised HMM training. The states of the HMM model = the NE tags.  \n",
        "NOTE: may use NaiveBayes to learn emission probabilities in a supervized manner.\n",
        "Or implement from scratch (with Viterbi for prediction).  \n",
        "NOTE: use tuples of features for X (not just the word, but additional info).  \n",
        "NOTE: use smoothing for state transitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqh6q_GJfKN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hmmlearn.base import _BaseHMM\n",
        "import scipy.sparse as sp\n",
        "from scipy.special import logsumexp\n",
        "from sklearn.utils.extmath import safe_sparse_dot\n",
        "from sklearn.utils import check_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WePak4nrfYgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def array2d(X, dtype=None, order=None, copy=False):\n",
        "    \"\"\"Returns at least 2-d array with data from X\"\"\"\n",
        "    if sp.issparse(X):\n",
        "        raise TypeError('A sparse matrix was passed, but dense data '\n",
        "                        'is required. Use X.toarray() to convert to dense.')\n",
        "    X_2d = np.asarray(np.atleast_2d(X), dtype=dtype, order=order)\n",
        "    if X is X_2d and copy:\n",
        "        X_2d = safe_copy(X_2d)\n",
        "    return X_2d\n",
        "\n",
        "\n",
        "def _atleast2d_or_sparse(X, dtype, order, copy, sparse_class, convmethod,\n",
        "                         check_same_type):\n",
        "    if sp.issparse(X):\n",
        "        logging.info('X is sparse. Convert to csr if needed')\n",
        "        if check_same_type(X) and X.dtype == dtype:\n",
        "            X = getattr(X, convmethod)(copy=copy)\n",
        "        elif dtype is None or X.dtype == dtype:\n",
        "            X = getattr(X, convmethod)()\n",
        "        else:\n",
        "            X = sparse_class(X, dtype=dtype)\n",
        "        X.data = np.array(X.data, copy=False, order=order)\n",
        "    else:\n",
        "        logging.info('Converting X to array2d')\n",
        "        X = array2d(X, dtype=dtype, order=order, copy=copy)\n",
        "    return X\n",
        "\n",
        "\n",
        "def atleast2d_or_csr(X, dtype=None, order=None, copy=False):\n",
        "    \"\"\"Like numpy.atleast_2d, but converts sparse matrices to CSR format\n",
        "    Also, converts np.matrix to np.ndarray.\n",
        "    \"\"\"\n",
        "    return _atleast2d_or_sparse(X, dtype, order, copy, sp.csr_matrix,\n",
        "                                \"tocsr\", sp.isspmatrix_csr)\n",
        "\n",
        "\n",
        "def count_trans(y, n_classes):\n",
        "    \"\"\"Count transitions in a target vector.\n",
        "    Parameters\n",
        "    ----------\n",
        "    y : array of integers, shape = n_samples\n",
        "    n_classes : int\n",
        "        Number of distinct labels.\n",
        "    \"\"\"\n",
        "    trans = np.zeros((n_classes, n_classes), \n",
        "                     #dtype=np.intp\n",
        "                     )\n",
        "\n",
        "    for i in range(y.shape[0] - 1):\n",
        "        trans[y[i], y[i + 1]] += 1\n",
        "    return trans\n",
        "\n",
        "\n",
        "def iter_from_X_lengths(X, lengths):\n",
        "    if lengths is None:\n",
        "        yield 0, len(X)\n",
        "    else:\n",
        "        n_samples = X.shape[0]\n",
        "        end = np.cumsum(lengths).astype(np.int32)\n",
        "        start = end - lengths\n",
        "        if end[-1] > n_samples:\n",
        "            raise ValueError(\"more than {:d} samples in lengths array {!s}\"\n",
        "                             .format(n_samples, lengths))\n",
        "\n",
        "        for i in range(len(lengths)):\n",
        "            yield start[i], end[i]\n",
        "\n",
        "\n",
        "class my_hmm(hmmlearn_MHMM):\n",
        "    def __init__(self, algorithm=\"viterbi\", alpha=.01, **kwargs):\n",
        "        self.alpha = alpha\n",
        "        self.algorithm = algorithm\n",
        "        hmmlearn_MHMM.__init__(self, **kwargs)\n",
        "\n",
        "    def fit_supervised(self, X, y, lengths):\n",
        "        \"\"\"Fit HMM model to data by applying the Maximum Likelihood Estimation \n",
        "        principle, which will compute the matrices. This is achieved by counting \n",
        "        how many times each event occurs in the corpus and normalizing the \n",
        "        counts to form proper probability distributions.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        y : array-like, shape (n_samples,)\n",
        "            Target labels.\n",
        "        lengths : array-like of integers, shape (n_sequences,)\n",
        "            Lengths of the individual sequences in X, y. The sum of these\n",
        "            should be n_samples.\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.alpha\n",
        "        if alpha <= 0:\n",
        "            raise ValueError(\"alpha should be >0, got {0!r}\".format(alpha))\n",
        "\n",
        "        X = atleast2d_or_csr(X)\n",
        "        self.n_visible = X.shape[1]\n",
        "        classes, y_indices = np.unique(y, return_inverse=True)\n",
        "        self.n_hidden = len(classes)\n",
        "        self.classes = classes\n",
        "        lengths = np.asarray(lengths)\n",
        "        # to list of one-hot vectors shape of (n_samples, unique_labels)\n",
        "        Y = y_indices.reshape(-1, 1) == np.arange(len(classes))\n",
        "        #return X, Y\n",
        "\n",
        "        end_indices = np.cumsum(lengths)\n",
        "        start_indices = end_indices - lengths\n",
        "        end_indices -= 1\n",
        "\n",
        "        # how much times each tag was at the beginning of the sequence\n",
        "        log_init_prob = np.log(Y[start_indices].sum(axis=0) + alpha)\n",
        "        # softmax, smoothing here is also taken into account \n",
        "        # (alpha taken the number of times equal number of classes)\n",
        "        normalized_log_init_prob = log_init_prob - logsumexp(log_init_prob)\n",
        "        init_prob = np.exp(normalized_log_init_prob)\n",
        "        \n",
        "        # how many times each tag was at the end of the sequence\n",
        "        log_final_prob = np.log(Y[end_indices].sum(axis=0) + alpha)\n",
        "        normalized_log_final_prob = log_final_prob - logsumexp(log_final_prob)\n",
        "        final_prob = np.exp(normalized_log_final_prob)\n",
        "\n",
        "        # how many times each feature occured with each tag\n",
        "        log_emission_prob = np.log(safe_sparse_dot(Y.T, X) + alpha)\n",
        "        normalized_log_emission_prob = log_emission_prob - logsumexp(log_emission_prob, axis=1)[:, np.newaxis]\n",
        "        emission_prob = np.exp(normalized_log_emission_prob)\n",
        "\n",
        "        log_trans_prob = np.log(count_trans(y_indices, len(classes)) + alpha)\n",
        "        normalized_log_trans_prob = log_trans_prob - logsumexp(log_trans_prob, axis=1)[:, np.newaxis]\n",
        "        trans_prob = np.exp(normalized_log_trans_prob)\n",
        "\n",
        "        self.startprob_ = init_prob\n",
        "        self.transmat_ = trans_prob\n",
        "        self.emissionprob_ = emission_prob \n",
        "        self.n_components = self.n_hidden  \n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        \"\"\"Func to calculate forward probabilities, i.e. that the HMM will be in \n",
        "        a particular hidden state at a particular time step after emitting first\n",
        "        t number of visible words from input_seq.\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_seq : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        Returns\n",
        "        -------\n",
        "        forward_prob : np.array, shape(n_samples, n_hidden)\n",
        "            Matrix of forward probabilities\n",
        "        \"\"\"\n",
        "        input_seq_len = input_seq.shape[0]\n",
        "        input_seq = atleast2d_or_csr(input_seq)\n",
        "\n",
        "        forward_prob = np.zeros((input_seq_len, self.n_hidden))\n",
        "        # element-wise multiplication\n",
        "        forward_prob[0, :] = self.startprob_ * self.emissionprob_[:, input_seq[0]]\n",
        "    \n",
        "        for t in range(1, input_seq_len):\n",
        "            for j in range(self.n_hidden):\n",
        "                # probability that there will be a transition from any hidden \n",
        "                # state at (t−1) to a particular state j at time step t.\n",
        "                state_j_prob = forward_prob[t - 1].dot(selt.transmat_[:, j])\n",
        "                forward_prob[t, j] = state_j_prob * self.emissionprob_[j, input_seq[t]]\n",
        "        return forward_prob\n",
        "    \n",
        "    def backward(self, input_seq):\n",
        "        \"\"\"Func to calculate backward probabilities, i.e. that the HMM will be in \n",
        "        a particular hidden state at a particular time step and will generate \n",
        "        the remaining part visible words from input_seq.\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_seq : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        Returns\n",
        "        -------\n",
        "        backward_prob : np.array, shape(n_samples, n_hidden)\n",
        "            Matrix of backward probabilities\n",
        "        \"\"\"\n",
        "        input_seq_len = input_seq.shape[0]\n",
        "        input_seq = atleast2d_or_csr(input_seq)\n",
        "\n",
        "        backward_prob = np.zeros((input_seq_len, self.n_hidden))\n",
        "        # setting last column to 1\n",
        "        backward_prob[input_seq_len - 1] = np.ones((self.n_hidden))\n",
        "    \n",
        "        # Loop in backward way from T-1 to\n",
        "        # Due to python indexing the actual loop will be T-2 to 0\n",
        "        for t in range(input_seq_len - 2, -1, -1):\n",
        "            for j in range(self.n_hidden):\n",
        "                backward_prob[t, j] = (backward_prob[t + 1] * self.emissionprob_[:, input_seq[t + 1]]).dot(self.transmat_[j, :])\n",
        "        return backward_prob\n",
        "\n",
        "    def viterbi(self, input_seq):\n",
        "        \"\"\"Func to calculate forward probabilities, i.e. that the HMM will be in \n",
        "        a particular hidden state at a particular time step after emitting first\n",
        "        t number of visible words from input_seq.\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_seq : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        Returns\n",
        "        -------\n",
        "        forward_prob : np.array, shape(n_samples, n_hidden)\n",
        "            Matrix of forward probabilities\n",
        "        \"\"\"\n",
        "        input_seq_len = input_seq.shape[0]\n",
        "        input_seq = atleast2d_or_csr(input_seq)\n",
        "    \n",
        "        omega = np.zeros((input_seq_len, self.n_hidden))\n",
        "        omega[0, :] = self.startprob_ * self.emissionprob_[:, input_seq[0]]\n",
        "    \n",
        "        prev = np.zeros((input_seq_len - 1, self.n_hidden))\n",
        "    \n",
        "        for t in range(1, input_seq_len):\n",
        "            for j in range(self.n_hidden):\n",
        "                # Same as Forward Probability\n",
        "                state_j_prob = forward_prob[t - 1].dot(selt.transmat_[:, j])\n",
        "                forward_prob[t, j] = state_j_prob * self.emissionprob_[j, input_seq[t]]\n",
        "    \n",
        "                # This is the most probable state given previous state at time t (1)\n",
        "                prev[t - 1, j] = np.argmax(forward_prob)\n",
        "    \n",
        "                # This is the probability of the most probable state (2)\n",
        "                omega[t, j] = np.max(forward_prob)\n",
        "    \n",
        "        # Path Array\n",
        "        viterbi_path = np.zeros(input_seq_len)\n",
        "        # Find the most probable last hidden state\n",
        "        last_state = np.argmax(omega[input_seq_len - 1, :])\n",
        "        viterbi_path[0] = last_state\n",
        "    \n",
        "        backtrack_index = 1\n",
        "        for i in range(input_seq_len - 2, -1, -1):\n",
        "            viterbi_path[backtrack_index] = prev[i, int(last_state)]\n",
        "            last_state = prev[i, int(last_state)]\n",
        "            backtrack_index += 1\n",
        "    \n",
        "        # Flip the path array since we were backtracking\n",
        "        viterbi_path = np.flip(viterbi_path, axis=0)\n",
        "    \n",
        "        # Convert numeric values to actual hidden states\n",
        "        result = []\n",
        "        for s in viterbi_path:\n",
        "            result.append(self.classes[s])    \n",
        "        return result\n",
        "\n",
        "    def _decode_viterbi(self, X):\n",
        "        if sp.issparse(X):\n",
        "            X = X.toarray()\n",
        "        framelogprob = self._compute_log_likelihood(X)\n",
        "        return self._do_viterbi_pass(framelogprob)\n",
        "\n",
        "    def decode(self, X, lengths=None, algorithm=None):\n",
        "        \"\"\"Find most likely state sequence corresponding to ``X``.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        lengths : array-like of integers, shape (n_sequences, ), optional\n",
        "            Lengths of the individual sequences in ``X``. The sum of\n",
        "            these should be ``n_samples``.\n",
        "        algorithm : string\n",
        "            Decoder algorithm. Must be one of \"viterbi\" or \"map\".\n",
        "            If not given, :attr:`decoder` is used.\n",
        "        Returns\n",
        "        -------\n",
        "        logprob : float\n",
        "            Log probability of the produced state sequence.\n",
        "        state_sequence : array, shape (n_samples, )\n",
        "            Labels for each sample from ``X`` obtained via a given\n",
        "            decoder ``algorithm``.\n",
        "        See Also\n",
        "        --------\n",
        "        score_samples : Compute the log probability under the model and\n",
        "            posteriors.\n",
        "        score : Compute the log probability under the model.\n",
        "        \"\"\"\n",
        "        algorithm = algorithm or self.algorithm\n",
        "        decoder = {\n",
        "            \"viterbi\": self._decode_viterbi,\n",
        "            \"map\": self._decode_map\n",
        "        }[algorithm]\n",
        "\n",
        "        X = check_array(X, accept_sparse=True)\n",
        "        n_samples = X.shape[0]\n",
        "        logprob = 0\n",
        "        state_sequence = np.empty(n_samples, dtype=int)\n",
        "        for i, j in iter_from_X_lengths(X, lengths):\n",
        "            # XXX decoder works on a single sample at a time!\n",
        "            logprobij, state_sequenceij = decoder(X[i:j])\n",
        "            logprob += logprobij\n",
        "            state_sequence[i:j] = state_sequenceij\n",
        "\n",
        "        return logprob, state_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTnesATpM0oM",
        "colab_type": "code",
        "outputId": "842635e7-4871-4389-c408-0539c604e10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "%%time \n",
        "dv = DictVectorizer(sparse=True, dtype=int)\n",
        "X_train_flatten_vect = dv.fit_transform(X_train_flatten)\n",
        "display(X_train_flatten_vect, X_train_flatten_vect.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<984882x29197 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1984430 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(984882, 29197)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.14 s, sys: 10.1 ms, total: 2.15 s\n",
            "Wall time: 2.16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ-0tspfhPO8",
        "colab_type": "code",
        "outputId": "049c502d-d345-45e1-8d3a-83b52e94ee18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "inst = my_hmm()\n",
        "inst.fit_supervised(X_train_flatten_vect, y_train_flatten, lengths=lengths_train)\n",
        "print(inst.startprob_.shape)\n",
        "print(inst.transmat_.shape)\n",
        "print(inst.emissionprob_.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO      [2020-04-11 13:17:41,539] : X is sparse. Convert to csr if needed\n",
            "(17,)\n",
            "(17, 17)\n",
            "(17, 29197)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztw5v2FsY774",
        "colab_type": "code",
        "outputId": "7e83d2df-2641-4b1c-cade-a4c7efc76d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "inst.emissionprob_.max(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99982302, 0.99978742, 0.99989626, 0.99988842, 0.99975034,\n",
              "       0.99989546, 0.99989668, 0.99989834, 0.99979614, 0.99976735,\n",
              "       0.99989588, 0.99973787, 0.99927933, 0.99989821, 0.99989834,\n",
              "       0.99989455, 0.99989863])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbZWDLm7S1zX",
        "colab_type": "code",
        "outputId": "60dc47ef-a34a-4e10-ee8b-f01e4638ac68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "inst.emissionprob_.argmax(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxeyiyYqB9J8",
        "colab_type": "code",
        "outputId": "96fa3be1-184f-4ba8-f90d-8cf51cd0bbe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "inst.predict(X_train_flatten_vect[:np.cumsum(lengths_train[:2])[-1]].toarray(), lengths_train[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ff0eb12011ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mLabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \"\"\"\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-de887a8a4651>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, X, lengths, algorithm)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlogprobij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequenceij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mlogprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogprobij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mstate_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_sequenceij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4467141) into shape (153)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qYkgWJEyHE",
        "colab_type": "code",
        "outputId": "045ec166-41d2-4730-c410-a86c410c664f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.cumsum(lengths_train[:10])[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TKIyatDC2rv",
        "colab_type": "code",
        "outputId": "537920ef-a2f7-47ab-9e91-8ee82c90fb4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "inst = my_hmm(n_components=17, verbose=2)\n",
        "inst.fit(X_train_flatten_vect[:np.cumsum(lengths_train[:2])[-1]].toarray(), lengths_train[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         1    -5220923.2498             +nan\n",
            "         2       -6305.3314    +5214617.9184\n",
            "         3       -6304.7750          +0.5564\n",
            "         4       -6304.5293          +0.2457\n",
            "         5       -6304.4086          +0.1208\n",
            "         6       -6304.3395          +0.0690\n",
            "         7       -6304.2916          +0.0480\n",
            "         8       -6304.2517          +0.0399\n",
            "         9       -6304.2142          +0.0375\n",
            "        10       -6304.1764          +0.0378\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "my_hmm(algorithm='viterbi', alpha=0.01)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ2aFve66rO8",
        "colab_type": "code",
        "outputId": "b2a71a15-2d6d-48be-a1c7-c2f2835b243c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "inst.decode(X_train_flatten_vect, lengths=lengths_train, algorithm='viterbi')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-6e71e7e0c126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viterbi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-123-6898a5c0dc3d>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, X, lengths, algorithm)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mlogprobij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequenceij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlogprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogprobij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mstate_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_sequenceij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4467141) into shape (153)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSIfTIy5oO0N",
        "colab_type": "code",
        "outputId": "ae88863b-38ae-4d25-d963-52263204f52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "gen = iter_from_X_lengths(X_train_flatten_vect, lengths_train)\n",
        "start, stop = next(gen)\n",
        "X_train_flatten_vect[start:stop]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<153x29197 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 308 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erocSfJnzqgd",
        "colab_type": "code",
        "outputId": "889473de-58af-438a-bac5-ea5f6c3a3dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_train_flatten_vect[start:stop].toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True, False,  True, ..., False, False, False],\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       [False,  True,  True, ..., False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy24LdbKppSy",
        "colab_type": "code",
        "outputId": "23811cdd-7e15-4a7b-de5b-ed1fa64129a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.concatenate(X_train_flatten_vect[start:stop].toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False,  True, ..., False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wB4nTSJpk7j",
        "colab_type": "code",
        "outputId": "29cc8be7-0722-4f1b-bb89-c8fb55d7dd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "log_mask_zero(inst.emissionprob_)[:, np.concatenate(X_train_flatten_vect[start:stop].toarray())].T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-16829817842b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_mask_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissionprob_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 29197 but corresponding boolean dimension is 4467141"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8V64UIWMiMh",
        "colab_type": "code",
        "outputId": "7087999e-5629-4430-9522-307581141c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(X_train_flatten_vect[0].todense().tolist()[0]), inst.emissionprob_.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29197, (17, 29197))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C67GbUCiwoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "safe_sparse_dot(Y.T, X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV_aXgU3xrPQ",
        "colab_type": "code",
        "outputId": "497cea46-869e-4f26-8b7c-8713ea80e845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(X_train_flatten_vect[0].todense()).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 29197)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnl3DDyUyZRH",
        "colab_type": "code",
        "outputId": "702a7690-2a62-46b0-cde8-46b692f1dad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.concatenate(np.array(X_train_flatten_vect[0].todense())).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29197,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7NL0UfuL0A0",
        "colab_type": "code",
        "outputId": "6979ee58-6a0d-41b8-add6-38f654ee42a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "inst.emissionprob_[:, X_train_flatten_vect[0].todense().tolist()[0]].T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.79724896e-03, 2.53787974e-03, 3.19320133e-04, 1.47667295e-03,\n",
              "        3.05838456e-05, 3.38702267e-04, 3.09628844e-04, 8.62532772e-04,\n",
              "        1.96475234e-05, 2.61117059e-05, 7.78138170e-04, 3.02142188e-05,\n",
              "        3.24706952e-05, 3.20515902e-06, 2.36688071e-06, 1.11486449e-05,\n",
              "        5.13995696e-05],\n",
              "       [1.79724896e-03, 2.53787974e-03, 3.19320133e-04, 1.47667295e-03,\n",
              "        3.08896841e-03, 3.38702267e-04, 3.09628844e-04, 8.62532772e-04,\n",
              "        1.98439987e-03, 2.63728229e-03, 7.78138170e-04, 3.05163610e-03,\n",
              "        3.27954021e-03, 3.23721061e-04, 2.39054952e-04, 1.12601313e-03,\n",
              "        5.13995696e-05],\n",
              "       [1.77945442e-05, 2.51275222e-05, 3.16158547e-06, 1.46205243e-05,\n",
              "        3.05838456e-05, 3.35348779e-06, 3.06563212e-06, 8.53992844e-06,\n",
              "        1.96475234e-05, 2.61117059e-05, 7.78138170e-04, 3.02142188e-05,\n",
              "        3.24706952e-05, 3.20515902e-06, 2.36688071e-06, 1.11486449e-05,\n",
              "        5.13995696e-05]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdkLUzBsK0Ls",
        "colab_type": "code",
        "outputId": "1dc6fffd-13a0-4202-92ff-2220d3375d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "inst.emissionprob_[:, [1,2,3]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.42533719e-06, 3.60999840e-01, 9.42533719e-06],\n",
              "       [1.22553525e-05, 3.19876956e-01, 1.22553525e-05],\n",
              "       [1.05579543e-04, 4.90793424e-01, 1.31809666e-07],\n",
              "       [6.07912480e-05, 4.72599328e-01, 3.02444020e-07],\n",
              "       [1.46634016e-05, 2.85950995e-01, 1.46634016e-05],\n",
              "       [5.13567771e-05, 4.88886112e-01, 2.55506354e-07],\n",
              "       [2.87985504e-07, 4.91821932e-01, 2.87985504e-07],\n",
              "       [2.69103913e-05, 4.95870854e-01, 2.66439518e-07],\n",
              "       [1.17100132e-05, 3.29063082e-01, 1.17100132e-05],\n",
              "       [1.36617621e-05, 3.00572428e-01, 1.36617621e-05],\n",
              "       [6.88611807e-07, 4.89879128e-01, 6.88611807e-07],\n",
              "       [1.53381291e-05, 2.76101661e-01, 1.53381291e-05],\n",
              "       [2.59087494e-05, 1.21797031e-01, 2.59087494e-05],\n",
              "       [3.07955278e-05, 4.95533886e-01, 3.04906215e-07],\n",
              "       [2.84058872e-07, 4.95853451e-01, 2.84058872e-07],\n",
              "       [1.81835123e-04, 4.86703872e-01, 9.04652356e-07],\n",
              "       [4.38063264e-03, 4.96572206e-01, 1.45422796e-03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehgVqF9D7kTe",
        "colab_type": "code",
        "outputId": "d67b981f-5534-4632-a025-3f7b4ea65ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "inst.emissionprob_[:, X_train_flatten_vect[0]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-4e1d5c8bb037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissionprob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Iq0uxNjTZI",
        "colab_type": "code",
        "outputId": "0be4c2d1-cfba-4f7f-9b13-8aa8e8b2b1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.unique(X_train_flatten_vect[0].todense().tolist())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH3IfP1x7465",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNHemq9HhHb1",
        "colab_type": "code",
        "outputId": "b0e37ad6-4d4c-440f-f775-a725427ccbfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "atleast2d_or_csr(X_train_flatten_vect)[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO      [2020-04-07 12:11:03,465] : X is sparse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x29197 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRfRHqOwgdWS",
        "colab_type": "code",
        "outputId": "be635a72-41dd-4047-fdd4-54673adf6a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "inst.viterbi(X_train_flatten_vect)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-6c0827312ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-7e8f3d045c35>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0momega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0momega\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartprob_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissionprob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmmtX5Iykd2I",
        "colab_type": "code",
        "outputId": "152179a7-8797-43f8-f3a3-649af19381e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "inst.emissionprob_[:, X_train_flatten_vect[0].todense()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-9033f66c877f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissionprob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt8iL4ISaeg8",
        "colab_type": "text"
      },
      "source": [
        "###Unsupervised\n",
        "use hmmlearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGHM9BdM36Xm",
        "colab_type": "code",
        "outputId": "daa2465b-54de-4418-804c-9744bcf9817f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.array(X_train_flatten).reshape(-1, 1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(984882, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZytmoLKE3MBN",
        "colab_type": "code",
        "outputId": "d1750d40-d0fe-4b8f-8534-d04fbdbfe63f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.array(X_train_flatten).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(984882,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b376pG-vy_91",
        "colab_type": "code",
        "outputId": "9b35590c-15eb-4b3a-a7a1-8e370c661790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unsupervised_hmm = hmmlearn_MHMM(n_components=unique_labels)\n",
        "unsupervised_hmm.fit(np.array(X_train_flatten).reshape(-1, 1), lengths_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-4fa41e469ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munsupervised_hmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmmlearn_MHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munsupervised_hmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \"\"\"\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIhTA47mSL0d",
        "colab_type": "text"
      },
      "source": [
        "## CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPsUagYYl0c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_rand_search(X_train, y_train, parameters):\n",
        "    search = RandomizedSearchCV(estimator=CRF(),\n",
        "                            param_distributions=parameters,\n",
        "                            n_iter=10, scoring={metric.__name__:make_scorer(_flattens_y(metric)) for metric in scoring}, \n",
        "                            n_jobs=-1,\n",
        "                            verbose=2,\n",
        "                            cv=KFold(n_splits=3, shuffle=False, random_state=42),\n",
        "                            refit='bio_f_score'#False,\n",
        "                            )\n",
        "    search.fit(X_train, y_train)\n",
        "    return search\n",
        "\n",
        "def show_reports(estimator):\n",
        "    pred_unflatten = estimator.predict(X_test)\n",
        "    bio_clf_report = evaluate_bio_clf_report(y_test, pred_unflatten, \n",
        "                                            labels=list(estimator.classes_),\n",
        "                                            do_flatten=True)\n",
        "    entity_clf_report = evaluate_entity_clf_report(y_test, pred_unflatten, lengths_test)\n",
        "    print('*****BIO-tag LEVEL*****\\n', bio_clf_report, '\\n*****ENTITY LEVEL*****\\n', entity_clf_report)\n",
        "\n",
        "def show_search_results(search):\n",
        "    full_df = pd.DataFrame(search.cv_results_)\n",
        "    df_cutted = full_df.drop([k for k in search.cv_results_.keys() if any(col in k for col in ['split','std', 'params'])], axis=1)\n",
        "\n",
        "    print('best params:', search.best_params_)\n",
        "    print('best CV score:', search.best_score_)\n",
        "    print('model size: {:0.2f}M'.format(search.best_estimator_.size_ / 1000000))\n",
        "\n",
        "    show_reports(search.best_estimator_)\n",
        "\n",
        "    return full_df, df_cutted, pred_unflatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X872piziZBlS",
        "colab_type": "text"
      },
      "source": [
        "####Simple features (bias, lower, BOS, EOS) without tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tlFaU1qTSL0k",
        "colab_type": "code",
        "outputId": "eb8c63de-d270-4061-d990-e8d84ed41117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "crf=CRF(algorithm='lbfgs',\n",
        "         c1=0.1,\n",
        "         c2=0.1,\n",
        "         max_iterations=100,\n",
        "         all_possible_transitions=False)\n",
        "\n",
        "scores = cross_validate(crf, X_train, y_train, cv=cv, n_jobs=-1, \n",
        "                        scoring={metric.__name__:make_scorer(_flattens_y(metric)) for metric in scoring}, \n",
        "                        verbose=100, return_estimator=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pickling array (shape=(5866,), dtype=int64).\n",
            "Pickling array (shape=(1467,), dtype=int64).\n",
            "Pickling array (shape=(5866,), dtype=int64).\n",
            "Pickling array (shape=(1467,), dtype=int64).\n",
            "Pickling array (shape=(5866,), dtype=int64).\n",
            "Pickling array (shape=(1467,), dtype=int64).\n",
            "Pickling array (shape=(5867,), dtype=int64).\n",
            "Pickling array (shape=(1466,), dtype=int64).\n",
            "Pickling array (shape=(5867,), dtype=int64).\n",
            "Pickling array (shape=(1466,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.0min remaining:  6.0min\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.4min remaining:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  5.8min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  5.8min finished\n",
            "CPU times: user 1min 40s, sys: 1.52 s, total: 1min 41s\n",
            "Wall time: 5min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd9e9nYgSL0m",
        "colab_type": "code",
        "outputId": "cc4ff157-a8df-42ec-d9e5-300dac27e769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "pd.DataFrame({k:v for k,v in scores.items() if 'test_' in k})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_bio_f_score</th>\n",
              "      <th>test_f1_macro</th>\n",
              "      <th>test_fbeta_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.767883</td>\n",
              "      <td>0.556919</td>\n",
              "      <td>0.520987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.789853</td>\n",
              "      <td>0.622899</td>\n",
              "      <td>0.578765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.785177</td>\n",
              "      <td>0.584575</td>\n",
              "      <td>0.556278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.780904</td>\n",
              "      <td>0.591135</td>\n",
              "      <td>0.566910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.791902</td>\n",
              "      <td>0.602960</td>\n",
              "      <td>0.570546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_bio_f_score  test_f1_macro  test_fbeta_macro\n",
              "0          0.767883       0.556919          0.520987\n",
              "1          0.789853       0.622899          0.578765\n",
              "2          0.785177       0.584575          0.556278\n",
              "3          0.780904       0.591135          0.566910\n",
              "4          0.791902       0.602960          0.570546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtkpMcX1tqus",
        "colab_type": "code",
        "outputId": "401a7ef2-77b7-495c-b822-32f2564567ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "source": [
        "show_reports(np.random.choice(scores['estimator']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****BIO-tag LEVEL*****\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       B-art      0.100     0.014     0.024        72\n",
            "       I-art      0.000     0.000     0.000        54\n",
            "       B-eve      0.588     0.364     0.449        55\n",
            "       I-eve      0.344     0.268     0.301        41\n",
            "       B-geo      0.852     0.854     0.853      9387\n",
            "       I-geo      0.773     0.731     0.751      1744\n",
            "       B-gpe      0.966     0.943     0.954      3843\n",
            "       I-gpe      0.724     0.583     0.646        36\n",
            "       B-nat      0.889     0.267     0.410        30\n",
            "       I-nat      0.714     0.625     0.667         8\n",
            "       B-org      0.805     0.535     0.643      4999\n",
            "       I-org      0.677     0.568     0.618      4274\n",
            "       B-per      0.837     0.710     0.768      4291\n",
            "       I-per      0.814     0.845     0.829      4343\n",
            "       B-tim      0.933     0.758     0.836      4691\n",
            "       I-tim      0.776     0.613     0.685      1415\n",
            "\n",
            "   micro avg      0.837     0.744     0.787     39283\n",
            "   macro avg      0.675     0.542     0.590     39283\n",
            "weighted avg      0.832     0.744     0.782     39283\n",
            " \n",
            "*****ENTITY LEVEL*****\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "      geo       0.84      0.84      0.84      9387\n",
            "      tim       0.90      0.73      0.80      4691\n",
            "      org       0.71      0.47      0.57      4999\n",
            "      gpe       0.96      0.94      0.95      3843\n",
            "      per       0.75      0.63      0.69      4291\n",
            "      art       0.10      0.01      0.02        72\n",
            "      eve       0.47      0.29      0.36        55\n",
            "      nat       0.89      0.27      0.41        30\n",
            "\n",
            "micro avg       0.84      0.73      0.78     27368\n",
            "macro avg       0.83      0.73      0.77     27368\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNm0OHjjfbeF",
        "colab_type": "text"
      },
      "source": [
        "#### All features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwQJMwalA1f2",
        "colab_type": "text"
      },
      "source": [
        "#### GB methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22x6QgNVWo2l",
        "colab_type": "code",
        "outputId": "72747953-faff-4b9b-8c1b-43f8530f52e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "parameters = {'algorithm': ['lbfgs'], \n",
        "              'c1': [0.1, 0.01], \n",
        "              'c2': [0.1, 0.01],\n",
        "              'all_possible_transitions': [True, False]}\n",
        "\n",
        "search = run_rand_search(X_train, y_train, parameters)\n",
        "full_df, df_cutted, pred_unflatten = show_search_results(search)\n",
        "df_cutted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 575.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best params: {'c2': 0.1, 'c1': 0.1, 'all_possible_transitions': True, 'algorithm': 'lbfgs'}\n",
            "best CV score: 0.8442490525177447\n",
            "model size: 3.13M\n",
            "*****BIO-tag LEVEL*****\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       B-art      0.452     0.194     0.272        72\n",
            "       I-art      0.467     0.259     0.333        54\n",
            "       B-eve      0.386     0.309     0.343        55\n",
            "       I-eve      0.194     0.146     0.167        41\n",
            "       B-geo      0.872     0.910     0.890      9387\n",
            "       I-geo      0.813     0.818     0.815      1744\n",
            "       B-gpe      0.974     0.956     0.965      3843\n",
            "       I-gpe      0.812     0.722     0.765        36\n",
            "       B-nat      0.846     0.367     0.512        30\n",
            "       I-nat      0.833     0.625     0.714         8\n",
            "       B-org      0.805     0.729     0.765      4999\n",
            "       I-org      0.822     0.782     0.802      4274\n",
            "       B-per      0.836     0.839     0.838      4291\n",
            "       I-per      0.835     0.893     0.863      4343\n",
            "       B-tim      0.923     0.876     0.898      4691\n",
            "       I-tim      0.829     0.700     0.759      1415\n",
            "\n",
            "   micro avg      0.860     0.848     0.854     39283\n",
            "   macro avg      0.731     0.633     0.669     39283\n",
            "weighted avg      0.859     0.848     0.852     39283\n",
            " \n",
            "*****ENTITY LEVEL*****\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "      per       0.77      0.77      0.77      4291\n",
            "      tim       0.90      0.85      0.88      4691\n",
            "      nat       0.85      0.37      0.51        30\n",
            "      gpe       0.97      0.96      0.96      3843\n",
            "      geo       0.87      0.90      0.89      9387\n",
            "      org       0.77      0.70      0.74      4999\n",
            "      eve       0.36      0.29      0.32        55\n",
            "      art       0.45      0.19      0.27        72\n",
            "\n",
            "micro avg       0.85      0.84      0.85     27368\n",
            "macro avg       0.85      0.84      0.85     27368\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>param_c2</th>\n",
              "      <th>param_c1</th>\n",
              "      <th>param_all_possible_transitions</th>\n",
              "      <th>param_algorithm</th>\n",
              "      <th>mean_test_bio_f_score</th>\n",
              "      <th>rank_test_bio_f_score</th>\n",
              "      <th>mean_test_f1_macro</th>\n",
              "      <th>rank_test_f1_macro</th>\n",
              "      <th>mean_test_fbeta_macro</th>\n",
              "      <th>rank_test_fbeta_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5078.268208</td>\n",
              "      <td>13.006236</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.844249</td>\n",
              "      <td>1</td>\n",
              "      <td>0.639689</td>\n",
              "      <td>3</td>\n",
              "      <td>0.623642</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7884.569026</td>\n",
              "      <td>14.014825</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.839618</td>\n",
              "      <td>6</td>\n",
              "      <td>0.633747</td>\n",
              "      <td>6</td>\n",
              "      <td>0.620083</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5042.338612</td>\n",
              "      <td>13.442750</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>True</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.843070</td>\n",
              "      <td>4</td>\n",
              "      <td>0.639646</td>\n",
              "      <td>4</td>\n",
              "      <td>0.624001</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8294.303088</td>\n",
              "      <td>12.860991</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>True</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.833200</td>\n",
              "      <td>8</td>\n",
              "      <td>0.624828</td>\n",
              "      <td>7</td>\n",
              "      <td>0.614282</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3874.859576</td>\n",
              "      <td>13.421319</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>False</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.844139</td>\n",
              "      <td>2</td>\n",
              "      <td>0.640371</td>\n",
              "      <td>2</td>\n",
              "      <td>0.624631</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5902.170344</td>\n",
              "      <td>14.100148</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.1</td>\n",
              "      <td>False</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.839809</td>\n",
              "      <td>5</td>\n",
              "      <td>0.635455</td>\n",
              "      <td>5</td>\n",
              "      <td>0.623602</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3715.930987</td>\n",
              "      <td>13.114199</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.843072</td>\n",
              "      <td>3</td>\n",
              "      <td>0.641796</td>\n",
              "      <td>1</td>\n",
              "      <td>0.627176</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4059.283186</td>\n",
              "      <td>8.828271</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.833361</td>\n",
              "      <td>7</td>\n",
              "      <td>0.623698</td>\n",
              "      <td>8</td>\n",
              "      <td>0.613546</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  ... mean_test_fbeta_macro rank_test_fbeta_macro\n",
              "0    5078.268208        13.006236  ...              0.623642                     4\n",
              "1    7884.569026        14.014825  ...              0.620083                     6\n",
              "2    5042.338612        13.442750  ...              0.624001                     3\n",
              "3    8294.303088        12.860991  ...              0.614282                     7\n",
              "4    3874.859576        13.421319  ...              0.624631                     2\n",
              "5    5902.170344        14.100148  ...              0.623602                     5\n",
              "6    3715.930987        13.114199  ...              0.627176                     1\n",
              "7    4059.283186         8.828271  ...              0.613546                     8\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eXPr1Nyl_2_",
        "colab_type": "code",
        "outputId": "5cf23fcc-1ffc-4345-dbe7-e2d7c568849c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "parameters = {'algorithm': ['l2sgd'], \n",
        "              'c2': [0.1, 0.01],\n",
        "              'all_possible_transitions': [True, False]}\n",
        "\n",
        "search = run_rand_search(X_train, y_train, parameters)\n",
        "full_df, df_cutted, pred_unflatten = show_search_results(search)\n",
        "df_cutted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 36.5min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 36.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best params: {'c2': 0.1, 'all_possible_transitions': True, 'algorithm': 'l2sgd'}\n",
            "best CV score: 0.8391407477825762\n",
            "model size: 8.93M\n",
            "*****BIO-tag LEVEL*****\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       B-art      0.419     0.181     0.252        72\n",
            "       I-art      0.370     0.185     0.247        54\n",
            "       B-eve      0.386     0.309     0.343        55\n",
            "       I-eve      0.222     0.244     0.233        41\n",
            "       B-geo      0.848     0.929     0.886      9387\n",
            "       I-geo      0.769     0.833     0.799      1744\n",
            "       B-gpe      0.974     0.956     0.965      3843\n",
            "       I-gpe      0.844     0.750     0.794        36\n",
            "       B-nat      0.684     0.433     0.531        30\n",
            "       I-nat      0.714     0.625     0.667         8\n",
            "       B-org      0.829     0.701     0.760      4999\n",
            "       I-org      0.857     0.743     0.796      4274\n",
            "       B-per      0.819     0.839     0.829      4291\n",
            "       I-per      0.814     0.908     0.858      4343\n",
            "       B-tim      0.921     0.881     0.900      4691\n",
            "       I-tim      0.832     0.706     0.764      1415\n",
            "\n",
            "   micro avg      0.853     0.847     0.850     39283\n",
            "   macro avg      0.706     0.639     0.664     39283\n",
            "weighted avg      0.854     0.847     0.848     39283\n",
            " \n",
            "*****ENTITY LEVEL*****\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "      per       0.75      0.77      0.76      4291\n",
            "      tim       0.90      0.86      0.88      4691\n",
            "      nat       0.68      0.43      0.53        30\n",
            "      gpe       0.97      0.96      0.96      3843\n",
            "      geo       0.84      0.92      0.88      9387\n",
            "      org       0.80      0.67      0.73      4999\n",
            "      eve       0.36      0.29      0.32        55\n",
            "      art       0.42      0.18      0.25        72\n",
            "\n",
            "micro avg       0.85      0.84      0.84     27368\n",
            "macro avg       0.85      0.84      0.84     27368\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>param_c2</th>\n",
              "      <th>param_all_possible_transitions</th>\n",
              "      <th>param_algorithm</th>\n",
              "      <th>mean_test_bio_f_score</th>\n",
              "      <th>rank_test_bio_f_score</th>\n",
              "      <th>mean_test_f1_macro</th>\n",
              "      <th>rank_test_f1_macro</th>\n",
              "      <th>mean_test_fbeta_macro</th>\n",
              "      <th>rank_test_fbeta_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>537.090520</td>\n",
              "      <td>15.092035</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>l2sgd</td>\n",
              "      <td>0.839141</td>\n",
              "      <td>1</td>\n",
              "      <td>0.627980</td>\n",
              "      <td>4</td>\n",
              "      <td>0.616956</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>454.976540</td>\n",
              "      <td>14.281680</td>\n",
              "      <td>0.01</td>\n",
              "      <td>True</td>\n",
              "      <td>l2sgd</td>\n",
              "      <td>0.826727</td>\n",
              "      <td>4</td>\n",
              "      <td>0.635371</td>\n",
              "      <td>3</td>\n",
              "      <td>0.623382</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>639.355750</td>\n",
              "      <td>14.025988</td>\n",
              "      <td>0.1</td>\n",
              "      <td>False</td>\n",
              "      <td>l2sgd</td>\n",
              "      <td>0.839034</td>\n",
              "      <td>2</td>\n",
              "      <td>0.639518</td>\n",
              "      <td>2</td>\n",
              "      <td>0.624699</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>397.214507</td>\n",
              "      <td>8.920340</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>l2sgd</td>\n",
              "      <td>0.835731</td>\n",
              "      <td>3</td>\n",
              "      <td>0.645080</td>\n",
              "      <td>1</td>\n",
              "      <td>0.626771</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  ... mean_test_fbeta_macro rank_test_fbeta_macro\n",
              "0     537.090520        15.092035  ...              0.616956                     4\n",
              "1     454.976540        14.281680  ...              0.623382                     3\n",
              "2     639.355750        14.025988  ...              0.624699                     2\n",
              "3     397.214507         8.920340  ...              0.626771                     1\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcPk8a5EA6Lk",
        "colab_type": "text"
      },
      "source": [
        "#### Non-GB methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lFlBTr7BHTw",
        "colab_type": "code",
        "outputId": "1710ff08-92f2-4d3a-add5-744b7711a03e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "parameters = {'algorithm': ['ap', 'pa', 'arow']}\n",
        "\n",
        "search = run_rand_search(X_train, y_train, parameters)\n",
        "full_df, df_cutted, pred_unflatten = show_search_results(search)\n",
        "df_cutted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed: 16.2min remaining:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 18.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best params: {'algorithm': 'pa'}\n",
            "best CV score: 0.8419118105485338\n",
            "model size: 5.10M\n",
            "*****BIO-tag LEVEL*****\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       B-art      0.381     0.222     0.281        72\n",
            "       I-art      0.481     0.241     0.321        54\n",
            "       B-eve      0.438     0.382     0.408        55\n",
            "       I-eve      0.303     0.244     0.270        41\n",
            "       B-geo      0.871     0.909     0.890      9387\n",
            "       I-geo      0.813     0.814     0.814      1744\n",
            "       B-gpe      0.970     0.957     0.964      3843\n",
            "       I-gpe      0.844     0.750     0.794        36\n",
            "       B-nat      0.812     0.433     0.565        30\n",
            "       I-nat      1.000     0.625     0.769         8\n",
            "       B-org      0.800     0.729     0.763      4999\n",
            "       I-org      0.845     0.764     0.802      4274\n",
            "       B-per      0.826     0.841     0.833      4291\n",
            "       I-per      0.832     0.895     0.862      4343\n",
            "       B-tim      0.921     0.879     0.900      4691\n",
            "       I-tim      0.853     0.683     0.759      1415\n",
            "\n",
            "   micro avg      0.861     0.846     0.853     39283\n",
            "   macro avg      0.749     0.648     0.687     39283\n",
            "weighted avg      0.860     0.846     0.852     39283\n",
            " \n",
            "*****ENTITY LEVEL*****\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "      per       0.76      0.77      0.76      4291\n",
            "      tim       0.90      0.86      0.88      4691\n",
            "      nat       0.81      0.43      0.57        30\n",
            "      gpe       0.97      0.96      0.96      3843\n",
            "      geo       0.87      0.90      0.88      9387\n",
            "      org       0.77      0.70      0.73      4999\n",
            "      eve       0.42      0.36      0.39        55\n",
            "      art       0.38      0.22      0.28        72\n",
            "\n",
            "micro avg       0.85      0.84      0.85     27368\n",
            "macro avg       0.85      0.84      0.84     27368\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>param_algorithm</th>\n",
              "      <th>mean_test_bio_f_score</th>\n",
              "      <th>rank_test_bio_f_score</th>\n",
              "      <th>mean_test_f1_macro</th>\n",
              "      <th>rank_test_f1_macro</th>\n",
              "      <th>mean_test_fbeta_macro</th>\n",
              "      <th>rank_test_fbeta_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>215.801909</td>\n",
              "      <td>12.645297</td>\n",
              "      <td>ap</td>\n",
              "      <td>0.840907</td>\n",
              "      <td>2</td>\n",
              "      <td>0.643963</td>\n",
              "      <td>2</td>\n",
              "      <td>0.627523</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246.379716</td>\n",
              "      <td>11.997287</td>\n",
              "      <td>pa</td>\n",
              "      <td>0.841912</td>\n",
              "      <td>1</td>\n",
              "      <td>0.645208</td>\n",
              "      <td>1</td>\n",
              "      <td>0.628318</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>205.178590</td>\n",
              "      <td>8.887510</td>\n",
              "      <td>arow</td>\n",
              "      <td>0.755875</td>\n",
              "      <td>3</td>\n",
              "      <td>0.578727</td>\n",
              "      <td>3</td>\n",
              "      <td>0.572033</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  ... mean_test_fbeta_macro  rank_test_fbeta_macro\n",
              "0     215.801909        12.645297  ...              0.627523                      2\n",
              "1     246.379716        11.997287  ...              0.628318                      1\n",
              "2     205.178590         8.887510  ...              0.572033                      3\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww7d_H8byxmK",
        "colab_type": "text"
      },
      "source": [
        "##Bi-LSTM:\n",
        "Use keras or tensorflow;  \n",
        "https://github.com/hse-aml/natural-language-processing/blob/master/week2/week2-NER.ipynb  \n",
        "A plus for incorporating CNN-layers;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfBwo2Sv7UTP",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Wd4uIMWkQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "750aca8e-bd01-455e-832d-08037f0c19a3"
      },
      "source": [
        "maxlen = 170\n",
        "\n",
        "words = list(set(voa_data[\"word\"].values))\n",
        "\n",
        "words.append(\"ENDPAD\")\n",
        "#unique_labels = np.append(unique_labels, \"ENDPAD\")\n",
        "\n",
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i, t in enumerate(unique_labels)}\n",
        "\n",
        "len(word2idx), len(tag2idx)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35155, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBRxidduZ1bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [[word2idx[w[0]] for w in s] for s in word_pos_tag_sentences]\n",
        "X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\", value=len(words) - 1) # ENDPAD\n",
        "\n",
        "y = [[tag2idx[w[2]] for w in s] for s in word_pos_tag_sentences]\n",
        "y = pad_sequences(maxlen=maxlen, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
        "y = np.apply_along_axis(lambda x: to_categorical(x, num_classes=len(unique_labels)), axis=1, arr=y)\n",
        "\n",
        "#make a split while the data is still sequential\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=False, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2ElDrze7Wu9",
        "colab_type": "text"
      },
      "source": [
        "### Bi-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvcUFPRdXGJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    input = Input(shape=(maxlen,))\n",
        "    masked_input = Masking(mask_value=len(words)-1)(input)\n",
        "    model = Embedding(input_dim=len(words), output_dim=maxlen, input_length=maxlen)(masked_input)\n",
        "    model = Dropout(0.1)(model)\n",
        "    model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "    out = TimeDistributed(Dense(len(unique_labels), activation=\"softmax\"))(model)  # softmax output layer\n",
        "    model = Model(input, out)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF_iP1i-7Nhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def launch_nn(get_model, X_train, y_train, callbacks, **kwargs):\n",
        "    k.clear_session()\n",
        "    model = get_model()\n",
        "    print(model.summary())\n",
        "\n",
        "    history = model.fit(X_train, y_train, batch_size=32, validation_split=0.2, \n",
        "                        verbose=1, callbacks=callbacks, epochs=50, **kwargs)\n",
        "    \n",
        "    return trained_model\n",
        "\n",
        "\n",
        "def estimate_nn(get_model, X_train, y_train, X_test, y_test, **kwargs):\n",
        "    \n",
        "    trained_model = launch_nn(get_model, X_train, y_train, **kwargs)\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    pred_tags = unique_labels[np.argmax(pred, axis=2)]\n",
        "    test_tags = unique_labels[np.argmax(y_test, axis=2)]\n",
        "\n",
        "    bio_clf_report = evaluate_bio_clf_report(test_tags, pred_tags, \n",
        "                                        labels=list(tag2idx.keys()),\n",
        "                                        do_flatten=True)\n",
        "    entity_clf_report = evaluate_entity_clf_report(test_tags.tolist(), pred_tags.tolist(), lengths_test)\n",
        "    print('*****BIO-tag LEVEL*****\\n', bio_clf_report, '\\n*****ENTITY LEVEL*****\\n', entity_clf_report)\n",
        "\n",
        "    scores = dict((metric.__name__, []) for metric in scoring)\n",
        "    for metric in scoring:\n",
        "        scores[metric.__name__].append(metric(flatten(test_tags), flatten(pred_tags)))\n",
        "    return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7p4PwQI5n4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "d1e80ca8-eeb1-4bb7-9554-4241fd583609"
      },
      "source": [
        "%%time \n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, \n",
        "                   min_delta=0.001, restore_best_weights=True)\n",
        "callbacks = [es]\n",
        "\n",
        "scores = estimate_nn(get_model, X_train, y_train, X_test, y_test,\n",
        "                     callbacks=callbacks)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 170)               0         \n",
            "_________________________________________________________________\n",
            "masking_1 (Masking)          (None, 170)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 170, 170)          5976350   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 170, 170)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 170, 200)          216800    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 170, 17)           3417      \n",
            "=================================================================\n",
            "Total params: 6,196,567\n",
            "Trainable params: 6,196,567\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 5866 samples, validate on 1467 samples\n",
            "Epoch 1/50\n",
            "1344/5866 [=====>........................] - ETA: 42s - loss: 1.1609 - accuracy: 0.8494"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-220-c17588baa64c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, \\n                   min_delta=0.001, restore_best_weights=True)\\ncallbacks = [es]\\n\\nscores = estimate_nn(get_model, X_train, y_train, X_test, y_test,\\n                     callbacks=callbacks)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-219-f56ab0096e52>\u001b[0m in \u001b[0;36mestimate_nn\u001b[0;34m(get_model, X_train, y_train, X_test, y_test, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mestimate_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaunch_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-219-f56ab0096e52>\u001b[0m in \u001b[0;36mlaunch_nn\u001b[0;34m(get_model, X_train, y_train, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     history = model.fit(X_train, y_train, batch_size=32, validation_split=0.2, \n\u001b[0;32m----> 7\u001b[0;31m                         verbose=1, callbacks=callbacks, epochs=50, **kwargs)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgQxvQPD54qV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f9a54961-0af6-41e1-8f9f-1db2f1087aec"
      },
      "source": [
        "scores"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bio_f_score': [0.785052698818269],\n",
              " 'f1_macro': [0.4823028211731934],\n",
              " 'fbeta_macro': [0.4729998396986362]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    }
  ]
}