{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# About notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "Dataset\n",
    "*\tGroningen Meaning Bank (version 2.2.0)\n",
    "*\tTask: named entity recognition\n",
    "*\tTarget – named entity tags (BIO + entity type)\n",
    "*\tInput data: \n",
    "  * Use “en.met” files to extract the subcorpus\n",
    "  corpus = 'Voice of America' (for honogeneity of the input data set)\n",
    "  * Use \"en.tags\" files for the main input data:\n",
    "      *\traw tokens + may use the lemmas and the POS-tags \n",
    "  (i.e. take the “golden” POS-tagging);\n",
    "      *\twhich means:\n",
    "        *\tfirst three columns for input: ['word', 'pos', 'lemma']\n",
    "        *\tthe fourth column for target variable (‘ne_tags’)\n",
    "        (BIO annotation + the named-entity type in one tag)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "1.\tThe most trivial model = supervised HMM:\n",
    "  *\tTake hmmlearn (former sklearn), modify MultinomialHMM (I.e. inherit a new class from _BaseHMM making it a modified copy of the latter) to allow for supervised HMM training. The states of the HMM model = the NE tags.\n",
    "  *\tNOTE: may use NaiveBayes to learn emission probabilities in a supervized manner.\n",
    "  *\tOr implement from scratch (with Viterbi for prediction).\n",
    "  *\tNOTE: use tuples of features for X (not just the word, but additional info).\n",
    "  *\tNOTE: use smoothing for state transitions.\n",
    "2.\tCRF\n",
    "  *\tModify the input features;\n",
    "  *\tUse CRFSuite.\n",
    "3.\tBi-LSTM:\n",
    "  *\tUse keras or tensorflow;\n",
    "  *\thttps://github.com/hse-aml/natural-language-processing/blob/master/week2/week2-NER.ipynb\n",
    "  *\tA plus for incorporating CNN-layers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "* normalized confusion matrices, precision, recall, F-score \n",
    "(macro- and micro-) \n",
    "* (token level, entity level, partial matching (i.e. boundary-detection problem), binary).  \n",
    "NOTE: taking into account vocabulary transfer is a plus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/  \n",
    "http://larsmans.github.io/seqlearn/reference.html#module-seqlearn.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# Evaluation Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "Scoring (14.5 max):  \n",
    "*\tDataset overview – 0.5\n",
    "  *\ttext lengths, vocabulary size, frequencies of patterns (<UNK-type-i>) \n",
    "  *\tstats over the target tags\n",
    "*\tFeature engineering – 2 (1+1)\n",
    "  *\tgrammatical words = closed set (~ stop words)\n",
    "  *\tStemming + POS\n",
    "  *\tWord shape\n",
    "  *\tAd hoc features ( +1)  \n",
    "*\tWord patterns -> encode types of unknown words +0.5\n",
    "*\tSmoothing in HMM – 0.5 \n",
    "  *\tIn HMM: for state transitions.\n",
    "*\tIncorporating tupled features in HMM (on top of tokens) – 1\n",
    "*\tThe correct HMM implementation – 1\n",
    "*\tMore fine-grained feature engineering for the Neural Network + 0.5\n",
    "  *\tDifferentiate between POS-relevancy for the word and the context, etc.\n",
    "  *\tSentence-level features (may use “golden” sentence-splitting)\n",
    "*\tEvaluation (on all levels) – 1\n",
    "*\tConclusion on HMM deficiency (as a model) – 1\n",
    "*\tCRF: 1 point for use and evaluation, + 0.5 points for comparison and conclusions;\n",
    "*\tNN:\n",
    "  *\tMain network: 4\n",
    "  *\tCNN layers: +2  \n",
    "\n",
    "Libraries: hmmlearn, crfsuite, tensorflow, keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30D0Scxk4kn3"
   },
   "source": [
    "# Libs import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ZnXUdrxQ3TAN",
    "outputId": "910fb799-41ed-4c9b-98ca-55a44b62566f"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "import os\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VD2z8D2V7Dod"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "auzLnrdK51Rg",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data found: ['p00', 'p01', 'p02', 'p03', 'p04', 'p05', 'p06', 'p07', 'p08', 'p09', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'p66', 'p67', 'p68', 'p69', 'p70', 'p71', 'p72', 'p73', 'p74', 'p75', 'p76', 'p77', 'p78', 'p79', 'p80', 'p81', 'p82', 'p83', 'p84', 'p85', 'p86', 'p87', 'p88', 'p89', 'p90', 'p91', 'p92', 'p93', 'p94', 'p95', 'p96', 'p97', 'p98', 'p99']\n"
     ]
    }
   ],
   "source": [
    "data_path = 'D:\\Data\\gmb-2.2.0\\data'\n",
    "print('data found:', os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcorpus = 'Voice of America'\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "tgwhO8ngi-A4"
   },
   "source": [
    "Parsing data from \"Voice of America\" subcorpus. According to the instructions we take first four columns and additional column to separate data on texts, sentences or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "-UBeZ_eui-A5",
    "outputId": "5308f75a-eaa2-42e3-ecae-4f6aa512ec36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [08:55<00:00,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "voa_data = pd.DataFrame(columns=['word', 'pos', 'lemma', 'ne_tags', 'text_id'])\n",
    "\n",
    "os.chdir(data_path)\n",
    "part_paths = os.listdir()\n",
    "\n",
    "for part_path in tqdm(part_paths, total=len(part_paths)):\n",
    "    os.chdir(part_path)\n",
    "    document_paths = os.listdir()\n",
    "    for document_path in document_paths:\n",
    "        os.chdir(document_path)\n",
    "        f = codecs.open(\"en.met\", 'r', \"utf_8_sig\")\n",
    "        file_met = f.read()\n",
    "        if ('subcorpus: {}'.format(subcorpus) in file_met):\n",
    "            tags_df = pd.read_csv('en.tags',\n",
    "                                  sep='\\t',\n",
    "                                  header=None,\n",
    "                                  names=['word', 'pos', 'lemma', 'ne_tags'],\n",
    "                                  usecols=[0, 1, 2, 3],\n",
    "                                  error_bad_lines=False)\n",
    "            tags_df['text_id'] = str(part_path) + '_' + str(document_path)\n",
    "            voa_data = voa_data.append(tags_df, ignore_index=True)\n",
    "        f.close()\n",
    "        os.chdir('..')\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_memory_usage(df):\n",
    "    print(\"memory usage: \", df.memory_usage().sum()/1024/1024, \" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "UX1ViqnKi-A-",
    "outputId": "c391cb23-3288-4f4f-db22-f5afc86f4fa2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage:  46.969688415527344  MB\n"
     ]
    }
   ],
   "source": [
    "show_memory_usage(voa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrator</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos         lemma ne_tags    text_id\n",
       "0      Thousands  NNS      thousand       O  p00_d0018\n",
       "1             of   IN            of       O  p00_d0018\n",
       "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
       "3           have  VBP          have       O  p00_d0018\n",
       "4        marched  VBN         march       O  p00_d0018"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "kUrX7pvxi-BB",
    "outputId": "f42abe57-ad1b-4a64-a7b3-6bf93acb5155",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1231279, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "8vWQ-w4Qi-BF"
   },
   "source": [
    "Number of tokens coincided with the declared in README file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "voa_data.to_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "15GVrJYa717o"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrator</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos         lemma ne_tags    text_id\n",
       "0      Thousands  NNS      thousand       O  p00_d0018\n",
       "1             of   IN            of       O  p00_d0018\n",
       "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
       "3           have  VBP          have       O  p00_d0018\n",
       "4        marched  VBN         march       O  p00_d0018"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data = pd.read_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus))\n",
    "voa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "b1Y2cJhli-BG",
    "outputId": "31c7858e-e9f0-45de-fd83-9c7ff746db38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average text length:  134.31646121959201\n"
     ]
    }
   ],
   "source": [
    "def average_text_length(text_id):\n",
    "    doc_lengths = list(dict(Counter(text_id)).values())\n",
    "    sum = 0\n",
    "    for length in doc_lengths:\n",
    "        sum += length\n",
    "    return sum/len(doc_lengths)\n",
    "\n",
    "print(\"average text length: \", average_text_length(voa_data['text_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>35154</td>\n",
       "      <td>48</td>\n",
       "      <td>27209</td>\n",
       "      <td>25</td>\n",
       "      <td>9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>61398</td>\n",
       "      <td>168817</td>\n",
       "      <td>74941</td>\n",
       "      <td>1032479</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word      pos    lemma  ne_tags    text_id\n",
       "count   1231279  1231279  1231279  1231279    1231279\n",
       "unique    35154       48    27209       25       9167\n",
       "top         the       NN      the        O  p00_d0090\n",
       "freq      61398   168817    74941  1032479        388"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O          1032479\n",
       "geo-nam      55480\n",
       "org-nam      44646\n",
       "per-nam      22931\n",
       "gpe-nam      19685\n",
       "tim-dow      11398\n",
       "tim-dat      10929\n",
       "per-tit       9672\n",
       "per-fam       8098\n",
       "[]            4064\n",
       "tim-moy       3811\n",
       "tim-yoc       3009\n",
       "per-giv       2376\n",
       "tim-clo        810\n",
       "art-nam        789\n",
       "eve-nam        514\n",
       "nat-nam        280\n",
       "tim-nam        132\n",
       "eve-ord         63\n",
       "per-ini         55\n",
       "per-ord         35\n",
       "org-leg         13\n",
       "tim-dom          8\n",
       "art-add          1\n",
       "per-mid          1\n",
       "Name: ne_tags, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data['ne_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificators work better if avoid redundant granularity. Also such detailed fragmentation has no value for the task of only finding named entities. Thus, we can combine subcategories and leave only first part of tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O      1032479\n",
       "geo      55480\n",
       "org      44659\n",
       "per      43168\n",
       "tim      30097\n",
       "gpe      19685\n",
       "[]        4064\n",
       "art        790\n",
       "eve        577\n",
       "nat        280\n",
       "Name: ne_tags, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data['ne_tags'] = voa_data['ne_tags'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "voa_data['ne_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_prev_value_decorator(func):\n",
    "    prev_tag = \"O\"\n",
    "\n",
    "    def wrapper(curr_tag, **kwargs):\n",
    "        nonlocal prev_tag\n",
    "        bio_tag = func(curr_tag, prev_tag)\n",
    "        prev_tag = curr_tag\n",
    "        return bio_tag\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@use_prev_value_decorator\n",
    "# Tag tokens with standard NLP BIO tags\n",
    "def bio_tagger(curr_tag, prev_tag):\n",
    "    if curr_tag == \"O\":  #O\n",
    "        return curr_tag\n",
    "    elif curr_tag != \"O\" and prev_tag == \"O\":  # Begin NE\n",
    "        return \"B-\" + curr_tag\n",
    "    elif prev_tag != \"O\" and prev_tag == curr_tag:  # Inside NE\n",
    "        return \"I-\" + curr_tag\n",
    "    elif prev_tag != \"O\" and prev_tag != curr_tag:  # Adjacent NE\n",
    "        return \"B-\" + curr_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 764 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "voa_data['bio_tag'] = voa_data['ne_tags'].apply(bio_tagger, axis=1)\n",
    "\n",
    "voa_data['bio_tag'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible investigation: check if loop for column would be faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_sentences(df, word_col='word', pos_col='pos', \n",
    "                  tag_col='bio_tag', id_col='text_id'):\n",
    "    \"\"\"func to get the sentences in this format:\n",
    "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_n, Tag_n)]\"\"\"\n",
    "    \n",
    "    agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[word_col].values.tolist(),\n",
    "                                                       s[pos_col].values.tolist(),\n",
    "                                                       s[tag_col].values.tolist())]\n",
    "    grouped = df.groupby(id_col).apply(agg_func)\n",
    "    sentences = [s for s in grouped]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_pos_tag_sentences = get_sentences(voa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets visualize how the sentences are distributed by their length\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist([len(s) for s in word_pos_tag_sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "create featuretfransformer like in https://www.depends-on-the-definition.com/introduction-named-entity-recognition-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:], #replace with BPE\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def get_sent_labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "X = [sent2features(s) for s in word_pos_tag_sentences]\n",
    "y = [get_sent_labels(s) for s in word_pos_tag_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# le.fit(y[:2])\n",
    "\n",
    "# le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from seqlearn.evaluation import SequenceKFold\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from seqlearn.evaluation import bio_f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoring = make_scorer(roc_auc_score, needs_proba=True, average='weighted', multi_class='ovr')\n",
    "scoring = make_scorer(bio_f_score)\n",
    "cv = ShuffleSplit(n_splits=2, test_size=0.3, random_state=42)\n",
    "#cv = SequenceKFold(lengths, n_folds=3, n_iter=1, shuffle=False, random_state=None, yield_lengths=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8APgvUyskaf"
   },
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lengths = [len(x) for x in X_train]\n",
    "\n",
    "flatten_X = [item for sublist in X_train for item in sublist]\n",
    "\n",
    "flatten_y = [item for sublist in y_train for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqlearn.hmm import MultinomialHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = MultinomialHMM(decode='viterbi', alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(flatten_X) == np.array(lengths).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-597a18c9dda5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mflatten_X_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\feature_extraction\\_dict_vectorizer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mFeature\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0malways\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\feature_extraction\\_dict_vectorizer.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, fitting)\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mresult_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mresult_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfitting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    945\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "flatten_X_vec = dv.fit_transform(flatten_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm.fit(flatten_X_vec[:10])\n",
    "pred = hmm.predict(flatten_X_vec[:10])\n",
    "bio_f_score(flatten_y[:10], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to pass length to pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer', DictVectorizer(sparse=False)),\n",
    "                 ('seq_clf', hmm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "Memmapping (shape=(689230,), dtype=int32) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_25472_4540203103\\25472-2485368498104-b118afe67c4f470bb25d211231fc461b.pkl\n",
      "Memmapping (shape=(295385,), dtype=int32) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_25472_4540203103\\25472-2485368498104-bff69a7dd193433a8ad70e1bbd5d2785.pkl\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.6min\n",
      "Memmapping (shape=(689230,), dtype=int32) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_25472_4540203103\\25472-2485368498104-4732deaab1e64fc0b7c4dd82d21e57af.pkl\n",
      "Memmapping (shape=(295385,), dtype=int32) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_25472_4540203103\\25472-2485368498104-3dbc69ecf68a46eb9bf8588f99556c59.pkl\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.9min finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, flatten_X, flatten_y, cv=cv, n_jobs=-1, \n",
    "                         scoring=scoring, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf=CRF(algorithm='lbfgs',\n",
    "         c1=0.1,\n",
    "         c2=0.1,\n",
    "         max_iterations=100,\n",
    "         all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scores = cross_validate(crf, X_train, y_train, cv=cv, n_jobs=-1, \n",
    "#                          scoring=scoring, verbose=100)\n",
    "scores = cross_validate(crf, X_train[:100], y_train[:100], cv=cv, n_jobs=-1, \n",
    "                         scoring=scoring, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97032539, 0.97388456, 0.97253039, 0.97323582, 0.97233593])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "HW1. NER.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
