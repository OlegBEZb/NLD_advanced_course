{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# About notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "Dataset\n",
    "*\tGroningen Meaning Bank (version 2.2.0)\n",
    "*\tTask: named entity recognition\n",
    "*\tTarget – named entity tags (BIO + entity type)\n",
    "*\tInput data: \n",
    "  * Use “en.met” files to extract the subcorpus\n",
    "  corpus = 'Voice of America' (for honogeneity of the input data set)\n",
    "  * Use \"en.tags\" files for the main input data:\n",
    "      *\traw tokens + may use the lemmas and the POS-tags \n",
    "  (i.e. take the “golden” POS-tagging);\n",
    "      *\twhich means:\n",
    "        *\tfirst three columns for input: ['word', 'pos', 'lemma']\n",
    "        *\tthe fourth column for target variable (‘ne_tags’)\n",
    "        (BIO annotation + the named-entity type in one tag)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "1.\tThe most trivial model = supervised HMM:\n",
    "  *\tTake hmmlearn (former sklearn), modify MultinomialHMM (I.e. inherit a new class from _BaseHMM making it a modified copy of the latter) to allow for supervised HMM training. The states of the HMM model = the NE tags.\n",
    "  *\tNOTE: may use NaiveBayes to learn emission probabilities in a supervized manner.\n",
    "  *\tOr implement from scratch (with Viterbi for prediction).\n",
    "  *\tNOTE: use tuples of features for X (not just the word, but additional info).\n",
    "  *\tNOTE: use smoothing for state transitions.\n",
    "2.\tCRF\n",
    "  *\tModify the input features;\n",
    "  *\tUse CRFSuite.\n",
    "3.\tBi-LSTM:\n",
    "  *\tUse keras or tensorflow;\n",
    "  *\thttps://github.com/hse-aml/natural-language-processing/blob/master/week2/week2-NER.ipynb\n",
    "  *\tA plus for incorporating CNN-layers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "* normalized confusion matrices, precision, recall, F-score \n",
    "(macro- and micro-) \n",
    "* (token level, entity level, partial matching (i.e. boundary-detection problem), binary).  \n",
    "NOTE: taking into account vocabulary transfer is a plus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# Evaluation Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "Scoring (14.5 max):  \n",
    "*\tDataset overview – 0.5\n",
    "  *\ttext lengths, vocabulary size, frequencies of patterns (<UNK-type-i>) \n",
    "  *\tstats over the target tags\n",
    "*\tFeature engineering – 2 (1+1)\n",
    "  *\tgrammatical words = closed set (~ stop words)\n",
    "  *\tStemming + POS\n",
    "  *\tWord shape\n",
    "  *\tAd hoc features ( +1)  \n",
    "*\tWord patterns -> encode types of unknown words +0.5\n",
    "*\tSmoothing in HMM – 0.5 \n",
    "  *\tIn HMM: for state transitions.\n",
    "*\tIncorporating tupled features in HMM (on top of tokens) – 1\n",
    "*\tThe correct HMM implementation – 1\n",
    "*\tMore fine-grained feature engineering for the Neural Network + 0.5\n",
    "  *\tDifferentiate between POS-relevancy for the word and the context, etc.\n",
    "  *\tSentence-level features (may use “golden” sentence-splitting)\n",
    "*\tEvaluation (on all levels) – 1\n",
    "*\tConclusion on HMM deficiency (as a model) – 1\n",
    "*\tCRF: 1 point for use and evaluation, + 0.5 points for comparison and conclusions;\n",
    "*\tNN:\n",
    "  *\tMain network: 4\n",
    "  *\tCNN layers: +2  \n",
    "\n",
    "Libraries: hmmlearn, crfsuite, tensorflow, keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30D0Scxk4kn3"
   },
   "source": [
    "# Libs import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ZnXUdrxQ3TAN",
    "outputId": "910fb799-41ed-4c9b-98ca-55a44b62566f"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "import os\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, ShuffleSplit\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "VD2z8D2V7Dod"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "auzLnrdK51Rg",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data found: ['p00', 'p01', 'p02', 'p03', 'p04', 'p05', 'p06', 'p07', 'p08', 'p09', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'p66', 'p67', 'p68', 'p69', 'p70', 'p71', 'p72', 'p73', 'p74', 'p75', 'p76', 'p77', 'p78', 'p79', 'p80', 'p81', 'p82', 'p83', 'p84', 'p85', 'p86', 'p87', 'p88', 'p89', 'p90', 'p91', 'p92', 'p93', 'p94', 'p95', 'p96', 'p97', 'p98', 'p99']\n"
     ]
    }
   ],
   "source": [
    "data_path = 'D:\\Data\\gmb-2.2.0\\data'\n",
    "print('data found:', os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subcorpus = 'Voice of America'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "tgwhO8ngi-A4"
   },
   "source": [
    "Parsing data from \"Voice of America\" subcorpus. According to the instructions we take first four columns and additional column to separate data on texts, sentences or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "-UBeZ_eui-A5",
    "outputId": "5308f75a-eaa2-42e3-ecae-4f6aa512ec36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [08:55<00:00,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "voa_data = pd.DataFrame(columns=['word', 'pos', 'lemma', 'ne_tags', 'text_id'])\n",
    "\n",
    "os.chdir(data_path)\n",
    "part_paths = os.listdir()\n",
    "\n",
    "for part_path in tqdm(part_paths, total=len(part_paths)):\n",
    "    os.chdir(part_path)\n",
    "    document_paths = os.listdir()\n",
    "    for document_path in document_paths:\n",
    "        os.chdir(document_path)\n",
    "        f = codecs.open(\"en.met\", 'r', \"utf_8_sig\")\n",
    "        file_met = f.read()\n",
    "        if ('subcorpus: {}'.format(subcorpus) in file_met):\n",
    "            tags_df = pd.read_csv('en.tags',\n",
    "                                  sep='\\t',\n",
    "                                  header=None,\n",
    "                                  names=['word', 'pos', 'lemma', 'ne_tags'],\n",
    "                                  usecols=[0, 1, 2, 3],\n",
    "                                  error_bad_lines=False)\n",
    "            tags_df['text_id'] = str(part_path) + '_' + str(document_path)\n",
    "            voa_data = voa_data.append(tags_df, ignore_index=True)\n",
    "        f.close()\n",
    "        os.chdir('..')\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_memory_usage(df):\n",
    "    print(\"memory usage: \", df.memory_usage().sum()/1024/1024, \" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "UX1ViqnKi-A-",
    "outputId": "c391cb23-3288-4f4f-db22-f5afc86f4fa2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage:  46.969688415527344  MB\n"
     ]
    }
   ],
   "source": [
    "show_memory_usage(voa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrator</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos         lemma ne_tags    text_id\n",
       "0      Thousands  NNS      thousand       O  p00_d0018\n",
       "1             of   IN            of       O  p00_d0018\n",
       "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
       "3           have  VBP          have       O  p00_d0018\n",
       "4        marched  VBN         march       O  p00_d0018"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "kUrX7pvxi-BB",
    "outputId": "f42abe57-ad1b-4a64-a7b3-6bf93acb5155",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1231279, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "8vWQ-w4Qi-BF"
   },
   "source": [
    "Number of tokens coincided with the declared in README file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "voa_data.to_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "15GVrJYa717o"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrator</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos         lemma ne_tags    text_id\n",
       "0      Thousands  NNS      thousand       O  p00_d0018\n",
       "1             of   IN            of       O  p00_d0018\n",
       "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
       "3           have  VBP          have       O  p00_d0018\n",
       "4        marched  VBN         march       O  p00_d0018"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data = pd.read_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus))\n",
    "voa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "b1Y2cJhli-BG",
    "outputId": "31c7858e-e9f0-45de-fd83-9c7ff746db38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average text length:  134.31646121959201\n"
     ]
    }
   ],
   "source": [
    "def average_text_length(text_id):\n",
    "    doc_lengths = list(dict(Counter(text_id)).values())\n",
    "    sum = 0\n",
    "    for length in doc_lengths:\n",
    "        sum += length\n",
    "    return sum/len(doc_lengths)\n",
    "\n",
    "print(\"average text length: \", average_text_length(voa_data['text_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>35154</td>\n",
       "      <td>48</td>\n",
       "      <td>27209</td>\n",
       "      <td>25</td>\n",
       "      <td>9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>61398</td>\n",
       "      <td>168817</td>\n",
       "      <td>74941</td>\n",
       "      <td>1032479</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word      pos    lemma  ne_tags    text_id\n",
       "count   1231279  1231279  1231279  1231279    1231279\n",
       "unique    35154       48    27209       25       9167\n",
       "top         the       NN      the        O  p00_d0090\n",
       "freq      61398   168817    74941  1032479        388"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O          1032479\n",
       "geo-nam      55480\n",
       "org-nam      44646\n",
       "per-nam      22931\n",
       "gpe-nam      19685\n",
       "tim-dow      11398\n",
       "tim-dat      10929\n",
       "per-tit       9672\n",
       "per-fam       8098\n",
       "[]            4064\n",
       "tim-moy       3811\n",
       "tim-yoc       3009\n",
       "per-giv       2376\n",
       "tim-clo        810\n",
       "art-nam        789\n",
       "eve-nam        514\n",
       "nat-nam        280\n",
       "tim-nam        132\n",
       "eve-ord         63\n",
       "per-ini         55\n",
       "per-ord         35\n",
       "org-leg         13\n",
       "tim-dom          8\n",
       "art-add          1\n",
       "per-mid          1\n",
       "Name: ne_tags, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data['ne_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Make BIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  pos     lemma ne_tags    text_id\n",
       "0  Thousands  NNS  thousand       O  p00_d0018\n",
       "1         of   IN        of       O  p00_d0018"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def use_prev_value_decorator(func):\n",
    "    prev_tag = \"O\"\n",
    "\n",
    "    def wrapper(curr_tag, **kwargs):\n",
    "        nonlocal prev_tag\n",
    "        bio_tag = func(curr_tag, prev_tag)\n",
    "        prev_tag = curr_tag\n",
    "        return bio_tag\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@use_prev_value_decorator\n",
    "# Tag tokens with standard NLP BIO tags\n",
    "def bio_tagger(curr_tag, prev_tag):\n",
    "    if curr_tag == \"O\":  #O\n",
    "        return curr_tag\n",
    "    elif curr_tag != \"O\" and prev_tag == \"O\":  # Begin NE\n",
    "        return \"B-\" + curr_tag\n",
    "    elif prev_tag != \"O\" and prev_tag == curr_tag:  # Inside NE\n",
    "        return \"I-\" + curr_tag\n",
    "    elif prev_tag != \"O\" and prev_tag != curr_tag:  # Adjacent NE\n",
    "        return \"B-\" + curr_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voa_data['bio_tag'] = voa_data['ne_tags'].apply(bio_tagger, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O            1032479\n",
       "B-geo-nam      46622\n",
       "B-org-nam      24134\n",
       "I-org-nam      20512\n",
       "B-gpe-nam      19469\n",
       "Name: bio_tag, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data['bio_tag'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Classificators work better if avoid redundant granularity. Also such detailed fragmentation has no value for the task of only finding named entities. Thus, we can combine subcategories and leave only first part of tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "voa_data['ne_tags'] = voa_data['ne_tags'].apply(lambda x: x.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O      1032479\n",
       "geo      55480\n",
       "org      44659\n",
       "per      43168\n",
       "tim      30097\n",
       "gpe      19685\n",
       "[]        4064\n",
       "art        790\n",
       "eve        577\n",
       "nat        280\n",
       "Name: ne_tags, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data['ne_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrator</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos         lemma ne_tags    text_id\n",
       "0      Thousands  NNS      thousand       O  p00_d0018\n",
       "1             of   IN            of       O  p00_d0018\n",
       "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
       "3           have  VBP          have       O  p00_d0018\n",
       "4        marched  VBN         march       O  p00_d0018"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## For other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  pos     lemma ne_tags    text_id\n",
       "0  Thousands  NNS  thousand       O  p00_d0018\n",
       "1         of   IN        of       O  p00_d0018"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def encode_labels(df, labels_list):\n",
    "    for label in labels_list:\n",
    "        le = LabelEncoder()\n",
    "        df[label] = le.fit_transform(df[label])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "voa_data = encode_labels(voa_data, ['ne_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target = voa_data['ne_tags']\n",
    "voa_data.drop(['ne_tags', 'text_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voa_data = encode_labels(voa_data, ['word', 'pos', 'lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-bd33e2565e3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoa_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2141\u001b[0m                      random_state=random_state)\n\u001b[0;32m   2142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2143\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1327\u001b[0m         \"\"\"\n\u001b[0;32m   1328\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1330\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1657\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[0;32m   1660\u001b[0m                              \u001b[1;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m                              \u001b[1;34m\" number of groups for any class cannot\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(voa_data, target, test_size = 0.2, shuffle=True, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## For CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_sentences(df):\n",
    "    \"\"\"func to get the sentences in this format:\n",
    "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_n, Tag_n)]\"\"\"\n",
    "    \n",
    "    agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                       s[\"pos\"].values.tolist(),\n",
    "                                                       s[\"ne_tags\"].values.tolist())]\n",
    "    grouped = df.groupby(\"text_id\").apply(agg_func)\n",
    "    sentences = [s for s in grouped]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Thousands', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('demonstrators', 'NNS', 'O'),\n",
       "  ('have', 'VBP', 'O'),\n",
       "  ('marched', 'VBN', 'O'),\n",
       "  ('through', 'IN', 'O'),\n",
       "  ('London', 'NNP', 'geo-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('protest', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('war', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Iraq', 'NNP', 'geo-nam'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('demand', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('withdrawal', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('British', 'JJ', 'gpe-nam'),\n",
       "  ('troops', 'NNS', 'O'),\n",
       "  ('from', 'IN', 'O'),\n",
       "  ('that', 'DT', 'O'),\n",
       "  ('country', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Families', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('soldiers', 'NNS', 'O'),\n",
       "  ('killed', 'VBN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('conflict', 'NN', 'O'),\n",
       "  ('joined', 'VBD', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('protesters', 'NNS', 'O'),\n",
       "  ('who', 'WP', 'O'),\n",
       "  ('carried', 'VBD', 'O'),\n",
       "  ('banners', 'NNS', 'O'),\n",
       "  ('with', 'IN', 'O'),\n",
       "  ('such', 'JJ', 'O'),\n",
       "  ('slogans', 'NNS', 'O'),\n",
       "  ('as', 'IN', 'O'),\n",
       "  ('\\tLQU\\t', 'O', '[]'),\n",
       "  ('Bush', 'NNP', 'per-fam'),\n",
       "  ('Number', 'NN', 'O'),\n",
       "  ('One', 'CD', 'O'),\n",
       "  ('Terrorist', 'NN', 'O'),\n",
       "  ('\\tRQU\\t', 'O', '[]'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('\\tLQU\\t', 'O', '[]'),\n",
       "  ('Stop', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Bombings', 'NNS', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('\\tLQU\\t', 'O', '[]'),\n",
       "  ('They', 'PRP', 'O'),\n",
       "  ('marched', 'VBD', 'O'),\n",
       "  ('from', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Houses', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('Parliament', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('a', 'DT', 'O'),\n",
       "  ('rally', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Hyde', 'NNP', 'geo-nam'),\n",
       "  ('Park', 'NNP', 'geo-nam'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Police', 'NNS', 'O'),\n",
       "  ('put', 'VBD', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('number', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('marchers', 'NNS', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('10,000', 'CD', 'O'),\n",
       "  ('while', 'IN', 'O'),\n",
       "  ('organizers', 'NNS', 'O'),\n",
       "  ('claimed', 'VBD', 'O'),\n",
       "  ('it', 'PRP', 'O'),\n",
       "  ('was', 'VBD', 'O'),\n",
       "  ('100,000', 'CD', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('protest', 'NN', 'O'),\n",
       "  ('comes', 'VBZ', 'O'),\n",
       "  ('on', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('eve', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('annual', 'JJ', 'O'),\n",
       "  ('conference', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('Britain', 'NNP', 'geo-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('ruling', 'VBG', 'O'),\n",
       "  ('Labor', 'NNP', 'org-nam'),\n",
       "  ('Party', 'NNP', 'org-nam'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('southern', 'JJ', 'O'),\n",
       "  ('English', 'JJ', 'gpe-nam'),\n",
       "  ('seaside', 'NN', 'O'),\n",
       "  ('resort', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('Brighton', 'NNP', 'geo-nam'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('party', 'NN', 'O'),\n",
       "  ('is', 'VBZ', 'O'),\n",
       "  ('divided', 'VBN', 'O'),\n",
       "  ('over', 'IN', 'O'),\n",
       "  ('Britain', 'NNP', 'gpe-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('participation', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Iraq', 'NNP', 'geo-nam'),\n",
       "  ('conflict', 'NN', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('continued', 'JJ', 'O'),\n",
       "  ('deployment', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('8,500', 'CD', 'O'),\n",
       "  ('British', 'JJ', 'gpe-nam'),\n",
       "  ('troops', 'NNS', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('that', 'DT', 'O'),\n",
       "  ('country', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('London', 'NNP', 'geo-nam'),\n",
       "  ('march', 'NN', 'O'),\n",
       "  ('came', 'VBD', 'O'),\n",
       "  ('ahead', 'RB', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('anti-war', 'JJ', 'O'),\n",
       "  ('protests', 'NNS', 'O'),\n",
       "  ('today', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('other', 'JJ', 'O'),\n",
       "  ('cities', 'NNS', 'O'),\n",
       "  (',', ',', 'O'),\n",
       "  ('including', 'VBG', 'O'),\n",
       "  ('Rome', 'NNP', 'geo-nam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('Paris', 'NNP', 'geo-nam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('Madrid', 'NNP', 'geo-nam'),\n",
       "  ('.', '.', 'O')],\n",
       " [('The', 'DT', 'O'),\n",
       "  ('International', 'NNP', 'org-nam'),\n",
       "  ('Atomic', 'NNP', 'org-nam'),\n",
       "  ('Energy', 'NNP', 'org-nam'),\n",
       "  ('Agency', 'NNP', 'org-nam'),\n",
       "  ('is', 'VBZ', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('hold', 'VB', 'O'),\n",
       "  ('second', 'JJ', 'O'),\n",
       "  ('day', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('talks', 'NNS', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Vienna', 'NNP', 'geo-nam'),\n",
       "  ('Wednesday', 'NNP', 'tim-dow'),\n",
       "  ('on', 'IN', 'O'),\n",
       "  ('how', 'WRB', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('respond', 'VB', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('resumption', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('low-level', 'JJ', 'O'),\n",
       "  ('uranium', 'NN', 'O'),\n",
       "  ('conversion', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  ('this', 'DT', 'O'),\n",
       "  ('week', 'NN', 'O'),\n",
       "  ('restarted', 'VBD', 'O'),\n",
       "  ('parts', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('conversion', 'NN', 'O'),\n",
       "  ('process', 'NN', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('its', 'PRP$', 'O'),\n",
       "  ('Isfahan', 'NNP', 'geo-nam'),\n",
       "  ('nuclear', 'JJ', 'O'),\n",
       "  ('plant', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Iranian', 'JJ', 'gpe-nam'),\n",
       "  ('officials', 'NNS', 'O'),\n",
       "  ('say', 'VBP', 'O'),\n",
       "  ('they', 'PRP', 'O'),\n",
       "  ('expect', 'VBP', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('get', 'VB', 'O'),\n",
       "  ('access', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('sealed', 'JJ', 'O'),\n",
       "  ('sensitive', 'JJ', 'O'),\n",
       "  ('parts', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('plant', 'NN', 'O'),\n",
       "  ('Wednesday', 'NNP', 'tim-dow'),\n",
       "  (',', ',', 'O'),\n",
       "  ('after', 'IN', 'O'),\n",
       "  ('an', 'DT', 'O'),\n",
       "  ('IAEA', 'NNP', 'org-nam'),\n",
       "  ('surveillance', 'NN', 'O'),\n",
       "  ('system', 'NN', 'O'),\n",
       "  ('begins', 'VBZ', 'O'),\n",
       "  ('functioning', 'VBG', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('step', 'NN', 'O'),\n",
       "  ('will', 'MD', 'O'),\n",
       "  ('allow', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('facility', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('operate', 'VB', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('full', 'JJ', 'O'),\n",
       "  ('capacity', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('European', 'NNP', 'org-nam'),\n",
       "  ('Union', 'NNP', 'org-nam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('with', 'IN', 'O'),\n",
       "  ('U.S.', 'NNP', 'gpe-nam'),\n",
       "  ('backing', 'NN', 'O'),\n",
       "  (',', ',', 'O'),\n",
       "  ('has', 'VBZ', 'O'),\n",
       "  ('threatened', 'VBN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('refer', 'VB', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('U.N.', 'NNP', 'org-nam'),\n",
       "  ('Security', 'NNP', 'org-nam'),\n",
       "  ('Council', 'NNP', 'org-nam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('which', 'WDT', 'O'),\n",
       "  ('could', 'MD', 'O'),\n",
       "  ('impose', 'VB', 'O'),\n",
       "  ('sanctions', 'NNS', 'O'),\n",
       "  ('if', 'IN', 'O'),\n",
       "  ('it', 'PRP', 'O'),\n",
       "  ('finds', 'VBZ', 'O'),\n",
       "  ('Tehran', 'NNP', 'gpe-nam'),\n",
       "  ('has', 'VBZ', 'O'),\n",
       "  ('violated', 'VBN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Nuclear', 'NNP', 'art-nam'),\n",
       "  ('Non-Proliferation', 'NNP', 'art-nam'),\n",
       "  ('treaty', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('new', 'JJ', 'O'),\n",
       "  ('President', 'NNP', 'per-tit'),\n",
       "  ('Mahmoud', 'NNP', 'per-giv'),\n",
       "  ('Ahmadinejad', 'NNP', 'per-fam'),\n",
       "  ('said', 'VBD', 'O'),\n",
       "  ('Tuesday', 'NNP', 'tim-dow'),\n",
       "  ('that', 'IN', 'O'),\n",
       "  ('European', 'JJ', 'gpe-nam'),\n",
       "  ('incentives', 'NNS', 'O'),\n",
       "  ('aimed', 'VBN', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('persuading', 'VBG', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('end', 'VB', 'O'),\n",
       "  ('its', 'PRP$', 'O'),\n",
       "  ('nuclear', 'JJ', 'O'),\n",
       "  ('fuel', 'NN', 'O'),\n",
       "  ('program', 'NN', 'O'),\n",
       "  ('are', 'VBP', 'O'),\n",
       "  ('an', 'DT', 'O'),\n",
       "  ('insult', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Iranian', 'JJ', 'gpe-nam'),\n",
       "  ('nation', 'NN', 'O'),\n",
       "  ('.', '.', 'O')]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_pos_tag_sentences = get_sentences(voa_data)\n",
    "display(word_pos_tag_sentences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets visualize how the sentences are distributed by their length\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist([len(s) for s in word_pos_tag_sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:], #replace with BPE\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def get_sent_labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9167"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_pos_tag_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in word_pos_tag_sentences]\n",
    "y = [get_sent_labels(s) for s in word_pos_tag_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bias': 1.0,\n",
       "   'word.lower()': 'thousands',\n",
       "   'word[-3:]': 'nds',\n",
       "   'word[-2:]': 'ds',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   'BOS': True,\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'thousands',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'demonstrators',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'demonstrators',\n",
       "   'word[-3:]': 'ors',\n",
       "   'word[-2:]': 'rs',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'have',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBP',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'have',\n",
       "   'word[-3:]': 'ave',\n",
       "   'word[-2:]': 've',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'demonstrators',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'marched',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'marched',\n",
       "   'word[-3:]': 'hed',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'have',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'through',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'through',\n",
       "   'word[-3:]': 'ugh',\n",
       "   'word[-2:]': 'gh',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'marched',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'london',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'london',\n",
       "   'word[-3:]': 'don',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'through',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'london',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'protest',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'protest',\n",
       "   'word[-3:]': 'est',\n",
       "   'word[-2:]': 'st',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'protest',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'war',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'war',\n",
       "   'word[-3:]': 'war',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'war',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'iraq',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iraq',\n",
       "   'word[-3:]': 'raq',\n",
       "   'word[-2:]': 'aq',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'and',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CC',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   '-1:word.lower()': 'iraq',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'demand',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'demand',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'demand',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'withdrawal',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'withdrawal',\n",
       "   'word[-3:]': 'wal',\n",
       "   'word[-2:]': 'al',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'withdrawal',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'british',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'british',\n",
       "   'word[-3:]': 'ish',\n",
       "   'word[-2:]': 'sh',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'troops',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'troops',\n",
       "   'word[-3:]': 'ops',\n",
       "   'word[-2:]': 'ps',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'british',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'from',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'from',\n",
       "   'word[-3:]': 'rom',\n",
       "   'word[-2:]': 'om',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'troops',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'that',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'that',\n",
       "   'word[-3:]': 'hat',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'from',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'country',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'country',\n",
       "   'word[-3:]': 'try',\n",
       "   'word[-2:]': 'ry',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'that',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'country',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'families',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'families',\n",
       "   'word[-3:]': 'ies',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'families',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'soldiers',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'soldiers',\n",
       "   'word[-3:]': 'ers',\n",
       "   'word[-2:]': 'rs',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'killed',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'killed',\n",
       "   'word[-3:]': 'led',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'soldiers',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'killed',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'conflict',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'conflict',\n",
       "   'word[-3:]': 'ict',\n",
       "   'word[-2:]': 'ct',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'joined',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'joined',\n",
       "   'word[-3:]': 'ned',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'conflict',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'joined',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'protesters',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'protesters',\n",
       "   'word[-3:]': 'ers',\n",
       "   'word[-2:]': 'rs',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'who',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'WP',\n",
       "   '+1:postag[:2]': 'WP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'who',\n",
       "   'word[-3:]': 'who',\n",
       "   'word[-2:]': 'ho',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'WP',\n",
       "   'postag[:2]': 'WP',\n",
       "   '-1:word.lower()': 'protesters',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'carried',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'carried',\n",
       "   'word[-3:]': 'ied',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'who',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'WP',\n",
       "   '-1:postag[:2]': 'WP',\n",
       "   '+1:word.lower()': 'banners',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'banners',\n",
       "   'word[-3:]': 'ers',\n",
       "   'word[-2:]': 'rs',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'carried',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'with',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'with',\n",
       "   'word[-3:]': 'ith',\n",
       "   'word[-2:]': 'th',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'banners',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'such',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'such',\n",
       "   'word[-3:]': 'uch',\n",
       "   'word[-2:]': 'ch',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'with',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'slogans',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'slogans',\n",
       "   'word[-3:]': 'ans',\n",
       "   'word[-2:]': 'ns',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'such',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'as',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'as',\n",
       "   'word[-3:]': 'as',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'slogans',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '\\tlqu\\t',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'O',\n",
       "   '+1:postag[:2]': 'O'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '\\tlqu\\t',\n",
       "   'word[-3:]': 'QU\\t',\n",
       "   'word[-2:]': 'U\\t',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'O',\n",
       "   'postag[:2]': 'O',\n",
       "   '-1:word.lower()': 'as',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'bush',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'bush',\n",
       "   'word[-3:]': 'ush',\n",
       "   'word[-2:]': 'sh',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': '\\tlqu\\t',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'O',\n",
       "   '-1:postag[:2]': 'O',\n",
       "   '+1:word.lower()': 'number',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'number',\n",
       "   'word[-3:]': 'ber',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'bush',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'one',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CD',\n",
       "   '+1:postag[:2]': 'CD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'one',\n",
       "   'word[-3:]': 'One',\n",
       "   'word[-2:]': 'ne',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   '-1:word.lower()': 'number',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'terrorist',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'terrorist',\n",
       "   'word[-3:]': 'ist',\n",
       "   'word[-2:]': 'st',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'one',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   '+1:word.lower()': '\\trqu\\t',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'O',\n",
       "   '+1:postag[:2]': 'O'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '\\trqu\\t',\n",
       "   'word[-3:]': 'QU\\t',\n",
       "   'word[-2:]': 'U\\t',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'O',\n",
       "   'postag[:2]': 'O',\n",
       "   '-1:word.lower()': 'terrorist',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'and',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CC',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   '-1:word.lower()': '\\trqu\\t',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'O',\n",
       "   '-1:postag[:2]': 'O',\n",
       "   '+1:word.lower()': '\\tlqu\\t',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'O',\n",
       "   '+1:postag[:2]': 'O'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '\\tlqu\\t',\n",
       "   'word[-3:]': 'QU\\t',\n",
       "   'word[-2:]': 'U\\t',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'O',\n",
       "   'postag[:2]': 'O',\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:word.lower()': 'stop',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'stop',\n",
       "   'word[-3:]': 'top',\n",
       "   'word[-2:]': 'op',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': '\\tlqu\\t',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'O',\n",
       "   '-1:postag[:2]': 'O',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'stop',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'bombings',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'bombings',\n",
       "   'word[-3:]': 'ngs',\n",
       "   'word[-2:]': 'gs',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'bombings',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '\\tlqu\\t',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'O',\n",
       "   '+1:postag[:2]': 'O'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '\\tlqu\\t',\n",
       "   'word[-3:]': 'QU\\t',\n",
       "   'word[-2:]': 'U\\t',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'O',\n",
       "   'postag[:2]': 'O',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'they',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'they',\n",
       "   'word[-3:]': 'hey',\n",
       "   'word[-2:]': 'ey',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': '\\tlqu\\t',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'O',\n",
       "   '-1:postag[:2]': 'O',\n",
       "   '+1:word.lower()': 'marched',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'marched',\n",
       "   'word[-3:]': 'hed',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'they',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'from',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'from',\n",
       "   'word[-3:]': 'rom',\n",
       "   'word[-2:]': 'om',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'marched',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'from',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'houses',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'houses',\n",
       "   'word[-3:]': 'ses',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'houses',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'parliament',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'parliament',\n",
       "   'word[-3:]': 'ent',\n",
       "   'word[-2:]': 'nt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'parliament',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'a',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'a',\n",
       "   'word[-3:]': 'a',\n",
       "   'word[-2:]': 'a',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'rally',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'rally',\n",
       "   'word[-3:]': 'lly',\n",
       "   'word[-2:]': 'ly',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'a',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'rally',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'hyde',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'hyde',\n",
       "   'word[-3:]': 'yde',\n",
       "   'word[-2:]': 'de',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'park',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'park',\n",
       "   'word[-3:]': 'ark',\n",
       "   'word[-2:]': 'rk',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'hyde',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'park',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'police',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'police',\n",
       "   'word[-3:]': 'ice',\n",
       "   'word[-2:]': 'ce',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'put',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'put',\n",
       "   'word[-3:]': 'put',\n",
       "   'word[-2:]': 'ut',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'police',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'put',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'number',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'number',\n",
       "   'word[-3:]': 'ber',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'number',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'marchers',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'marchers',\n",
       "   'word[-3:]': 'ers',\n",
       "   'word[-2:]': 'rs',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'at',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'at',\n",
       "   'word[-3:]': 'at',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'marchers',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '10,000',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CD',\n",
       "   '+1:postag[:2]': 'CD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '10,000',\n",
       "   'word[-3:]': '000',\n",
       "   'word[-2:]': '00',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   '-1:word.lower()': 'at',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'while',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'while',\n",
       "   'word[-3:]': 'ile',\n",
       "   'word[-2:]': 'le',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': '10,000',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   '+1:word.lower()': 'organizers',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'organizers',\n",
       "   'word[-3:]': 'ers',\n",
       "   'word[-2:]': 'rs',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'while',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'claimed',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'claimed',\n",
       "   'word[-3:]': 'med',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'organizers',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'it',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'it',\n",
       "   'word[-3:]': 'it',\n",
       "   'word[-2:]': 'it',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'claimed',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'was',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'was',\n",
       "   'word[-3:]': 'was',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'it',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': '100,000',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CD',\n",
       "   '+1:postag[:2]': 'CD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '100,000',\n",
       "   'word[-3:]': '000',\n",
       "   'word[-2:]': '00',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   '-1:word.lower()': 'was',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': '100,000',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'The',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'protest',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'protest',\n",
       "   'word[-3:]': 'est',\n",
       "   'word[-2:]': 'st',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'comes',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'comes',\n",
       "   'word[-3:]': 'mes',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'protest',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'on',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'on',\n",
       "   'word[-3:]': 'on',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'comes',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'on',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'eve',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'eve',\n",
       "   'word[-3:]': 'eve',\n",
       "   'word[-2:]': 've',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'eve',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'annual',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'annual',\n",
       "   'word[-3:]': 'ual',\n",
       "   'word[-2:]': 'al',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'conference',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'conference',\n",
       "   'word[-3:]': 'nce',\n",
       "   'word[-2:]': 'ce',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'annual',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'conference',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'britain',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'britain',\n",
       "   'word[-3:]': 'ain',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': \"'s\",\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'POS',\n",
       "   '+1:postag[:2]': 'PO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': \"'s\",\n",
       "   'word[-3:]': \"'s\",\n",
       "   'word[-2:]': \"'s\",\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'POS',\n",
       "   'postag[:2]': 'PO',\n",
       "   '-1:word.lower()': 'britain',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'ruling',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBG',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'ruling',\n",
       "   'word[-3:]': 'ing',\n",
       "   'word[-2:]': 'ng',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBG',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': \"'s\",\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'POS',\n",
       "   '-1:postag[:2]': 'PO',\n",
       "   '+1:word.lower()': 'labor',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'labor',\n",
       "   'word[-3:]': 'bor',\n",
       "   'word[-2:]': 'or',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'ruling',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBG',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'party',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'party',\n",
       "   'word[-3:]': 'rty',\n",
       "   'word[-2:]': 'ty',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'labor',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'party',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'southern',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'southern',\n",
       "   'word[-3:]': 'ern',\n",
       "   'word[-2:]': 'rn',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'english',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'english',\n",
       "   'word[-3:]': 'ish',\n",
       "   'word[-2:]': 'sh',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'southern',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'seaside',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'seaside',\n",
       "   'word[-3:]': 'ide',\n",
       "   'word[-2:]': 'de',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'english',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'resort',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'resort',\n",
       "   'word[-3:]': 'ort',\n",
       "   'word[-2:]': 'rt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'seaside',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'resort',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'brighton',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'brighton',\n",
       "   'word[-3:]': 'ton',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'brighton',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'The',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'party',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'party',\n",
       "   'word[-3:]': 'rty',\n",
       "   'word[-2:]': 'ty',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'is',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'is',\n",
       "   'word[-3:]': 'is',\n",
       "   'word[-2:]': 'is',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'party',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'divided',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'divided',\n",
       "   'word[-3:]': 'ded',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'is',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'over',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'over',\n",
       "   'word[-3:]': 'ver',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'divided',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'britain',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'britain',\n",
       "   'word[-3:]': 'ain',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'over',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': \"'s\",\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'POS',\n",
       "   '+1:postag[:2]': 'PO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': \"'s\",\n",
       "   'word[-3:]': \"'s\",\n",
       "   'word[-2:]': \"'s\",\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'POS',\n",
       "   'postag[:2]': 'PO',\n",
       "   '-1:word.lower()': 'britain',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'participation',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'participation',\n",
       "   'word[-3:]': 'ion',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': \"'s\",\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'POS',\n",
       "   '-1:postag[:2]': 'PO',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'participation',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'iraq',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iraq',\n",
       "   'word[-3:]': 'raq',\n",
       "   'word[-2:]': 'aq',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'conflict',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'conflict',\n",
       "   'word[-3:]': 'ict',\n",
       "   'word[-2:]': 'ct',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'iraq',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'and',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CC',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   '-1:word.lower()': 'conflict',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:word.lower()': 'continued',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'continued',\n",
       "   'word[-3:]': 'ued',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'deployment',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'deployment',\n",
       "   'word[-3:]': 'ent',\n",
       "   'word[-2:]': 'nt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'continued',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'deployment',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '8,500',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CD',\n",
       "   '+1:postag[:2]': 'CD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '8,500',\n",
       "   'word[-3:]': '500',\n",
       "   'word[-2:]': '00',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'british',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'british',\n",
       "   'word[-3:]': 'ish',\n",
       "   'word[-2:]': 'sh',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': '8,500',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   '+1:word.lower()': 'troops',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'troops',\n",
       "   'word[-3:]': 'ops',\n",
       "   'word[-2:]': 'ps',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'british',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'troops',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'that',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'that',\n",
       "   'word[-3:]': 'hat',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'country',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'country',\n",
       "   'word[-3:]': 'try',\n",
       "   'word[-2:]': 'ry',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'that',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'country',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'The',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'london',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'london',\n",
       "   'word[-3:]': 'don',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'march',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'march',\n",
       "   'word[-3:]': 'rch',\n",
       "   'word[-2:]': 'ch',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'london',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'came',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'came',\n",
       "   'word[-3:]': 'ame',\n",
       "   'word[-2:]': 'me',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'march',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'ahead',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'RB',\n",
       "   '+1:postag[:2]': 'RB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'ahead',\n",
       "   'word[-3:]': 'ead',\n",
       "   'word[-2:]': 'ad',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'RB',\n",
       "   'postag[:2]': 'RB',\n",
       "   '-1:word.lower()': 'came',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'ahead',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'RB',\n",
       "   '-1:postag[:2]': 'RB',\n",
       "   '+1:word.lower()': 'anti-war',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'anti-war',\n",
       "   'word[-3:]': 'war',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'protests',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'protests',\n",
       "   'word[-3:]': 'sts',\n",
       "   'word[-2:]': 'ts',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'anti-war',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'today',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'today',\n",
       "   'word[-3:]': 'day',\n",
       "   'word[-2:]': 'ay',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'protests',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'today',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'other',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'other',\n",
       "   'word[-3:]': 'her',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'cities',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'cities',\n",
       "   'word[-3:]': 'ies',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'other',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'cities',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'including',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBG',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'including',\n",
       "   'word[-3:]': 'ing',\n",
       "   'word[-2:]': 'ng',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBG',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': 'rome',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'rome',\n",
       "   'word[-3:]': 'ome',\n",
       "   'word[-2:]': 'me',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'including',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBG',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'rome',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'paris',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'paris',\n",
       "   'word[-3:]': 'ris',\n",
       "   'word[-2:]': 'is',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'paris',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'and',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CC',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': 'madrid',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'madrid',\n",
       "   'word[-3:]': 'rid',\n",
       "   'word[-2:]': 'id',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'madrid',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'EOS': True}],\n",
       " [{'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'The',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   'BOS': True,\n",
       "   '+1:word.lower()': 'international',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'international',\n",
       "   'word[-3:]': 'nal',\n",
       "   'word[-2:]': 'al',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'atomic',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'atomic',\n",
       "   'word[-3:]': 'mic',\n",
       "   'word[-2:]': 'ic',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'international',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'energy',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'energy',\n",
       "   'word[-3:]': 'rgy',\n",
       "   'word[-2:]': 'gy',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'atomic',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'agency',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'agency',\n",
       "   'word[-3:]': 'ncy',\n",
       "   'word[-2:]': 'cy',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'energy',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'is',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'is',\n",
       "   'word[-3:]': 'is',\n",
       "   'word[-2:]': 'is',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'agency',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'is',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'hold',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'hold',\n",
       "   'word[-3:]': 'old',\n",
       "   'word[-2:]': 'ld',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'second',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'second',\n",
       "   'word[-3:]': 'ond',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'hold',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'day',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'day',\n",
       "   'word[-3:]': 'day',\n",
       "   'word[-2:]': 'ay',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'second',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'day',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'talks',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'talks',\n",
       "   'word[-3:]': 'lks',\n",
       "   'word[-2:]': 'ks',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'in',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'word[-2:]': 'in',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'talks',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'vienna',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'vienna',\n",
       "   'word[-3:]': 'nna',\n",
       "   'word[-2:]': 'na',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'wednesday',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'wednesday',\n",
       "   'word[-3:]': 'day',\n",
       "   'word[-2:]': 'ay',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'vienna',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'on',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'on',\n",
       "   'word[-3:]': 'on',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'wednesday',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'how',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'WRB',\n",
       "   '+1:postag[:2]': 'WR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'how',\n",
       "   'word[-3:]': 'how',\n",
       "   'word[-2:]': 'ow',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'WRB',\n",
       "   'postag[:2]': 'WR',\n",
       "   '-1:word.lower()': 'on',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'how',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'WRB',\n",
       "   '-1:postag[:2]': 'WR',\n",
       "   '+1:word.lower()': 'respond',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'respond',\n",
       "   'word[-3:]': 'ond',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'respond',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'iran',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iran',\n",
       "   'word[-3:]': 'ran',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': \"'s\",\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'POS',\n",
       "   '+1:postag[:2]': 'PO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': \"'s\",\n",
       "   'word[-3:]': \"'s\",\n",
       "   'word[-2:]': \"'s\",\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'POS',\n",
       "   'postag[:2]': 'PO',\n",
       "   '-1:word.lower()': 'iran',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'resumption',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'resumption',\n",
       "   'word[-3:]': 'ion',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': \"'s\",\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'POS',\n",
       "   '-1:postag[:2]': 'PO',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'resumption',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'low-level',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'low-level',\n",
       "   'word[-3:]': 'vel',\n",
       "   'word[-2:]': 'el',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'uranium',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'uranium',\n",
       "   'word[-3:]': 'ium',\n",
       "   'word[-2:]': 'um',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'low-level',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'conversion',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'conversion',\n",
       "   'word[-3:]': 'ion',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'uranium',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'conversion',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'iran',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iran',\n",
       "   'word[-3:]': 'ran',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'this',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'this',\n",
       "   'word[-3:]': 'his',\n",
       "   'word[-2:]': 'is',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'iran',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'week',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'week',\n",
       "   'word[-3:]': 'eek',\n",
       "   'word[-2:]': 'ek',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'this',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'restarted',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'restarted',\n",
       "   'word[-3:]': 'ted',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'week',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'parts',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'parts',\n",
       "   'word[-3:]': 'rts',\n",
       "   'word[-2:]': 'ts',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'restarted',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'parts',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'conversion',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'conversion',\n",
       "   'word[-3:]': 'ion',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'process',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'process',\n",
       "   'word[-3:]': 'ess',\n",
       "   'word[-2:]': 'ss',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'conversion',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'at',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'at',\n",
       "   'word[-3:]': 'at',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'process',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'its',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP$',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'its',\n",
       "   'word[-3:]': 'its',\n",
       "   'word[-2:]': 'ts',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP$',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'at',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'isfahan',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'isfahan',\n",
       "   'word[-3:]': 'han',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'its',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP$',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'nuclear',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'nuclear',\n",
       "   'word[-3:]': 'ear',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'isfahan',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'plant',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'plant',\n",
       "   'word[-3:]': 'ant',\n",
       "   'word[-2:]': 'nt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'nuclear',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'plant',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'iranian',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iranian',\n",
       "   'word[-3:]': 'ian',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'officials',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'officials',\n",
       "   'word[-3:]': 'als',\n",
       "   'word[-2:]': 'ls',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'iranian',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'say',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBP',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'say',\n",
       "   'word[-3:]': 'say',\n",
       "   'word[-2:]': 'ay',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'officials',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'they',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'they',\n",
       "   'word[-3:]': 'hey',\n",
       "   'word[-2:]': 'ey',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'say',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'expect',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBP',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'expect',\n",
       "   'word[-3:]': 'ect',\n",
       "   'word[-2:]': 'ct',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'they',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'expect',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'get',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'get',\n",
       "   'word[-3:]': 'get',\n",
       "   'word[-2:]': 'et',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'access',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'access',\n",
       "   'word[-3:]': 'ess',\n",
       "   'word[-2:]': 'ss',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'get',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'access',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'sealed',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'sealed',\n",
       "   'word[-3:]': 'led',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'sensitive',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'sensitive',\n",
       "   'word[-3:]': 'ive',\n",
       "   'word[-2:]': 've',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'sealed',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'parts',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'parts',\n",
       "   'word[-3:]': 'rts',\n",
       "   'word[-2:]': 'ts',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'sensitive',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'of',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'of',\n",
       "   'word[-3:]': 'of',\n",
       "   'word[-2:]': 'of',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'parts',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'of',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'plant',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'plant',\n",
       "   'word[-3:]': 'ant',\n",
       "   'word[-2:]': 'nt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'wednesday',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'wednesday',\n",
       "   'word[-3:]': 'day',\n",
       "   'word[-2:]': 'ay',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'plant',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'wednesday',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'after',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'after',\n",
       "   'word[-3:]': 'ter',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': 'an',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'an',\n",
       "   'word[-3:]': 'an',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'after',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'iaea',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iaea',\n",
       "   'word[-3:]': 'AEA',\n",
       "   'word[-2:]': 'EA',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'an',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'surveillance',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'surveillance',\n",
       "   'word[-3:]': 'nce',\n",
       "   'word[-2:]': 'ce',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'iaea',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'system',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'system',\n",
       "   'word[-3:]': 'tem',\n",
       "   'word[-2:]': 'em',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'surveillance',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'begins',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'begins',\n",
       "   'word[-3:]': 'ins',\n",
       "   'word[-2:]': 'ns',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'system',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'functioning',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBG',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'functioning',\n",
       "   'word[-3:]': 'ing',\n",
       "   'word[-2:]': 'ng',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBG',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'begins',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'functioning',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBG',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'The',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'step',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'step',\n",
       "   'word[-3:]': 'tep',\n",
       "   'word[-2:]': 'ep',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'will',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'MD',\n",
       "   '+1:postag[:2]': 'MD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'will',\n",
       "   'word[-3:]': 'ill',\n",
       "   'word[-2:]': 'll',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'MD',\n",
       "   'postag[:2]': 'MD',\n",
       "   '-1:word.lower()': 'step',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'allow',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'allow',\n",
       "   'word[-3:]': 'low',\n",
       "   'word[-2:]': 'ow',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'will',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'MD',\n",
       "   '-1:postag[:2]': 'MD',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'allow',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'facility',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'facility',\n",
       "   'word[-3:]': 'ity',\n",
       "   'word[-2:]': 'ty',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'facility',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'operate',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'operate',\n",
       "   'word[-3:]': 'ate',\n",
       "   'word[-2:]': 'te',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'at',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'at',\n",
       "   'word[-3:]': 'at',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'operate',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'full',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'full',\n",
       "   'word[-3:]': 'ull',\n",
       "   'word[-2:]': 'll',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'at',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'capacity',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'capacity',\n",
       "   'word[-3:]': 'ity',\n",
       "   'word[-2:]': 'ty',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'full',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'capacity',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'The',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': 'european',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'european',\n",
       "   'word[-3:]': 'ean',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'union',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'union',\n",
       "   'word[-3:]': 'ion',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'european',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'union',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'with',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'with',\n",
       "   'word[-3:]': 'ith',\n",
       "   'word[-2:]': 'th',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': 'u.s.',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'u.s.',\n",
       "   'word[-3:]': '.S.',\n",
       "   'word[-2:]': 'S.',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'with',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'backing',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'backing',\n",
       "   'word[-3:]': 'ing',\n",
       "   'word[-2:]': 'ng',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'u.s.',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'backing',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'has',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'has',\n",
       "   'word[-3:]': 'has',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': 'threatened',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'threatened',\n",
       "   'word[-3:]': 'ned',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'has',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'threatened',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'refer',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'refer',\n",
       "   'word[-3:]': 'fer',\n",
       "   'word[-2:]': 'er',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'iran',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iran',\n",
       "   'word[-3:]': 'ran',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'refer',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'iran',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'u.n.',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'u.n.',\n",
       "   'word[-3:]': '.N.',\n",
       "   'word[-2:]': 'N.',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'security',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'security',\n",
       "   'word[-3:]': 'ity',\n",
       "   'word[-2:]': 'ty',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'u.n.',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'council',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'council',\n",
       "   'word[-3:]': 'cil',\n",
       "   'word[-2:]': 'il',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'security',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': ',',\n",
       "   '+1:postag[:2]': ','},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': ',',\n",
       "   'postag[:2]': ',',\n",
       "   '-1:word.lower()': 'council',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'which',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'WDT',\n",
       "   '+1:postag[:2]': 'WD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'which',\n",
       "   'word[-3:]': 'ich',\n",
       "   'word[-2:]': 'ch',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'WDT',\n",
       "   'postag[:2]': 'WD',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': ',',\n",
       "   '-1:postag[:2]': ',',\n",
       "   '+1:word.lower()': 'could',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'MD',\n",
       "   '+1:postag[:2]': 'MD'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'could',\n",
       "   'word[-3:]': 'uld',\n",
       "   'word[-2:]': 'ld',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'MD',\n",
       "   'postag[:2]': 'MD',\n",
       "   '-1:word.lower()': 'which',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'WDT',\n",
       "   '-1:postag[:2]': 'WD',\n",
       "   '+1:word.lower()': 'impose',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'impose',\n",
       "   'word[-3:]': 'ose',\n",
       "   'word[-2:]': 'se',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'could',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'MD',\n",
       "   '-1:postag[:2]': 'MD',\n",
       "   '+1:word.lower()': 'sanctions',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'sanctions',\n",
       "   'word[-3:]': 'ons',\n",
       "   'word[-2:]': 'ns',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'impose',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'if',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'if',\n",
       "   'word[-3:]': 'if',\n",
       "   'word[-2:]': 'if',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'sanctions',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'it',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'it',\n",
       "   'word[-3:]': 'it',\n",
       "   'word[-2:]': 'it',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'if',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'finds',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'finds',\n",
       "   'word[-3:]': 'nds',\n",
       "   'word[-2:]': 'ds',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'it',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'tehran',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'tehran',\n",
       "   'word[-3:]': 'ran',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'finds',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'has',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBZ',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'has',\n",
       "   'word[-3:]': 'has',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBZ',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'tehran',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'violated',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'violated',\n",
       "   'word[-3:]': 'ted',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'has',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBZ',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'violated',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'nuclear',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'nuclear',\n",
       "   'word[-3:]': 'ear',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'non-proliferation',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'non-proliferation',\n",
       "   'word[-3:]': 'ion',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'nuclear',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'treaty',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'treaty',\n",
       "   'word[-3:]': 'aty',\n",
       "   'word[-2:]': 'ty',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'non-proliferation',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'treaty',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'iran',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iran',\n",
       "   'word[-3:]': 'ran',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': '.',\n",
       "   '-1:postag[:2]': '.',\n",
       "   '+1:word.lower()': \"'s\",\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'POS',\n",
       "   '+1:postag[:2]': 'PO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': \"'s\",\n",
       "   'word[-3:]': \"'s\",\n",
       "   'word[-2:]': \"'s\",\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'POS',\n",
       "   'postag[:2]': 'PO',\n",
       "   '-1:word.lower()': 'iran',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'new',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'new',\n",
       "   'word[-3:]': 'new',\n",
       "   'word[-2:]': 'ew',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': \"'s\",\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'POS',\n",
       "   '-1:postag[:2]': 'PO',\n",
       "   '+1:word.lower()': 'president',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'president',\n",
       "   'word[-3:]': 'ent',\n",
       "   'word[-2:]': 'nt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'new',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'mahmoud',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'mahmoud',\n",
       "   'word[-3:]': 'oud',\n",
       "   'word[-2:]': 'ud',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'president',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'ahmadinejad',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'ahmadinejad',\n",
       "   'word[-3:]': 'jad',\n",
       "   'word[-2:]': 'ad',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'mahmoud',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'said',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBD',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'said',\n",
       "   'word[-3:]': 'aid',\n",
       "   'word[-2:]': 'id',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBD',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'ahmadinejad',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'tuesday',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'tuesday',\n",
       "   'word[-3:]': 'day',\n",
       "   'word[-2:]': 'ay',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'said',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBD',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'that',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'that',\n",
       "   'word[-3:]': 'hat',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'tuesday',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'european',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'european',\n",
       "   'word[-3:]': 'ean',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'that',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'incentives',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNS',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'incentives',\n",
       "   'word[-3:]': 'ves',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'european',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'aimed',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBN',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'aimed',\n",
       "   'word[-3:]': 'med',\n",
       "   'word[-2:]': 'ed',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'incentives',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'at',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'IN',\n",
       "   '+1:postag[:2]': 'IN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'at',\n",
       "   'word[-3:]': 'at',\n",
       "   'word[-2:]': 'at',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   '-1:word.lower()': 'aimed',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'persuading',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBG',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'persuading',\n",
       "   'word[-3:]': 'ing',\n",
       "   'word[-2:]': 'ng',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBG',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'at',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   '+1:word.lower()': 'iran',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NNP',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iran',\n",
       "   'word[-3:]': 'ran',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'persuading',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBG',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'iran',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'end',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VB',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'end',\n",
       "   'word[-3:]': 'end',\n",
       "   'word[-2:]': 'nd',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VB',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'its',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PRP$',\n",
       "   '+1:postag[:2]': 'PR'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'its',\n",
       "   'word[-3:]': 'its',\n",
       "   'word[-2:]': 'ts',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PRP$',\n",
       "   'postag[:2]': 'PR',\n",
       "   '-1:word.lower()': 'end',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VB',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'nuclear',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'nuclear',\n",
       "   'word[-3:]': 'ear',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'its',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PRP$',\n",
       "   '-1:postag[:2]': 'PR',\n",
       "   '+1:word.lower()': 'fuel',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'fuel',\n",
       "   'word[-3:]': 'uel',\n",
       "   'word[-2:]': 'el',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'nuclear',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': 'program',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'program',\n",
       "   'word[-3:]': 'ram',\n",
       "   'word[-2:]': 'am',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'fuel',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'are',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VBP',\n",
       "   '+1:postag[:2]': 'VB'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'are',\n",
       "   'word[-3:]': 'are',\n",
       "   'word[-2:]': 're',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   '-1:word.lower()': 'program',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'an',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'an',\n",
       "   'word[-3:]': 'an',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'are',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   '+1:word.lower()': 'insult',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'insult',\n",
       "   'word[-3:]': 'ult',\n",
       "   'word[-2:]': 'lt',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'an',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'to',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'TO',\n",
       "   '+1:postag[:2]': 'TO'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'to',\n",
       "   'word[-3:]': 'to',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'TO',\n",
       "   'postag[:2]': 'TO',\n",
       "   '-1:word.lower()': 'insult',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   '+1:word.lower()': 'the',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DT',\n",
       "   '+1:postag[:2]': 'DT'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'the',\n",
       "   'word[-3:]': 'the',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   '-1:word.lower()': 'to',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'TO',\n",
       "   '-1:postag[:2]': 'TO',\n",
       "   '+1:word.lower()': 'iranian',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'iranian',\n",
       "   'word[-3:]': 'ian',\n",
       "   'word[-2:]': 'an',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   '-1:word.lower()': 'the',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   '+1:word.lower()': 'nation',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NN',\n",
       "   '+1:postag[:2]': 'NN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'nation',\n",
       "   'word[-3:]': 'ion',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   '-1:word.lower()': 'iranian',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': '.',\n",
       "   '+1:postag[:2]': '.'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   '-1:word.lower()': 'nation',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'EOS': True}]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'geo-nam', 'gpe-nam', '[]', 'per-fam', 'org-nam', 'tim-dow',\n",
       "       'art-nam', 'per-tit', 'per-giv', 'per-nam', 'tim-yoc', 'tim-moy',\n",
       "       'tim-dom', 'tim-dat', 'tim-nam', 'nat-nam', 'eve-ord', 'eve-nam',\n",
       "       'tim-clo', 'per-ord', 'per-ini', 'org-leg', 'per-mid', 'art-add'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_tags = voa_data['ne_tags'].unique()\n",
    "ne_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument must be a string or number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-fd41bf743dd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m    219\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"argument must be a string or number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument must be a string or number"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y[:2])\n",
    "\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8APgvUyskaf"
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "scoring = make_scorer(roc_auc_score, needs_proba=True, average='weighted', multi_class='ovr')\n",
    "cv = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>365118</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430144</td>\n",
       "      <td>27891</td>\n",
       "      <td>10</td>\n",
       "      <td>18001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  pos  lemma\n",
       "365118     23    2     16\n",
       "430144  27891   10  18001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    206238\n",
      "           1       1.00      1.00      1.00       804\n",
      "           3       0.37      0.15      0.22       168\n",
      "           4       0.38      0.14      0.20        95\n",
      "           5       0.41      0.82      0.55        11\n",
      "           6       0.81      0.87      0.84     11266\n",
      "           7       0.99      0.94      0.96      3966\n",
      "           8       0.63      0.58      0.61        57\n",
      "           9       1.00      0.33      0.50         3\n",
      "          10       0.76      0.64      0.70      8913\n",
      "          11       0.88      0.90      0.89      1648\n",
      "          12       0.86      0.79      0.82       514\n",
      "          13       0.80      0.89      0.84         9\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.75      0.78      0.76      4612\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.92      0.96      0.94      1962\n",
      "          18       0.78      0.39      0.52       173\n",
      "          19       0.64      0.24      0.35      2117\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.99      1.00      1.00      2331\n",
      "          22       0.99      1.00      0.99       757\n",
      "          23       0.00      0.00      0.00        23\n",
      "          24       0.98      0.99      0.99       576\n",
      "\n",
      "    accuracy                           0.96    246256\n",
      "   macro avg       0.66      0.60      0.61    246256\n",
      "weighted avg       0.96      0.96      0.96    246256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "bernoulliCLF = RandomForestClassifier()\n",
    "\n",
    "bernoulliCLF.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bernoulliCLF.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "Pickling array (shape=(3,), dtype=object).\n",
      "Memmapping (shape=(985023,), dtype=int64) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_23576_9312356208\\23576-1560074912544-306ce5811dbb4b66b62623150468230d.pkl\n",
      "Memmapping (shape=(3, 985023), dtype=int32) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_23576_9312356208\\23576-1560074912544-4f49efd3a67244c6b96efdb9249fc20b.pkl\n",
      "Pickling array (shape=(3,), dtype=object).\n",
      "Memmapping (shape=(985023,), dtype=int64) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_23576_9312356208\\23576-1560074912544-bcb30020675d4c18adb8d7b97e180c4a.pkl\n",
      "Memmapping (shape=(985023,), dtype=int32) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_23576_9312356208\\23576-1560074912544-376e0bf02d7445838cd1faf84f72d354.pkl\n",
      "Memmapping (shape=(985023,), dtype=int64) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_23576_9312356208\\23576-1560074912544-59d2ee40163a4431b8fcb56ef18c3e13.pkl\n",
      "Memmapping (shape=(689516,), dtype=int32) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_23576_9312356208\\23576-1560074912544-601f8f1702ac4996ab5aead174add22f.pkl\n",
      "Memmapping (shape=(295507,), dtype=int32) to new file C:\\Users\\Oleg\\AppData\\Local\\Temp\\joblib_memmapping_folder_23576_9312356208\\23576-1560074912544-a94e3235d6a74cf2ac198ccd9d39fea8.pkl\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes in y_true not equal to the number of columns in 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_validation.py\", line 544, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_validation.py\", line 591, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n    *args, **kwargs)\n  File \"C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\_scorer.py\", line 260, in _score\n    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n  File \"C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\_ranking.py\", line 383, in roc_auc_score\n    multi_class, average, sample_weight)\n  File \"C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\_ranking.py\", line 477, in _multiclass_roc_auc_score\n    \"Number of classes in y_true not equal to the number of \"\nValueError: Number of classes in y_true not equal to the number of columns in 'y_score'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-20ee8138e8f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m scores = cross_validate(BernoulliNB(), X_train, y_train, cv=cv, n_jobs=-1, \n\u001b[1;32m----> 2\u001b[1;33m                         scoring=scoring, verbose=100)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(BernoulliNB(), X_train, y_train, cv=cv, n_jobs=-1, \n",
    "                        scoring=scoring, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'in'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-93764fae8958>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoa_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'in'"
     ]
    }
   ],
   "source": [
    "RandomForestClassifier().fit(voa_data[:100], target[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'brier_score_loss',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['roc_auc']\n",
    "cv = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf=CRF(algorithm='lbfgs',\n",
    "         c1=0.1,\n",
    "         c2=0.1,\n",
    "         max_iterations=100,\n",
    "         all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "Pickling array (shape=(70,), dtype=int32).\n",
      "Pickling array (shape=(30,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.2s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 556, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 599, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 629, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 173, in __call__\n    y_type = type_of_target(y)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 260, in type_of_target\n    raise ValueError('You appear to be using a legacy multi-label data'\nValueError: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b6e467631103>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#                          scoring=scoring, verbose=100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m scores = cross_validate(crf, X_train[:100], y_train[:100], cv=cv, n_jobs=-1, \n\u001b[1;32m----> 4\u001b[1;33m                          scoring=scoring, verbose=100)\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 232\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "# scores = cross_validate(crf, X_train, y_train, cv=cv, n_jobs=-1, \n",
    "#                          scoring=scoring, verbose=100)\n",
    "scores = cross_validate(crf, X_train[:100], y_train[:100], cv=cv, n_jobs=-1, \n",
    "                         scoring=scoring, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97032539, 0.97388456, 0.97253039, 0.97323582, 0.97233593])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "HW1. NER.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
