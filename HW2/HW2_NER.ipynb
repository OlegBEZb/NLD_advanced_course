{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1. NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "384px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlegBEZb/NLP_advanced_course/blob/master/HW2/HW2_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "KVRaU_zG-PaI"
      },
      "source": [
        "# About notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "gjCnYYETSLxd"
      },
      "source": [
        "Dataset\n",
        "*\tGroningen Meaning Bank (version 2.2.0)\n",
        "*\tTask: named entity recognition\n",
        "*\tTarget – named entity tags (BIO + entity type)\n",
        "*\tInput data: \n",
        "  * Use “en.met” files to extract the subcorpus\n",
        "  corpus = 'Voice of America' (for honogeneity of the input data set)\n",
        "  * Use \"en.tags\" files for the main input data:\n",
        "      *\traw tokens + may use the lemmas and the POS-tags \n",
        "  (i.e. take the “golden” POS-tagging);\n",
        "      *\twhich means:\n",
        "        *\tfirst three columns for input: ['word', 'pos', 'lemma']\n",
        "        *\tthe fourth column for target variable (‘ne_tags’)\n",
        "        (BIO annotation + the named-entity type in one tag)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K5QmPxPgSLxf"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pK9ZLcizSLxg"
      },
      "source": [
        "1.\tThe most trivial model = supervised HMM:\n",
        "  *\tTake hmmlearn (former sklearn), modify MultinomialHMM (I.e. inherit a new class from _BaseHMM making it a modified copy of the latter) to allow for supervised HMM training. The states of the HMM model = the NE tags.\n",
        "  *\tNOTE: may use NaiveBayes to learn emission probabilities in a supervized manner.\n",
        "  *\tOr implement from scratch (with Viterbi for prediction).\n",
        "  *\tNOTE: use tuples of features for X (not just the word, but additional info).\n",
        "  *\tNOTE: use smoothing for state transitions.\n",
        "2.\tCRF\n",
        "  *\tModify the input features;\n",
        "  *\tUse CRFSuite.\n",
        "3.\tBi-LSTM:\n",
        "  *\tUse keras or tensorflow;\n",
        "  *\thttps://github.com/hse-aml/natural-language-processing/blob/master/week2/week2-NER.ipynb\n",
        "  *\tA plus for incorporating CNN-layers;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9jHB1yCYSLxh"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uqBWS_YOSLxi"
      },
      "source": [
        "* normalized confusion matrices, precision, recall, F-score \n",
        "(macro- and micro-) \n",
        "* (token level, entity level, partial matching (i.e. boundary-detection problem), binary).  \n",
        "NOTE: taking into account vocabulary transfer is a plus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9JfSarnSLxk",
        "colab_type": "text"
      },
      "source": [
        "http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/  \n",
        "http://larsmans.github.io/seqlearn/reference.html#module-seqlearn.datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "x0bjDrHYSLxm"
      },
      "source": [
        "# Evaluation Criteria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "8mJvCwaRSLxo"
      },
      "source": [
        "Scoring (14.5 max):  \n",
        "*\tDataset overview – 0.5\n",
        "  *\ttext lengths, vocabulary size, frequencies of patterns (<UNK-type-i>) \n",
        "  *\tstats over the target tags\n",
        "*\tFeature engineering – 2 (1+1)\n",
        "  *\tgrammatical words = closed set (~ stop words)\n",
        "  *\tStemming + POS\n",
        "  *\tWord shape\n",
        "  *\tAd hoc features ( +1)  \n",
        "*\tWord patterns -> encode types of unknown words +0.5\n",
        "*\tSmoothing in HMM – 0.5 \n",
        "  *\tIn HMM: for state transitions.\n",
        "*\tIncorporating tupled features in HMM (on top of tokens) – 1\n",
        "*\tThe correct HMM implementation – 1\n",
        "*\tMore fine-grained feature engineering for the Neural Network + 0.5\n",
        "  *\tDifferentiate between POS-relevancy for the word and the context, etc.\n",
        "  *\tSentence-level features (may use “golden” sentence-splitting)\n",
        "*\tEvaluation (on all levels) – 1\n",
        "*\tConclusion on HMM deficiency (as a model) – 1\n",
        "*\tCRF: 1 point for use and evaluation, + 0.5 points for comparison and conclusions;\n",
        "*\tNN:\n",
        "  *\tMain network: 4\n",
        "  *\tCNN layers: +2  \n",
        "\n",
        "Libraries: hmmlearn, crfsuite, tensorflow, keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "30D0Scxk4kn3"
      },
      "source": [
        "# Libs import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUftFhCTmV_w",
        "colab_type": "text"
      },
      "source": [
        "## Downloading, upgrading libs, fixing bug in seqlearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8MF1D8wS7dO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sklearn-crfsuite\n",
        "!pip install -U scipy\n",
        "!pip install seqlearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU9D7GLjmvut",
        "colab_type": "text"
      },
      "source": [
        "There is unsolved issue https://github.com/larsmans/seqlearn/issues/45  \n",
        "And there is no opportunity to use lower version of scipy because of other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur3f4jJ4kinE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cec835c0-56a9-4962-9dbe-357e9a819431"
      },
      "source": [
        "!rm /usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoLpi_3vkjmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3399d960-cd14-426a-b4d8-663e9f98bf2e"
      },
      "source": [
        "%%writefile /usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py\n",
        "\n",
        "\"\"\"Hidden Markov models (HMMs) with supervised training.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "#from scipy.misc import logsumexp\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "from .base import BaseSequenceClassifier\n",
        "from ._utils import atleast2d_or_csr, count_trans, safe_sparse_dot\n",
        "\n",
        "\n",
        "class MultinomialHMM(BaseSequenceClassifier):\n",
        "    \"\"\"First-order hidden Markov model with multinomial event model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    decode : string, optional\n",
        "        Decoding algorithm, either \"bestfirst\" or \"viterbi\" (default).\n",
        "        Best-first decoding is also called posterior decoding in the HMM\n",
        "        literature.\n",
        "\n",
        "    alpha : float\n",
        "        Lidstone (additive) smoothing parameter.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, decode=\"viterbi\", alpha=.01):\n",
        "        self.alpha = alpha\n",
        "        self.decode = decode\n",
        "\n",
        "    def fit(self, X, y, lengths):\n",
        "        \"\"\"Fit HMM model to data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "\n",
        "        y : array-like, shape (n_samples,)\n",
        "            Target labels.\n",
        "\n",
        "        lengths : array-like of integers, shape (n_sequences,)\n",
        "            Lengths of the individual sequences in X, y. The sum of these\n",
        "            should be n_samples.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        Make sure the training set (X) is one-hot encoded; if more than one\n",
        "        feature in X is on, the emission probabilities will be multiplied.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : MultinomialHMM\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.alpha\n",
        "        if alpha <= 0:\n",
        "            raise ValueError(\"alpha should be >0, got {0!r}\".format(alpha))\n",
        "\n",
        "        X = atleast2d_or_csr(X)\n",
        "        classes, y = np.unique(y, return_inverse=True)\n",
        "        lengths = np.asarray(lengths)\n",
        "        Y = y.reshape(-1, 1) == np.arange(len(classes))\n",
        "\n",
        "        end = np.cumsum(lengths)\n",
        "        start = end - lengths\n",
        "\n",
        "        init_prob = np.log(Y[start].sum(axis=0) + alpha)\n",
        "        init_prob -= logsumexp(init_prob)\n",
        "        final_prob = np.log(Y[start].sum(axis=0) + alpha)\n",
        "        final_prob -= logsumexp(final_prob)\n",
        "\n",
        "        feature_prob = np.log(safe_sparse_dot(Y.T, X) + alpha)\n",
        "        feature_prob -= logsumexp(feature_prob, axis=0)\n",
        "\n",
        "        trans_prob = np.log(count_trans(y, len(classes)) + alpha)\n",
        "        trans_prob -= logsumexp(trans_prob, axis=0)\n",
        "\n",
        "        self.coef_ = feature_prob\n",
        "        self.intercept_init_ = init_prob\n",
        "        self.intercept_final_ = final_prob\n",
        "        self.intercept_trans_ = trans_prob\n",
        "\n",
        "        self.classes_ = classes\n",
        "\n",
        "        return self"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzGIALzmnHyB",
        "colab_type": "text"
      },
      "source": [
        "## Importing libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab_type": "code",
        "id": "ZnXUdrxQ3TAN",
        "outputId": "a73e2ce3-62ec-439b-de9f-d20aec8df884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "%autosave 180\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "from copy import deepcopy\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import codecs\n",
        "from collections import Counter\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn.metrics import recall_score, roc_auc_score, make_scorer, f1_score, fbeta_score\n",
        "\n",
        "from seqlearn.hmm import MultinomialHMM\n",
        "from seqlearn.evaluation import SequenceKFold\n",
        "from seqlearn.evaluation import bio_f_score\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(180000)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Autosaving every 180 seconds\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VD2z8D2V7Dod"
      },
      "source": [
        "# Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okymGz_lEjLC",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "COLAB = True\n",
        "test_size = 0.2\n",
        "subcorpus = 'Voice of America'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORjyFpGXUgLw",
        "colab_type": "text"
      },
      "source": [
        "The raw data was preprocessed on my own PC bacause of google drive limitations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "trusted": true,
        "id": "oEOxPSZASzMt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e0ddb73a-3767-4fb8-a49b-e69a164f356a"
      },
      "source": [
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    data_folder = '/content/drive/My Drive/Advanced NLP/Homework 2: Named entity recognition on Groningen Meaning Bank dataset'\n",
        "else:\n",
        "    data_folder = 'D:\\Data\\gmb-2.2.0\\data'\n",
        "    print('data found:', os.listdir(data_folder))\n",
        "    \n",
        "print('data found:', os.listdir(data_folder))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "data found: ['HW1. NER.ipynb', 'Voice of America.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "yeZfDywxSLx6",
        "colab_type": "text"
      },
      "source": [
        "# Data extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "tgwhO8ngi-A4"
      },
      "source": [
        "Parsing data from \"Voice of America\" subcorpus. According to the instructions we take first four columns and additional column to separate data on texts, sentences or words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "-UBeZ_eui-A5",
        "outputId": "5308f75a-eaa2-42e3-ecae-4f6aa512ec36",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "voa_data = pd.DataFrame(columns=['word', 'pos', 'lemma', 'ne_tags', 'text_id'])\n",
        "\n",
        "os.chdir(data_path)\n",
        "part_paths = os.listdir()\n",
        "\n",
        "for part_path in tqdm(part_paths, total=len(part_paths)):\n",
        "    os.chdir(part_path)\n",
        "    document_paths = os.listdir()\n",
        "    for document_path in document_paths:\n",
        "        os.chdir(document_path)\n",
        "        f = codecs.open(\"en.met\", 'r', \"utf_8_sig\")\n",
        "        file_met = f.read()\n",
        "        if ('subcorpus: {}'.format(subcorpus) in file_met):\n",
        "            tags_df = pd.read_csv('en.tags',\n",
        "                                  sep='\\t',\n",
        "                                  header=None,\n",
        "                                  names=['word', 'pos', 'lemma', 'ne_tags'],\n",
        "                                  usecols=[0, 1, 2, 3],\n",
        "                                  error_bad_lines=False)\n",
        "            tags_df['text_id'] = str(part_path) + '_' + str(document_path)\n",
        "            voa_data = voa_data.append(tags_df, ignore_index=True)\n",
        "        f.close()\n",
        "        os.chdir('..')\n",
        "    os.chdir('..')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [08:55<00:00,  5.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wall time: 8min 55s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "JYpE1dtnSLyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_memory_usage(df):\n",
        "    print(\"memory usage: \", df.memory_usage().sum()/1024/1024, \" MB\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "UX1ViqnKi-A-",
        "outputId": "c391cb23-3288-4f4f-db22-f5afc86f4fa2",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "show_memory_usage(voa_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "memory usage:  46.969688415527344  MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "RYMlRwEcSLyO",
        "colab_type": "code",
        "colab": {},
        "outputId": "83f64eb0-ef62-46d1-bc84-475a0310520b"
      },
      "source": [
        "voa_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>march</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            word  pos         lemma ne_tags    text_id\n",
              "0      Thousands  NNS      thousand       O  p00_d0018\n",
              "1             of   IN            of       O  p00_d0018\n",
              "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
              "3           have  VBP          have       O  p00_d0018\n",
              "4        marched  VBN         march       O  p00_d0018"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "kUrX7pvxi-BB",
        "outputId": "f42abe57-ad1b-4a64-a7b3-6bf93acb5155",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "voa_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1231279, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "8vWQ-w4Qi-BF"
      },
      "source": [
        "Number of tokens coincided with the declared in README file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJLE7LWKSLyv",
        "colab_type": "text"
      },
      "source": [
        "## Make BIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjC-2hcvSLyw",
        "colab_type": "text"
      },
      "source": [
        "Classificators work better if avoid redundant granularity. Also such detailed fragmentation has no value for the task of only finding named entities. Thus, we can combine subcategories and leave only first part of tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBAE5CEJSLyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "443869f8-8853-4861-ea03-e398e47ab086"
      },
      "source": [
        "voa_data['ne_tags'] = voa_data['ne_tags'].apply(lambda x: x.split('-')[0])\n",
        "\n",
        "voa_data['ne_tags'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O      1032479\n",
              "geo      55480\n",
              "org      44659\n",
              "per      43168\n",
              "tim      30097\n",
              "gpe      19685\n",
              "[]        4064\n",
              "art        790\n",
              "eve        577\n",
              "nat        280\n",
              "Name: ne_tags, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1RJCoftSLy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def use_prev_value_decorator(func):\n",
        "    prev_tag = \"O\"\n",
        "\n",
        "    def wrapper(curr_tag, **kwargs):\n",
        "        nonlocal prev_tag\n",
        "        bio_tag = func(curr_tag, prev_tag)\n",
        "        prev_tag = curr_tag\n",
        "        return bio_tag\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "@use_prev_value_decorator\n",
        "# Tag tokens with standard NLP BIO tags\n",
        "def bio_tagger(curr_tag, prev_tag):\n",
        "    if curr_tag == \"O\":  #O\n",
        "        return curr_tag\n",
        "    elif curr_tag != \"O\" and prev_tag == \"O\":  # Begin NE\n",
        "        return \"B-\" + curr_tag\n",
        "    elif prev_tag != \"O\" and prev_tag == curr_tag:  # Inside NE\n",
        "        return \"I-\" + curr_tag\n",
        "    elif prev_tag != \"O\" and prev_tag != curr_tag:  # Adjacent NE\n",
        "        return \"B-\" + curr_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1aST79f1SLy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "7d41a9e1-b7b2-4365-95f2-3584c2d021b6"
      },
      "source": [
        "%%time \n",
        "\n",
        "voa_data['bio_tag'] = voa_data['ne_tags'].apply(bio_tagger, axis=1)\n",
        "\n",
        "print(voa_data['bio_tag'].value_counts().head())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O        1032479\n",
            "B-geo      46622\n",
            "B-org      24133\n",
            "B-tim      23302\n",
            "I-per      21799\n",
            "Name: bio_tag, dtype: int64\n",
            "CPU times: user 762 ms, sys: 6.99 ms, total: 769 ms\n",
            "Wall time: 769 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJX8dQw8oxD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "311a3149-4dba-4eb5-8dd6-bedb79746a99"
      },
      "source": [
        "voa_data.head(2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "      <th>bio_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        word  pos     lemma ne_tags    text_id bio_tag\n",
              "0  Thousands  NNS  thousand       O  p00_d0018       O\n",
              "1         of   IN        of       O  p00_d0018       O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Yl_enYrKSLyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voa_data.to_csv(os.path.join(data_folder,'{}.csv'.format(subcorpus)), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaKxWL7ASLzA",
        "colab_type": "text"
      },
      "source": [
        "Possible investigation: check if loop for column would be faster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "15GVrJYa717o"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "o0tal3WpSLyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "36840d16-1f9f-4ae7-e32a-3d4986e3e08b"
      },
      "source": [
        "if COLAB:\n",
        "    voa_data = pd.read_csv(os.path.join(data_folder,'{}.csv'.format(subcorpus)))\n",
        "else:\n",
        "    voa_data = pd.read_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus))\n",
        "voa_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "      <th>bio_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>march</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            word  pos         lemma ne_tags    text_id bio_tag\n",
              "0      Thousands  NNS      thousand       O  p00_d0018       O\n",
              "1             of   IN            of       O  p00_d0018       O\n",
              "2  demonstrators  NNS  demonstrator       O  p00_d0018       O\n",
              "3           have  VBP          have       O  p00_d0018       O\n",
              "4        marched  VBN         march       O  p00_d0018       O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "b1Y2cJhli-BG",
        "outputId": "0eccaadc-ec5b-48ef-e77d-077c60bbc821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def average_text_length(text_id):\n",
        "    doc_lengths = list(dict(Counter(text_id)).values())\n",
        "    sum = 0\n",
        "    for length in doc_lengths:\n",
        "        sum += length\n",
        "    return sum/len(doc_lengths)\n",
        "\n",
        "print(\"average text length: \", average_text_length(voa_data['text_id']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average text length:  134.31646121959201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "OARm2L-aSLyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "db4cf63a-7e0a-4ef4-b920-b45962349a4d"
      },
      "source": [
        "voa_data.describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "      <th>bio_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>35154</td>\n",
              "      <td>48</td>\n",
              "      <td>27209</td>\n",
              "      <td>10</td>\n",
              "      <td>9167</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0090</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>61398</td>\n",
              "      <td>168817</td>\n",
              "      <td>74941</td>\n",
              "      <td>1032479</td>\n",
              "      <td>388</td>\n",
              "      <td>1032479</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           word      pos    lemma  ne_tags    text_id  bio_tag\n",
              "count   1231279  1231279  1231279  1231279    1231279  1231279\n",
              "unique    35154       48    27209       10       9167       19\n",
              "top         the       NN      the        O  p00_d0090        O\n",
              "freq      61398   168817    74941  1032479        388  1032479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "DCIKki2uSLyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8f563918-8d4d-426f-ead0-d7b171a0ae0d"
      },
      "source": [
        "voa_data['ne_tags'].value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O      1032479\n",
              "geo      55480\n",
              "org      44659\n",
              "per      43168\n",
              "tim      30097\n",
              "gpe      19685\n",
              "[]        4064\n",
              "art        790\n",
              "eve        577\n",
              "nat        280\n",
              "Name: ne_tags, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96IP1SG7piIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "434c25c5-af59-4d42-d083-4cf517cee357"
      },
      "source": [
        "voa_data['bio_tag'].value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        1032479\n",
              "B-geo      46622\n",
              "B-org      24133\n",
              "B-tim      23302\n",
              "I-per      21799\n",
              "B-per      21369\n",
              "I-org      20526\n",
              "B-gpe      19469\n",
              "I-geo       8858\n",
              "I-tim       6795\n",
              "B-[]        4061\n",
              "B-art        455\n",
              "I-art        335\n",
              "B-eve        316\n",
              "I-eve        261\n",
              "B-nat        225\n",
              "I-gpe        216\n",
              "I-nat         55\n",
              "I-[]           3\n",
              "Name: bio_tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "UDocGTMBSLzD",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "nkdjfnBqSLzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentences(df, word_col='word', pos_col='pos', \n",
        "                  tag_col='bio_tag', id_col='text_id'):\n",
        "    \"\"\"func to get the sentences in this format:\n",
        "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_n, Tag_n)]\"\"\"\n",
        "    \n",
        "    agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[word_col].values.tolist(),\n",
        "                                                       s[pos_col].values.tolist(),\n",
        "                                                       s[tag_col].values.tolist())]\n",
        "    grouped = df.groupby(id_col).apply(agg_func)\n",
        "    sentences = [s for s in grouped]\n",
        "    \n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "w1HlGz6hSLzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d4ac658a-589c-46f7-954a-f8889fe5663b"
      },
      "source": [
        "%%time\n",
        "\n",
        "word_pos_tag_sentences = get_sentences(voa_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.29 s, sys: 79.1 ms, total: 1.37 s\n",
            "Wall time: 1.37 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "gBGopIG2SLzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a7385623-261d-4a12-b5d8-0e534270071e"
      },
      "source": [
        "#Lets visualize how the sentences are distributed by their length\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.hist([len(s) for s in word_pos_tag_sentences], bins=50)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "QGG9Ugo_SLzR",
        "colab_type": "text"
      },
      "source": [
        "create featuretfransformer like in https://www.depends-on-the-definition.com/introduction-named-entity-recognition-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "n6vL4H0uSLzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:], #replace with BPE\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def get_sent_labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "DEWQp8ecSLzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1ed4c6b8-11dd-4d6f-f56a-01ee2ae9db77"
      },
      "source": [
        "%%time \n",
        "\n",
        "X = [sent2features(s) for s in word_pos_tag_sentences]\n",
        "y = [get_sent_labels(s) for s in word_pos_tag_sentences]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.17 s, sys: 571 ms, total: 3.75 s\n",
            "Wall time: 3.75 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "-PcS8QWySLzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# le = LabelEncoder()\n",
        "# le.fit(y[:2])\n",
        "\n",
        "# le.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "arkFb4AhSLzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcZ30-ZdSLzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b007be2a-71d1-4e79-dc95-e961d815ab8d"
      },
      "source": [
        "%%time\n",
        "\n",
        "lengths_train = [len(x) for x in X_train]\n",
        "\n",
        "flatten_X_train = [item for sublist in X_train for item in sublist]\n",
        "\n",
        "flatten_y_train = [item for sublist in y_train for item in sublist]\n",
        "\n",
        "assert len(flatten_X_train) == np.array(lengths_train).sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 70 ms, sys: 17 ms, total: 87 ms\n",
            "Wall time: 86.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4iDcFD5SLzi",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPpcblmfSLzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scoring = make_scorer(roc_auc_score, needs_proba=True, average='weighted', multi_class='ovr')\n",
        "def f1_macro(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='macro')\n",
        "def fbeta_macro(y_true, y_pred, beta=2):\n",
        "    return fbeta_score(y_true, y_pred, average='macro', beta=beta)\n",
        "scoring = [bio_f_score, f1_macro, fbeta_macro]\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "sequence_cv = SequenceKFold(lengths_train, n_folds=5, n_iter=1, shuffle=True, random_state=42, yield_lengths=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n8APgvUyskaf"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEOKnlyZSLzs",
        "colab_type": "text"
      },
      "source": [
        "## HMM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qOHd9iN-SLz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "aae9b748-7c2f-4156-f041-193f7b91cfe3"
      },
      "source": [
        "%%time\n",
        "\n",
        "dv = DictVectorizer(sparse=True)\n",
        "# if sparse=False, memory dies\n",
        "flatten_X_train_vec = dv.fit_transform(flatten_X_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16.1 s, sys: 1.02 s, total: 17.1 s\n",
            "Wall time: 17.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiOIK4JoSLz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cb347727-53ae-45c1-c6b4-39cd7aae8250"
      },
      "source": [
        "%%time\n",
        "\n",
        "hmm = MultinomialHMM(decode='viterbi', alpha=0.01)\n",
        "hmm.fit(flatten_X_train_vec, flatten_y_train, lengths_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 868 ms, sys: 30.8 ms, total: 899 ms\n",
            "Wall time: 898 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXF0IWBuSL0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dbe3636-0343-48e0-b9c5-5049ff6e34d6"
      },
      "source": [
        "pred = hmm.predict(flatten_X_train_vec, \n",
        "                   #lengths=lengths_train,\n",
        "                   )\n",
        "bio_f_score(flatten_y_train, pred)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1978130125751777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta2fR9UdSL0F",
        "colab_type": "text"
      },
      "source": [
        "how to pass length to pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dNNFC2v_SL0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline([('vectorizer', DictVectorizer(sparse=True)),\n",
        "                 ('seq_clf', hmm)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceH2N7qkRCbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_cv = SequenceKFold(lengths_train, n_folds=2, n_iter=1, shuffle=True, random_state=42, yield_lengths=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTw2uVfgO8u3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_seq_cross_validate(estimator, X, y, cv, scoring):\n",
        "    scores = dict((metric.__name__, []) for metric in scoring)\n",
        "    print(scores)\n",
        "    for train, lengths_train, test, lengths_test in tqdm(list(cv)):\n",
        "        estimator_copy = deepcopy(estimator)\n",
        "        model_name = pipe.steps[-1][0]\n",
        "        estimator_copy.fit(X[train], y[train], **{model_name+'__lengths': lengths_train})\n",
        "        pred = estimator_copy.predict(X[test], **{'lengths': lengths_test})\n",
        "        for metric in scoring:\n",
        "            print(metric.__name__)\n",
        "            scores[metric.__name__].append(metric(y_true=y[test], y_pred=pred))\n",
        "    return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohHj9tOco7U4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "68222bdf-09cb-475e-9c55-e4f4c51f9ba2"
      },
      "source": [
        "scores = my_seq_cross_validate(pipe,\n",
        "                               np.array(flatten_X_train),\n",
        "                               np.array(flatten_y_train),\n",
        "                               sequence_cv,\n",
        "                               scoring)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bio_f_score': [], 'f1_macro': [], 'fbeta_macro': []}\n",
            "bio_f_score\n",
            "f1_macro\n",
            "fbeta_macro\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 1/2 [00:19<00:19, 19.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bio_f_score\n",
            "f1_macro\n",
            "fbeta_macro\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 2/2 [00:39<00:00, 19.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54-YJrbCvWgI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "cb3d7bde-5038-4d87-ad73-672526607e30"
      },
      "source": [
        "pd.DataFrame.from_dict(scores)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bio_f_score</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>fbeta_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.187745</td>\n",
              "      <td>0.146345</td>\n",
              "      <td>0.134927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.189133</td>\n",
              "      <td>0.142209</td>\n",
              "      <td>0.131189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bio_f_score  f1_macro  fbeta_macro\n",
              "0     0.187745  0.146345     0.134927\n",
              "1     0.189133  0.142209     0.131189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SnNpzcznSL0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = cross_validate(estimator=pipe, \n",
        "                        X=flatten_X_train, \n",
        "                        y=flatten_y_train, \n",
        "                        cv=sequence_cv, \n",
        "                        n_jobs=-1, \n",
        "                        scoring=bio_f_score, \n",
        "                        verbose=100,\n",
        "                        fit_params={'lengths': lengths_train})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6NWSQdFbSL0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIhTA47mSL0d",
        "colab_type": "text"
      },
      "source": [
        "## CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVKjWd3wSL0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crf=CRF(algorithm='lbfgs',\n",
        "         c1=0.1,\n",
        "         c2=0.1,\n",
        "         max_iterations=100,\n",
        "         all_possible_transitions=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tlFaU1qTSL0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scores = cross_validate(crf, X_train, y_train, cv=cv, n_jobs=-1, \n",
        "#                          scoring=scoring, verbose=100)\n",
        "scores = cross_validate(crf, X_train[:100], y_train[:100], cv=cv, n_jobs=-1, \n",
        "                         scoring=scoring, verbose=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd9e9nYgSL0m",
        "colab_type": "code",
        "colab": {},
        "outputId": "dbd5b17a-5492-4c50-b48d-0d2713bcd322"
      },
      "source": [
        "scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97032539, 0.97388456, 0.97253039, 0.97323582, 0.97233593])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}