{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1. NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "384px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4a84f1c06b34227b75d128a51a82d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95fb0b243e234e989e5f166489e3bc88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fccf7ed036694d76b071e11d1179a492",
              "IPY_MODEL_d092bae32bdb48389c8b9c25df13d1a1"
            ]
          }
        },
        "95fb0b243e234e989e5f166489e3bc88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fccf7ed036694d76b071e11d1179a492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b6eab54021140d69405a6deedac5f9b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 8,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b8c015059d540a7b0780e7d78bb18c0"
          }
        },
        "d092bae32bdb48389c8b9c25df13d1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1eff841162c54139bfaf5ba8aedd08f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/8 [02:28&lt;00:00, 18.50s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40617a7d172a4536be5451cb810adafa"
          }
        },
        "5b6eab54021140d69405a6deedac5f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b8c015059d540a7b0780e7d78bb18c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1eff841162c54139bfaf5ba8aedd08f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40617a7d172a4536be5451cb810adafa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f45ce16602f54f3ba34d3e95afbca514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_023bd140826c4d7daa3576bd1a691033",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26e43c5b2e874934b0c7c4494a71494c",
              "IPY_MODEL_856486a7bef543e894694d65b869b1da"
            ]
          }
        },
        "023bd140826c4d7daa3576bd1a691033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26e43c5b2e874934b0c7c4494a71494c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a30bf3cfb5534b84932bb22b491d131f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a65114dca834a2bb32e23cac42cc27d"
          }
        },
        "856486a7bef543e894694d65b869b1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ba9e31825084b01be3c246ce85d674f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.73s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94ef18e73685457a99107a8f35a691fa"
          }
        },
        "a30bf3cfb5534b84932bb22b491d131f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a65114dca834a2bb32e23cac42cc27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ba9e31825084b01be3c246ce85d674f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94ef18e73685457a99107a8f35a691fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f656a91824324958a7ca8f8a22eb36fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03534413eeed48ea8e359ca1695a644f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3127767d1df49b5b2ba9bb345c9fa23",
              "IPY_MODEL_9f608d24e8984e7d928787c01e8bcd63"
            ]
          }
        },
        "03534413eeed48ea8e359ca1695a644f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3127767d1df49b5b2ba9bb345c9fa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f357ac82ef704829ac8a6308bd8c4b0f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcbf26ca360b49a5849428b4f82ea9cf"
          }
        },
        "9f608d24e8984e7d928787c01e8bcd63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19b8e6d8d4ce478582ac51f569dc414e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.65s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93c1e2c856004760910461e1c1eaa81f"
          }
        },
        "f357ac82ef704829ac8a6308bd8c4b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcbf26ca360b49a5849428b4f82ea9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19b8e6d8d4ce478582ac51f569dc414e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93c1e2c856004760910461e1c1eaa81f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c762f72c0d74610971f14419eb1f77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e25ec04478248e89547194e43865bbb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_258a1f291fde4a40829cb581e10da680",
              "IPY_MODEL_82c5f91a9d10441ba2ae035eb9de2936"
            ]
          }
        },
        "2e25ec04478248e89547194e43865bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "258a1f291fde4a40829cb581e10da680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9ec6e1dcb984412bfb75bc16850cadf",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da7bf79f5d4a49299f0d0c9970a62e9b"
          }
        },
        "82c5f91a9d10441ba2ae035eb9de2936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f247b1d89fc457eb87ec1a18eb30be4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.70s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca79a346472743068eb779252473c487"
          }
        },
        "e9ec6e1dcb984412bfb75bc16850cadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da7bf79f5d4a49299f0d0c9970a62e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f247b1d89fc457eb87ec1a18eb30be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca79a346472743068eb779252473c487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ef95639863848f586957fa4823e5da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_941e276d3b124f8e8f6d6451edd9f4d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09e6562e30ff41a58c2dcd06089b1529",
              "IPY_MODEL_4c6fbe7617844969a03f099c6cf329f3"
            ]
          }
        },
        "941e276d3b124f8e8f6d6451edd9f4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09e6562e30ff41a58c2dcd06089b1529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3a33c390c5a4581bac946a16fa1eb9e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_415762ee983b44bdba02e9c3f62f59fa"
          }
        },
        "4c6fbe7617844969a03f099c6cf329f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b50024e4380498693d9c73e1ed61010",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.65s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f1fdfe150cf49d38178680dd1428ec4"
          }
        },
        "c3a33c390c5a4581bac946a16fa1eb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "415762ee983b44bdba02e9c3f62f59fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b50024e4380498693d9c73e1ed61010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f1fdfe150cf49d38178680dd1428ec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd85ee4310054709aa8c856a2e53419d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9bdacedde394392a26acc7aff38792e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5bc090a8379b4cd6b97132dbceb1f09e",
              "IPY_MODEL_7340797a41284319b19537f7fd03f5f5"
            ]
          }
        },
        "a9bdacedde394392a26acc7aff38792e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bc090a8379b4cd6b97132dbceb1f09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b071173e66bf4adcb618d0bd6a2a1413",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_506f8fbe830b40b787b2a192ac7e1343"
          }
        },
        "7340797a41284319b19537f7fd03f5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93c9a83ceb654e00bb90981a8f0c1f5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.72s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d15bd90075f741138938b5aaa54319a2"
          }
        },
        "b071173e66bf4adcb618d0bd6a2a1413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "506f8fbe830b40b787b2a192ac7e1343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93c9a83ceb654e00bb90981a8f0c1f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d15bd90075f741138938b5aaa54319a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ffde3a620b04824a654d45a691a79ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e6b3b99f72d4a37af3779a308a7a04c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d0c85b3844847129b622807d516f3f0",
              "IPY_MODEL_00b9587b903e41cb84180009bd409df9"
            ]
          }
        },
        "7e6b3b99f72d4a37af3779a308a7a04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d0c85b3844847129b622807d516f3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a52761a5d5e4fac98121e01fb376fd5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_510186523d2544f6a2aff4376e2387e3"
          }
        },
        "00b9587b903e41cb84180009bd409df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92609aa187a9427493e2afe938f0c528",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.65s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7a5845caf60444389c56007f48631b9"
          }
        },
        "1a52761a5d5e4fac98121e01fb376fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "510186523d2544f6a2aff4376e2387e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92609aa187a9427493e2afe938f0c528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7a5845caf60444389c56007f48631b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf55f18efc6748cb8a0b954fc02a3fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8f241b5c3d74f4da440208e8c21b066",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5520c24070a409e899d40bab89eb22f",
              "IPY_MODEL_810f5040b3c348cd8b0c3e34dccb7895"
            ]
          }
        },
        "d8f241b5c3d74f4da440208e8c21b066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5520c24070a409e899d40bab89eb22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_551d39b97c96417d818b3cf2615e7777",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eaf12f3480934de994f71a09006ccb2f"
          }
        },
        "810f5040b3c348cd8b0c3e34dccb7895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d94082cab95d4868a4236f81e429d44b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.68s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db4359d585bc4157b3beea372b160458"
          }
        },
        "551d39b97c96417d818b3cf2615e7777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eaf12f3480934de994f71a09006ccb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d94082cab95d4868a4236f81e429d44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db4359d585bc4157b3beea372b160458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acbbe65d0025430d901ebc72ff226a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1522f8813be74dd1a4c9a7f814f80f00",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_730c83053c964a80b8bbe6e0a17a1078",
              "IPY_MODEL_eb07ca7501504304ba77f3562ba1e786"
            ]
          }
        },
        "1522f8813be74dd1a4c9a7f814f80f00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "730c83053c964a80b8bbe6e0a17a1078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_507719b20a9d4132bed5a478413ff1f5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee87667c7eeb4b449bc8f73c3922f166"
          }
        },
        "eb07ca7501504304ba77f3562ba1e786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_23036e6b27d546bc8a262b6228dcb35c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:18&lt;00:00,  3.63s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd184f0c8f7c44da85298b9c2ca47a19"
          }
        },
        "507719b20a9d4132bed5a478413ff1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee87667c7eeb4b449bc8f73c3922f166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23036e6b27d546bc8a262b6228dcb35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd184f0c8f7c44da85298b9c2ca47a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlegBEZb/NLP_advanced_course/blob/master/HW2/HW2_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "KVRaU_zG-PaI"
      },
      "source": [
        "# About notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "gjCnYYETSLxd"
      },
      "source": [
        "Dataset\n",
        "*\tGroningen Meaning Bank (version 2.2.0)\n",
        "*\tTask: named entity recognition\n",
        "*\tTarget – named entity tags (BIO + entity type)\n",
        "*\tInput data: \n",
        "  * Use “en.met” files to extract the subcorpus\n",
        "  corpus = 'Voice of America' (for honogeneity of the input data set)\n",
        "  * Use \"en.tags\" files for the main input data:\n",
        "      *\traw tokens + may use the lemmas and the POS-tags \n",
        "  (i.e. take the “golden” POS-tagging);\n",
        "      *\twhich means:\n",
        "        *\tfirst three columns for input: ['word', 'pos', 'lemma']\n",
        "        *\tthe fourth column for target variable (‘ne_tags’)\n",
        "        (BIO annotation + the named-entity type in one tag)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K5QmPxPgSLxf"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pK9ZLcizSLxg"
      },
      "source": [
        "1.\tThe most trivial model = supervised HMM:\n",
        "  *\tTake hmmlearn (former sklearn), modify MultinomialHMM (I.e. inherit a new class from _BaseHMM making it a modified copy of the latter) to allow for supervised HMM training. The states of the HMM model = the NE tags.\n",
        "  *\tNOTE: may use NaiveBayes to learn emission probabilities in a supervized manner.\n",
        "  *\tOr implement from scratch (with Viterbi for prediction).\n",
        "  *\tNOTE: use tuples of features for X (not just the word, but additional info).\n",
        "  *\tNOTE: use smoothing for state transitions.\n",
        "2.\tCRF\n",
        "  *\tModify the input features;\n",
        "  *\tUse CRFSuite.\n",
        "3.\tBi-LSTM:\n",
        "  *\tUse keras or tensorflow;\n",
        "  *\thttps://github.com/hse-aml/natural-language-processing/blob/master/week2/week2-NER.ipynb\n",
        "  *\tA plus for incorporating CNN-layers;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9jHB1yCYSLxh"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uqBWS_YOSLxi"
      },
      "source": [
        "* normalized confusion matrices, precision, recall, F-score \n",
        "(macro- and micro-) \n",
        "* (token level, entity level, partial matching (i.e. boundary-detection problem), binary).  \n",
        "NOTE: taking into account vocabulary transfer is a plus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9JfSarnSLxk",
        "colab_type": "text"
      },
      "source": [
        "http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/  \n",
        "http://larsmans.github.io/seqlearn/reference.html#module-seqlearn.datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "x0bjDrHYSLxm"
      },
      "source": [
        "# Evaluation Criteria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "8mJvCwaRSLxo"
      },
      "source": [
        "Scoring (14.5 max):  \n",
        "*\tDataset overview – 0.5\n",
        "  *\ttext lengths, vocabulary size, frequencies of patterns (<UNK-type-i>) \n",
        "  *\tstats over the target tags\n",
        "*\tFeature engineering – 2 (1+1)\n",
        "  *\tgrammatical words = closed set (~ stop words)\n",
        "  *\tStemming + POS\n",
        "  *\tWord shape\n",
        "  *\tAd hoc features ( +1)  \n",
        "*\tWord patterns -> encode types of unknown words +0.5\n",
        "*\tSmoothing in HMM – 0.5 \n",
        "  *\tIn HMM: for state transitions.\n",
        "*\tIncorporating tupled features in HMM (on top of tokens) – 1\n",
        "*\tThe correct HMM implementation – 1\n",
        "*\tMore fine-grained feature engineering for the Neural Network + 0.5\n",
        "  *\tDifferentiate between POS-relevancy for the word and the context, etc.\n",
        "  *\tSentence-level features (may use “golden” sentence-splitting)\n",
        "*\tEvaluation (on all levels) – 1\n",
        "*\tConclusion on HMM deficiency (as a model) – 1\n",
        "*\tCRF: 1 point for use and evaluation, + 0.5 points for comparison and conclusions;\n",
        "*\tNN:\n",
        "  *\tMain network: 4\n",
        "  *\tCNN layers: +2  \n",
        "\n",
        "Libraries: hmmlearn, crfsuite, tensorflow, keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "30D0Scxk4kn3"
      },
      "source": [
        "# Libs import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUftFhCTmV_w",
        "colab_type": "text"
      },
      "source": [
        "## Downloading, upgrading libs, fixing bugs in seqlearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8MF1D8wS7dO",
        "colab_type": "code",
        "outputId": "6e1ed201-70f2-4d04-aebc-ddff967e8989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install sklearn-crfsuite\n",
        "!pip install -U scipy\n",
        "!pip install seqlearn\n",
        "!pip install seqeval\n",
        "!pip install hmmlearn==0.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.38.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\r\u001b[K     |▍                               | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 6.0MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 4.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 573kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 583kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 716kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 727kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 737kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 747kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n",
            "Requirement already up-to-date: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.2)\n",
            "Collecting seqlearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/2c/95da36839f647a6b15da1fd10f68d755c7fca549c92aabb3ff734f5c682c/seqlearn-0.2.tar.gz (557kB)\n",
            "\u001b[K     |████████████████████████████████| 563kB 3.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: seqlearn\n",
            "  Building wheel for seqlearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqlearn: filename=seqlearn-0.2-cp36-cp36m-linux_x86_64.whl size=314729 sha256=6ba1e95ab1b586c7a4bdbda8fb8733642e7a9293d80126d3ab7efd513d49ff25\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/bb/ba/a0b9c1a28f660d56616e0b75dd7a0e4d3d202a92fae5ede886\n",
            "Successfully built seqlearn\n",
            "Installing collected packages: seqlearn\n",
            "Successfully installed seqlearn-0.2\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.2)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=58e5d44a2bce232326afbf8b6f4b9cd7a75296a69a5262ca9e6c8d86eb5271d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n",
            "Collecting hmmlearn==0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/c5/91b43156b193d180ed94069269bcf88d3c7c6e54514a8482050fa9995e10/hmmlearn-0.2.2.tar.gz (146kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn==0.2.2) (1.18.2)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn==0.2.2) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn==0.2.2) (0.14.1)\n",
            "Building wheels for collected packages: hmmlearn\n",
            "  Building wheel for hmmlearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hmmlearn: filename=hmmlearn-0.2.2-cp36-cp36m-linux_x86_64.whl size=326424 sha256=3a2fa2e2370b8075ab074610abbe0d4ef65b5b32877a52b934fc72f9bf5be43f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/b6/0e/63a865a30e21e01d04f417d8995fbfb793d6bd464707efc546\n",
            "Successfully built hmmlearn\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU9D7GLjmvut",
        "colab_type": "text"
      },
      "source": [
        "There is unsolved issue https://github.com/larsmans/seqlearn/issues/45  \n",
        "And there is no opportunity to use lower version of scipy because of other dependencies  \n",
        "Also there is a [bug](https://github.com/larsmans/seqlearn/pull/29) with calculating final probabilities which is fixed below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur3f4jJ4kinE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm /usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoLpi_3vkjmP",
        "colab_type": "code",
        "outputId": "4e2d504e-3a77-47b2-890a-1dcde95e7eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile /usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py\n",
        "\n",
        "\"\"\"Hidden Markov models (HMMs) with supervised training.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "#from scipy.misc import logsumexp\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "from .base import BaseSequenceClassifier\n",
        "from ._utils import atleast2d_or_csr, count_trans, safe_sparse_dot\n",
        "\n",
        "\n",
        "class MultinomialHMM(BaseSequenceClassifier):\n",
        "    \"\"\"First-order hidden Markov model with multinomial event model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    decode : string, optional\n",
        "        Decoding algorithm, either \"bestfirst\" or \"viterbi\" (default).\n",
        "        Best-first decoding is also called posterior decoding in the HMM\n",
        "        literature.\n",
        "\n",
        "    alpha : float\n",
        "        Lidstone (additive) smoothing parameter.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, decode=\"viterbi\", alpha=.01):\n",
        "        self.alpha = alpha\n",
        "        self.decode = decode\n",
        "\n",
        "    def fit(self, X, y, lengths):\n",
        "        \"\"\"Fit HMM model to data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "\n",
        "        y : array-like, shape (n_samples,)\n",
        "            Target labels.\n",
        "\n",
        "        lengths : array-like of integers, shape (n_sequences,)\n",
        "            Lengths of the individual sequences in X, y. The sum of these\n",
        "            should be n_samples.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        Make sure the training set (X) is one-hot encoded; if more than one\n",
        "        feature in X is on, the emission probabilities will be multiplied.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : MultinomialHMM\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.alpha\n",
        "        if alpha <= 0:\n",
        "            raise ValueError(\"alpha should be >0, got {0!r}\".format(alpha))\n",
        "\n",
        "        X = atleast2d_or_csr(X)\n",
        "        classes, y = np.unique(y, return_inverse=True)\n",
        "        lengths = np.asarray(lengths)\n",
        "        Y = y.reshape(-1, 1) == np.arange(len(classes))\n",
        "\n",
        "        end = np.cumsum(lengths)\n",
        "        start = end - lengths\n",
        "\n",
        "        init_prob = np.log(Y[start].sum(axis=0) + alpha)\n",
        "        init_prob -= logsumexp(init_prob)\n",
        "        #final_prob = np.log(Y[start].sum(axis=0) + alpha)\n",
        "        final_prob = np.log(Y[end - 1].sum(axis=0) + alpha)\n",
        "        final_prob -= logsumexp(final_prob)\n",
        "\n",
        "        feature_prob = np.log(safe_sparse_dot(Y.T, X) + alpha)\n",
        "        feature_prob -= logsumexp(feature_prob, axis=0)\n",
        "\n",
        "        trans_prob = np.log(count_trans(y, len(classes)) + alpha)\n",
        "        trans_prob -= logsumexp(trans_prob, axis=0)\n",
        "\n",
        "        self.coef_ = feature_prob\n",
        "        self.intercept_init_ = init_prob\n",
        "        self.intercept_final_ = final_prob\n",
        "        self.intercept_trans_ = trans_prob\n",
        "\n",
        "        self.classes_ = classes\n",
        "\n",
        "        return self"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /usr/local/lib/python3.6/dist-packages/seqlearn/hmm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzGIALzmnHyB",
        "colab_type": "text"
      },
      "source": [
        "## Importing libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab_type": "code",
        "id": "ZnXUdrxQ3TAN",
        "outputId": "89b042c6-a995-4bb5-cb5a-1373b6973ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "%autosave 180\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "import sys\n",
        "from copy import deepcopy\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import codecs\n",
        "from collections import Counter\n",
        "import re\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import chain\n",
        "from functools import wraps\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_validate, KFold, ParameterGrid, RandomizedSearchCV    \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn_crfsuite import CRF\n",
        "\n",
        "from seqlearn.hmm import MultinomialHMM as seqlearn_MHMM\n",
        "from hmmlearn.hmm import MultinomialHMM as hmmlearn_MHMM\n",
        "from seqlearn.evaluation import SequenceKFold, bio_f_score\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.metrics import recall_score, roc_auc_score, make_scorer, f1_score, fbeta_score, classification_report\n",
        "from seqeval.metrics import classification_report as entity_classification_report\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)-9s [%(asctime)s] : %(message)s', stream=sys.stdout)\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(180000)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Autosaving every 180 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VD2z8D2V7Dod"
      },
      "source": [
        "# Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okymGz_lEjLC",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "COLAB = True\n",
        "test_size = 0.2\n",
        "subcorpus = 'Voice of America'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORjyFpGXUgLw",
        "colab_type": "text"
      },
      "source": [
        "The raw data was preprocessed on my own PC bacause of google drive limitations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "trusted": true,
        "id": "oEOxPSZASzMt",
        "outputId": "f0e3ad5a-f8a1-4f67-fc02-0728dd754b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    data_folder = '/content/drive/My Drive/Advanced NLP/Homework 2: Named entity recognition on Groningen Meaning Bank dataset'\n",
        "else:\n",
        "    data_folder = 'D:\\Data\\gmb-2.2.0\\data'\n",
        "    print('data found:', os.listdir(data_folder))\n",
        "    \n",
        "print('data found:', os.listdir(data_folder))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "data found: ['HW1. NER.ipynb', 'Voice of America.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "yeZfDywxSLx6",
        "colab_type": "text"
      },
      "source": [
        "# Data extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "tgwhO8ngi-A4"
      },
      "source": [
        "Parsing data from \"Voice of America\" subcorpus. According to the instructions we take first four columns and additional column to separate data on texts, sentences or words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "-UBeZ_eui-A5",
        "outputId": "5308f75a-eaa2-42e3-ecae-4f6aa512ec36",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "voa_data = pd.DataFrame(columns=['word', 'pos', 'lemma', 'ne_tags', 'text_id'])\n",
        "\n",
        "os.chdir(data_path)\n",
        "part_paths = os.listdir()\n",
        "\n",
        "for part_path in tqdm(part_paths, total=len(part_paths)):\n",
        "    os.chdir(part_path)\n",
        "    document_paths = os.listdir()\n",
        "    for document_path in document_paths:\n",
        "        os.chdir(document_path)\n",
        "        f = codecs.open(\"en.met\", 'r', \"utf_8_sig\")\n",
        "        file_met = f.read()\n",
        "        if ('subcorpus: {}'.format(subcorpus) in file_met):\n",
        "            tags_df = pd.read_csv('en.tags',\n",
        "                                  sep='\\t',\n",
        "                                  header=None,\n",
        "                                  names=['word', 'pos', 'lemma', 'ne_tags'],\n",
        "                                  usecols=[0, 1, 2, 3],\n",
        "                                  error_bad_lines=False)\n",
        "            tags_df['text_id'] = str(part_path) + '_' + str(document_path)\n",
        "            voa_data = voa_data.append(tags_df, ignore_index=True)\n",
        "        f.close()\n",
        "        os.chdir('..')\n",
        "    os.chdir('..')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [08:55<00:00,  5.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wall time: 8min 55s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "JYpE1dtnSLyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_memory_usage(df):\n",
        "    print(\"memory usage: \", df.memory_usage().sum()/1024/1024, \" MB\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "UX1ViqnKi-A-",
        "outputId": "c391cb23-3288-4f4f-db22-f5afc86f4fa2",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "show_memory_usage(voa_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "memory usage:  46.969688415527344  MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "RYMlRwEcSLyO",
        "colab_type": "code",
        "outputId": "83f64eb0-ef62-46d1-bc84-475a0310520b",
        "colab": {}
      },
      "source": [
        "voa_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>march</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            word  pos         lemma ne_tags    text_id\n",
              "0      Thousands  NNS      thousand       O  p00_d0018\n",
              "1             of   IN            of       O  p00_d0018\n",
              "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
              "3           have  VBP          have       O  p00_d0018\n",
              "4        marched  VBN         march       O  p00_d0018"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "kUrX7pvxi-BB",
        "outputId": "f42abe57-ad1b-4a64-a7b3-6bf93acb5155",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "voa_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1231279, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "hidden": true,
        "id": "8vWQ-w4Qi-BF"
      },
      "source": [
        "Number of tokens coincided with the declared in README file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJLE7LWKSLyv",
        "colab_type": "text"
      },
      "source": [
        "## Make BIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjC-2hcvSLyw",
        "colab_type": "text"
      },
      "source": [
        "Classificators work better if avoid redundant granularity. Also such detailed fragmentation has no value for the task of only finding named entities. Thus, we can combine subcategories and leave only first part of tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBAE5CEJSLyy",
        "colab_type": "code",
        "outputId": "443869f8-8853-4861-ea03-e398e47ab086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "voa_data['ne_tags'] = voa_data['ne_tags'].apply(lambda x: x.split('-')[0])\n",
        "\n",
        "voa_data['ne_tags'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O      1032479\n",
              "geo      55480\n",
              "org      44659\n",
              "per      43168\n",
              "tim      30097\n",
              "gpe      19685\n",
              "[]        4064\n",
              "art        790\n",
              "eve        577\n",
              "nat        280\n",
              "Name: ne_tags, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1RJCoftSLy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def use_prev_value_decorator(func):\n",
        "    prev_tag = \"O\"\n",
        "\n",
        "    def wrapper(curr_tag, **kwargs):\n",
        "        nonlocal prev_tag\n",
        "        bio_tag = func(curr_tag, prev_tag)\n",
        "        prev_tag = curr_tag\n",
        "        return bio_tag\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "@use_prev_value_decorator\n",
        "# Tag tokens with standard NLP BIO tags\n",
        "def bio_tagger(curr_tag, prev_tag):\n",
        "    if curr_tag == \"O\":  #O\n",
        "        return curr_tag\n",
        "    elif curr_tag != \"O\" and prev_tag == \"O\":  # Begin NE\n",
        "        return \"B-\" + curr_tag\n",
        "    elif prev_tag != \"O\" and prev_tag == curr_tag:  # Inside NE\n",
        "        return \"I-\" + curr_tag\n",
        "    elif prev_tag != \"O\" and prev_tag != curr_tag:  # Adjacent NE\n",
        "        return \"B-\" + curr_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1aST79f1SLy6",
        "colab_type": "code",
        "outputId": "7d41a9e1-b7b2-4365-95f2-3584c2d021b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "voa_data['bio_tag'] = voa_data['ne_tags'].apply(bio_tagger, axis=1)\n",
        "\n",
        "print(voa_data['bio_tag'].value_counts().head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O        1032479\n",
            "B-geo      46622\n",
            "B-org      24133\n",
            "B-tim      23302\n",
            "I-per      21799\n",
            "Name: bio_tag, dtype: int64\n",
            "CPU times: user 762 ms, sys: 6.99 ms, total: 769 ms\n",
            "Wall time: 769 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJX8dQw8oxD1",
        "colab_type": "code",
        "outputId": "311a3149-4dba-4eb5-8dd6-bedb79746a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "voa_data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "      <th>bio_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        word  pos     lemma ne_tags    text_id bio_tag\n",
              "0  Thousands  NNS  thousand       O  p00_d0018       O\n",
              "1         of   IN        of       O  p00_d0018       O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Yl_enYrKSLyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voa_data.to_csv(os.path.join(data_folder,'{}.csv'.format(subcorpus)), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaKxWL7ASLzA",
        "colab_type": "text"
      },
      "source": [
        "Possible investigation: check if loop for column would be faster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDWnjmrRSbi0",
        "colab_type": "text"
      },
      "source": [
        "#Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "o0tal3WpSLyc",
        "colab_type": "code",
        "outputId": "52355f17-9637-4608-bc2f-cdb6962bb100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "if COLAB:\n",
        "    voa_data = pd.read_csv(os.path.join(data_folder,'{}.csv'.format(subcorpus)))\n",
        "else:\n",
        "    voa_data = pd.read_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus))\n",
        "voa_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "      <th>bio_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>thousand</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>march</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0018</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            word  pos         lemma ne_tags    text_id bio_tag\n",
              "0      Thousands  NNS      thousand       O  p00_d0018       O\n",
              "1             of   IN            of       O  p00_d0018       O\n",
              "2  demonstrators  NNS  demonstrator       O  p00_d0018       O\n",
              "3           have  VBP          have       O  p00_d0018       O\n",
              "4        marched  VBN         march       O  p00_d0018       O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "15GVrJYa717o"
      },
      "source": [
        "# EDA and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "b1Y2cJhli-BG",
        "outputId": "8bcfdb5a-446a-49a1-c2cf-4876ce019568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def average_text_length(text_id):\n",
        "    doc_lengths = list(dict(Counter(text_id)).values())\n",
        "    sum = 0\n",
        "    for length in doc_lengths:\n",
        "        sum += length\n",
        "    return sum/len(doc_lengths)\n",
        "\n",
        "print(\"average text length: \", average_text_length(voa_data['text_id']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average text length:  134.31646121959201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "OARm2L-aSLyj",
        "colab_type": "code",
        "outputId": "30582425-53b7-47e1-f891-5d5fcc050f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "voa_data.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemma</th>\n",
              "      <th>ne_tags</th>\n",
              "      <th>text_id</th>\n",
              "      <th>bio_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "      <td>1231279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>35154</td>\n",
              "      <td>48</td>\n",
              "      <td>27209</td>\n",
              "      <td>10</td>\n",
              "      <td>9167</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>p00_d0090</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>61398</td>\n",
              "      <td>168817</td>\n",
              "      <td>74941</td>\n",
              "      <td>1032479</td>\n",
              "      <td>388</td>\n",
              "      <td>1032479</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           word      pos    lemma  ne_tags    text_id  bio_tag\n",
              "count   1231279  1231279  1231279  1231279    1231279  1231279\n",
              "unique    35154       48    27209       10       9167       19\n",
              "top         the       NN      the        O  p00_d0090        O\n",
              "freq      61398   168817    74941  1032479        388  1032479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "DCIKki2uSLyq",
        "colab_type": "code",
        "outputId": "6f989730-6dae-44d5-909c-d40d81950d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "voa_data['ne_tags'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O      1032479\n",
              "geo      55480\n",
              "org      44659\n",
              "per      43168\n",
              "tim      30097\n",
              "gpe      19685\n",
              "[]        4064\n",
              "art        790\n",
              "eve        577\n",
              "nat        280\n",
              "Name: ne_tags, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMN2b4zujvpW",
        "colab_type": "text"
      },
      "source": [
        "Let's check what does the [] tag mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpH766G2iB49",
        "colab_type": "code",
        "outputId": "1780e59c-286c-4252-a5c2-59710e6f26e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "voa_data[voa_data['ne_tags'] == '[]']['word'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\\tLQU\\t    3025\n",
              "\\tRQU\\t    1039\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wurgKOpRi-d7",
        "colab_type": "code",
        "outputId": "a60382bf-21d3-48e3-c4bd-e4775b9b3d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "' '.join(voa_data[voa_data['text_id'] == 'p00_d0018']['word'].values)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country . Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \\tLQU\\t Bush Number One Terrorist \\tRQU\\t and \\tLQU\\t Stop the Bombings . \\tLQU\\t They marched from the Houses of Parliament to a rally in Hyde Park . Police put the number of marchers at 10,000 while organizers claimed it was 100,000 . The protest comes on the eve of the annual conference of Britain 's ruling Labor Party in the southern English seaside resort of Brighton . The party is divided over Britain 's participation in the Iraq conflict and the continued deployment of 8,500 British troops in that country . The London march came ahead of anti-war protests today in other cities , including Rome , Paris , and Madrid .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwoWJqMQj6fn",
        "colab_type": "text"
      },
      "source": [
        "Comparison with the raw text shew that these values mean quotes. We can use this fact as a feature but quotes are not considered here as named entities so we convert them to O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdk1HCD6lbyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voa_data.loc[voa_data['ne_tags'] == '[]', ['ne_tags', 'bio_tag']] = 'O', 'O'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96IP1SG7piIB",
        "colab_type": "code",
        "outputId": "fc8f81e2-fb76-4ceb-eaf0-133445c72425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "voa_data['bio_tag'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        1036543\n",
              "B-geo      46622\n",
              "B-org      24133\n",
              "B-tim      23302\n",
              "I-per      21799\n",
              "B-per      21369\n",
              "I-org      20526\n",
              "B-gpe      19469\n",
              "I-geo       8858\n",
              "I-tim       6795\n",
              "B-art        455\n",
              "I-art        335\n",
              "B-eve        316\n",
              "I-eve        261\n",
              "B-nat        225\n",
              "I-gpe        216\n",
              "I-nat         55\n",
              "Name: bio_tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33WDK75S1kHp",
        "colab_type": "code",
        "outputId": "56c93a97-98c8-4028-92c0-2c8d1145605e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "unique_labels = voa_data['bio_tag'].nunique()\n",
        "unique_labels"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVeoAGgfbowZ",
        "colab_type": "code",
        "outputId": "0321220d-a8cd-47c0-eb34-3ba16e2df8f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "#Words distribution across Tags without O tag\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(15, 5))\n",
        "ax = sns.countplot('bio_tag', data=voa_data.loc[voa_data['bio_tag'] != 'O'])\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ju3cG1P137k",
        "colab_type": "text"
      },
      "source": [
        "todo: add wordshape. from spacy for example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "nkdjfnBqSLzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentences(df, word_col='word', pos_col='pos', \n",
        "                  tag_col='bio_tag', id_col='text_id'):\n",
        "    \"\"\"func to get the sentences in this format:\n",
        "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_n, Tag_n)]\"\"\"\n",
        "    \n",
        "    agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[word_col].values.tolist(),\n",
        "                                                       s[pos_col].values.tolist(),\n",
        "                                                       s[tag_col].values.tolist())]\n",
        "    grouped = df.groupby(id_col).apply(agg_func)\n",
        "    sentences = [s for s in grouped]\n",
        "    \n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "w1HlGz6hSLzI",
        "colab_type": "code",
        "outputId": "1c259fc9-7438-47db-b3c7-1471f48da165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "word_pos_tag_sentences = get_sentences(voa_data)\n",
        "\n",
        "#Lets visualize how the sentences are distributed by their length\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.hist([len(s) for s in word_pos_tag_sentences], bins=50)\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfAUlEQVR4nO3de2xT9+H+8bdzow0hF9tcFi6jgaCJFAo0rBQNEoI1TaXb+FIUqTeJUoZoWqLAqLisYps6IFMbkgUSUQ0UOlqtrRDQtVrL5GUBtRmaQxJawsqtrANxCbHTNAm0JPH5/cGvFikJAdtxDjvP66/6c47t53xc8+ScYx/bDMMwEBERS4oa6AAiIjJwVAIiIhamEhARsTCVgIiIhakEREQsTCUgImJhMQMdoC/nz5/vdZnT6aSpqSmCae6c2TMqX2iULzRmzwfmz9hTvtTU1Nu+v/YEREQsTCUgImJhKgEREQtTCYiIWJhKQETEwlQCIiIWphIQEbEwlYCIiIWpBERELMz03xiW/01dv/hZj+PRf/xLhJOIWJv2BERELEwlICJiYSoBERELUwmIiFiYSkBExMJUAiIiFqYSEBGxMJWAiIiFqQRERCysz28Ml5eXU1tbS1JSEkVFRYHxDz74gP379xMVFcW0adN46qmnANi7dy+VlZVERUXxzDPPMGXKFADq6+upqKjA7/czd+5c5s+f30+bJCIit6vPEsjOzuYnP/kJZWVlgbGjR49SU1PDK6+8QmxsLC0tLQCcO3eO6upqNm/eTHNzMy+//DJ/+MMfANixYwcvvfQSDoeDtWvXkpmZyahRo/pps0RE5Hb0WQITJ06ksbGx29jf/vY3fv7znxMbGwtAUlISAB6Ph5kzZxIbG8uwYcMYMWIEp06dAmDEiBEMHz4cgJkzZ+LxeFQCIiIDLKgLyF24cIHPPvuMt956i9jYWJ5++mnGjx+Pz+cjPT09sJ7dbsfn8wHgcDgC4w6Hg5MnT/b42G63G7fbDUBhYSFOp7P38DExt1xuBmbPOFD5LvUy/t0smr/QKF/ozJ4x1HxBlYDf76etrY0NGzZw+vRpiouL2bp1a9AhbuRyuXC5XIHbTU1Nva7rdDpvudwMzJ7RbPm+m8Vs+b5L+UJj9nxg/ow95UtNTb3t+wdVAna7nR/+8IfYbDbGjx9PVFQUra2t2O12vF5vYD2fz4fdbgfoNu71egPjIiIycIL6iOj06dNpaGgA4Pz583R2djJkyBAyMzOprq6mo6ODxsZGLly4wPjx4xk3bhwXLlygsbGRzs5OqquryczMDOuGiIjInetzT6CkpIRjx47R2trKsmXLyM3NJScnh/Lycn75y18SExPD888/j81mY/To0Tz88MOsXLmSqKgonn32WaKirvfM4sWL2bBhA36/nzlz5jB69Oh+3zgREbm1PkugoKCgx/H8/PwexxcsWMCCBQtuGp82bRrTpk27w3giItKf9I1hERELUwmIiFiYSkBExMKC+oioSH/p+sXPut3+9ktl0X/8S+TDiFiA9gRERCxMJSAiYmEqARERC1MJiIhYmEpARMTCVAIiIhamEhARsTCVgIiIhakEREQsTCUgImJhKgEREQvr89pB5eXl1NbWkpSURFFRUbdl7733Hrt27WL79u0kJiZiGAYVFRXU1dUxaNAg8vLySEtLA6Cqqoo9e/YA139zIDs7O/xbIyIid6TPPYHs7GzWrVt303hTUxOffPJJt1+5r6ur4+LFi5SWlrJ06VK2b98OQFtbG7t372bjxo1s3LiR3bt309bWFsbNEBGRYPRZAhMnTiQhIeGm8ddff50nn3wSm80WGKupqWH27NnYbDYmTJhAe3s7zc3N1NfXM3nyZBISEkhISGDy5MnU19eHd0tEROSOBXVOwOPxYLfbGTt2bLdxn8/Xbc/A4XDg8/nw+Xw4HI7AuN1ux+fzBZdYRETC5o5/T+Cbb75h7969vPTSS/2RB7fbjdvtBqCwsLBbqXxXTEzMLZebgdkzDlS+S32v0o1Z51Cvb2jMng/MnzHUfHdcApcuXaKxsZEXX3wRAK/Xy+rVq9m0aRN2u52mpqbAul6vF7vdjt1u59ixY4Fxn8/HxIkTe3x8l8uFy+UK3L7x8b7L6XTecrkZmD2j2fN9y6wZzT5/yhc6s2fsKV9qaupt3/+ODweNGTOG7du3U1ZWRllZGQ6Hg9///vckJyeTmZnJwYMHMQyDEydOEB8fT0pKClOmTOHIkSO0tbXR1tbGkSNHmDJlyp0+tYiIhFmfewIlJSUcO3aM1tZWli1bRm5uLjk5OT2uO3XqVGpra8nPzycuLo68vDwAEhISeOyxx1i7di0ACxcu7PFks4iIRFafJVBQUHDL5WVlZYH/ttlsLFmypMf1cnJyei0PEREZGPrGsIiIhakEREQsTCUgImJhKgEREQtTCYiIWJhKQETEwlQCIiIWphIQEbEwlYCIiIWpBERELEwlICJiYSoBERELUwmIiFiYSkBExMLu+JfFRO5E1y9+NtARROQWtCcgImJhfe4JlJeXU1tbS1JSEkVFRQDs2rWLw4cPExMTw/Dhw8nLy2Pw4MEA7N27l8rKSqKionjmmWcCPyNZX19PRUUFfr+fuXPnMn/+/H7cLBERuR197glkZ2ezbt26bmOTJ0+mqKiIV199le9973vs3bsXgHPnzlFdXc3mzZv51a9+xY4dO/D7/fj9fnbs2MG6desoLi7m448/5ty5c/2zRSIictv6LIGJEyfe9HvADzzwANHR0QBMmDABn88HgMfjYebMmcTGxjJs2DBGjBjBqVOnOHXqFCNGjGD48OHExMQwc+ZMPB5PP2yOiIjciZBPDFdWVjJz5kwAfD4f6enpgWV2uz1QEA6HIzDucDg4efJkj4/ndrtxu90AFBYW4nQ6ew8fE3PL5WZg9oz9ne9SmB7HrHNo9dc3VGbPB+bPGGq+kEpgz549REdHM2vWrFAephuXy4XL5Qrcbmpq6nVdp9N5y+VmYPaMZs/3LbNmNPv8KV/ozJ6xp3ypqam3ff+gS6CqqorDhw+zfv16bDYbcP0vf6/XG1jH5/Nht9sBuo17vd7AuIiIDJygPiJaX1/Pu+++y+rVqxk0aFBgPDMzk+rqajo6OmhsbOTChQuMHz+ecePGceHCBRobG+ns7KS6uprMzMywbYSIiASnzz2BkpISjh07RmtrK8uWLSM3N5e9e/fS2dnJyy+/DEB6ejpLly5l9OjRPPzww6xcuZKoqCieffZZoqKu98zixYvZsGEDfr+fOXPmMHr06P7dMhER6VOfJVBQUHDTWE5OTq/rL1iwgAULFtw0Pm3aNKZNm3aH8UREpD/pG8MiIhamEhARsTCVgIiIhekqonJX6O1qpNF//EuEk4j8b9GegIiIhakEREQsTCUgImJhKgEREQtTCYiIWJhKQETEwlQCIiIWphIQEbEwlYCIiIWpBERELEwlICJiYX1eO6i8vJza2lqSkpIoKioCoK2tjeLiYi5fvszQoUNZsWIFCQkJGIZBRUUFdXV1DBo0iLy8PNLS0oDrP0e5Z88e4PpvDmRnZ/ffVomIyG3pc08gOzubdevWdRvbt28fkyZNorS0lEmTJrFv3z4A6urquHjxIqWlpSxdupTt27cD10tj9+7dbNy4kY0bN7J7927a2tr6YXNERORO9FkCEydOJCEhoduYx+MhKysLgKysLDweDwA1NTXMnj0bm83GhAkTaG9vp7m5mfr6eiZPnkxCQgIJCQlMnjyZ+vr6ftgcERG5E0FdSrqlpYWUlBQAkpOTaWlpAcDn8+F0OgPrORwOfD4fPp8Ph8MRGLfb7fh8vh4f2+1243a7ASgsLOz2eDeFj4m55XIzMHvG/s53qd8e+bqBnlurv76hMns+MH/GUPOF/HsCNpsNm80W6sMEuFwuXC5X4HZTU1Ov6zqdzlsuNwOzZzR7vr4MdHazz5/yhc7sGXvKl5qaetv3D+rTQUlJSTQ3NwPQ3NxMYmIicP0v/BvDeL1e7HY7drsdr9cbGPf5fNjt9mCeWkREwiioEsjMzOTAgQMAHDhwgOnTpwfGDx48iGEYnDhxgvj4eFJSUpgyZQpHjhyhra2NtrY2jhw5wpQpU8K3FSIiEpQ+DweVlJRw7NgxWltbWbZsGbm5ucyfP5/i4mIqKysDHxEFmDp1KrW1teTn5xMXF0deXh4ACQkJPPbYY6xduxaAhQsX3nSyWUREIq/PEigoKOhxfP369TeN2Ww2lixZ0uP6OTk55OTk3GE8ERHpT/qheQmL3n4IXkTMTZeNEBGxMJWAiIiFqQRERCxMJSAiYmEqARERC1MJiIhYmEpARMTCVAIiIhamEhARsTCVgIiIhakEREQsTCUgImJhKgEREQtTCYiIWFhIl5J+//33qaysxGazMXr0aPLy8vjyyy8pKSmhtbWVtLQ0li9fTkxMDB0dHWzdupXPP/+cIUOGUFBQwLBhw8K1HSIiEoSg9wR8Ph8ffPABhYWFFBUV4ff7qa6u5o033mDevHls2bKFwYMHU1lZCUBlZSWDBw9my5YtzJs3jzfffDNsGyEiIsEJ6XCQ3+/n2rVrdHV1ce3aNZKTk2loaGDGjBkAZGdn4/F4AKipqSE7OxuAGTNmcPToUQzDCC29iIiEJOjDQXa7nZ/+9Kc899xzxMXF8cADD5CWlkZ8fDzR0dGBdXw+H3B9z8HhcAAQHR1NfHw8ra2tJCYmdntct9uN2+0GoLCwEKfT2Xv4mJhbLjcDs2cMV75LYcgSjIGeW6u8vv3F7PnA/BlDzRd0CbS1teHxeCgrKyM+Pp7NmzdTX18fdJBvuVwuXC5X4HZTU1Ov6zqdzlsuNwOzZzR7vr4MdHazz5/yhc7sGXvKl5qaetv3D/pw0KeffsqwYcNITEwkJiaGhx56iOPHj3PlyhW6urqA63/92+124PpegdfrBaCrq4srV64wZMiQYJ9eRETCIOgScDqdnDx5km+++QbDMPj0008ZNWoUGRkZHDp0CICqqioyMzMBePDBB6mqqgLg0KFDZGRkYLPZQt8CEREJWtCHg9LT05kxYwarV68mOjqasWPH4nK5mDZtGiUlJbz11lvcd9995OTkAJCTk8PWrVtZvnw5CQkJFBQUhG0jREQkOCF9TyA3N5fc3NxuY8OHD2fTpk03rRsXF8fKlStDeToREQkzfWNYRMTCVAIiIhamEhARsTCVgIiIhakEREQsTCUgImJhKgEREQtTCYiIWJhKQETEwlQCIiIWphIQEbEwlYCIiIWpBERELEwlICJiYSoBERELC+n3BNrb29m2bRtnz57FZrPx3HPPkZqaSnFxMZcvX2bo0KGsWLGChIQEDMOgoqKCuro6Bg0aRF5eHmlpaeHaDhERCUJIewIVFRVMmTKFkpISXnnlFUaOHMm+ffuYNGkSpaWlTJo0iX379gFQV1fHxYsXKS0tZenSpWzfvj0sGyAiIsELugSuXLnCv//978DPR8bExDB48GA8Hg9ZWVkAZGVl4fF4AKipqWH27NnYbDYmTJhAe3s7zc3NYdgEEREJVtCHgxobG0lMTKS8vJwvvviCtLQ0Fi1aREtLCykpKQAkJyfT0tICgM/nw+l0Bu7vcDjw+XyBdb/ldrtxu90AFBYWdrvPTeFjYm653AzMnjFc+S6FIUswBnpurfL69hez5wPzZww1X9Al0NXVxZkzZ1i8eDHp6elUVFQEDv18y2azYbPZ7uhxXS4XLpcrcLupqanXdZ1O5y2Xm4HZM5o9X18GOrvZ50/5Qmf2jD3lS01Nve37B10CDocDh8NBeno6ADNmzGDfvn0kJSXR3NxMSkoKzc3NJCYmAmC327sF9Xq92O32YJ9eBkjXL3420BFEJIyCPieQnJyMw+Hg/PnzAHz66aeMGjWKzMxMDhw4AMCBAweYPn06AJmZmRw8eBDDMDhx4gTx8fE3HQoSEZHICukjoosXL6a0tJTOzk6GDRtGXl4ehmFQXFxMZWVl4COiAFOnTqW2tpb8/Hzi4uLIy8sLywaIiEjwQiqBsWPHUlhYeNP4+vXrbxqz2WwsWbIklKcTEZEw0zeGRUQsTCUgImJhKgEREQtTCYiIWJhKQETEwlQCIiIWphIQEbEwlYCIiIWpBERELEwlICJiYSFdNkJkoN3qqqbRf/xLBJOI3J1UAtIjXTJaxBp0OEhExMJUAiIiFqYSEBGxsJDPCfj9ftasWYPdbmfNmjU0NjZSUlJCa2sraWlpLF++nJiYGDo6Oti6dSuff/45Q4YMoaCggGHDhoVjG0REJEgh7wn89a9/ZeTIkYHbb7zxBvPmzWPLli0MHjyYyspKACorKxk8eDBbtmxh3rx5vPnmm6E+tYiIhCikEvB6vdTW1jJ37lwADMOgoaGBGTNmAJCdnY3H4wGgpqaG7Oxs4PqP0h89ehTDMEJ5ehERCVFIh4N27tzJU089xdWrVwFobW0lPj6e6OhoAOx2Oz6fDwCfz4fD4QAgOjqa+Ph4WltbSUxM7PaYbrcbt9sNQGFhIU6ns/fwMTG3XG4GZs/YW75LA5Al3CIx73fr62sWZs8H5s8Yar6gS+Dw4cMkJSWRlpZGQ0ND0AG+y+Vy4XK5Arebmpp6XdfpdN5yuRmYPaPZ84UiEttl9vlTvtCZPWNP+VJTU2/7/kGXwPHjx6mpqaGuro5r165x9epVdu7cyZUrV+jq6iI6Ohqfz4fdbgeu7xV4vV4cDgddXV1cuXKFIUOGBPv0IiISBkGfE3jiiSfYtm0bZWVlFBQUcP/995Ofn09GRgaHDh0CoKqqiszMTAAefPBBqqqqADh06BAZGRnYbLbQt0BERIIW9u8JPPnkk7z//vssX76ctrY2cnJyAMjJyaGtrY3ly5fz/vvv8+STT4b7qUVE5A6F5dpBGRkZZGRkADB8+HA2bdp00zpxcXGsXLkyHE8nIiJhom8Mi4hYmEpARMTCVAIiIhamEhARsTD9qIzFXfq/mQMdQUQGkPYEREQsTCUgImJhKgEREQtTCYiIWJhKQETEwlQCIiIWphIQEbEwlYCIiIWpBERELEwlICJiYUFfNqKpqYmysjK+/PJLbDYbLpeLRx55hLa2NoqLi7l8+TJDhw5lxYoVJCQkYBgGFRUV1NXVMWjQIPLy8khLSwvntoiIyB0Kek8gOjqap59+muLiYjZs2MD+/fs5d+4c+/btY9KkSZSWljJp0iT27dsHQF1dHRcvXqS0tJSlS5eyffv2sG2EiIgEJ+gSSElJCfwlf++99zJy5Eh8Ph8ej4esrCwAsrKy8Hg8ANTU1DB79mxsNhsTJkygvb2d5ubmMGyCiIgEKyznBBobGzlz5gzjx4+npaWFlJQUAJKTk2lpaQHA5/PhdDoD93E4HPh8vnA8vYiIBCnkS0l//fXXFBUVsWjRIuLj47sts9ls2Gy2O3o8t9uN2+0GoLCwsFtxfFdMTMwtl5uB2TNeGugA/SgS827211f5Qmf2jKHmC6kEOjs7KSoqYtasWTz00EMAJCUl0dzcTEpKCs3NzSQmJgJgt9tpamoK3Nfr9WK32296TJfLhcvlCty+8T7f5XQ6b7ncDMySsesXPxvoCBEXiXk3y+vbG+ULndkz9pQvNTX1tu8f9OEgwzDYtm0bI0eO5NFHHw2MZ2ZmcuDAAQAOHDjA9OnTA+MHDx7EMAxOnDhBfHx84LCRiIgMjKD3BI4fP87BgwcZM2YML774IgCPP/448+fPp7i4mMrKysBHRAGmTp1KbW0t+fn5xMXFkZeXF54tEBGRoAVdAj/4wQ945513ely2fv36m8ZsNhtLliwJ9unkNlnxsI+IBE/fGBYRsTCVgIiIhakEREQsTCUgImJhKgEREQsL+RvDEnn6BJCIhIv2BERELEx7Aiamv/hFpL9pT0BExMJUAiIiFqYSEBGxMJWAiIiF6cSwCegEsIgMFJVABOkfexExG5VAP7jxH/v/5Z9vFJG7n84JiIhYWMT3BOrr66moqMDv9zN37lzmz58f6QgiIvL/RXRPwO/3s2PHDtatW0dxcTEff/wx586di2QEERG5QUT3BE6dOsWIESMYPnw4ADNnzsTj8TBq1KhIxuiVTtxaQ2+vc/Qf/xLhJJFxq/+v7/Ztttpr2R9shmEYkXqyQ4cOUV9fz7JlywA4ePAgJ0+e5Nlnnw2s43a7cbvdABQWFkYqmoiIJZnuxLDL5aKwsPC2CmDNmjURSBQas2dUvtAoX2jMng/MnzHUfBEtAbvdjtfrDdz2er3Y7fZIRhARkRtEtATGjRvHhQsXaGxspLOzk+rqajIzMyMZQUREbhD9m9/85jeRerKoqChGjBjBli1b+PDDD5k1axYzZswI6THT0tLClK7/mD2j8oVG+UJj9nxg/oyh5IvoiWERETEX050YFhGRyFEJiIhY2F17ATkzXn7i+eef55577iEqKoro6GgKCwtpa2ujuLiYy5cvM3ToUFasWEFCQkJE8pSXl1NbW0tSUhJFRUUAveYxDIOKigrq6uoYNGgQeXl5ETkO2lPGd955h7///e8kJiYC8PjjjzNt2jQA9u7dS2VlJVFRUTzzzDNMmTKl37I1NTVRVlbGl19+ic1mw+Vy8cgjj5hmDnvLZ5b5A7h27Rq//vWv6ezspKurixkzZpCbm0tjYyMlJSW0traSlpbG8uXLiYmJoaOjg61bt/L5558zZMgQCgoKGDZsWMTzlZWVcezYMeLj44Hr7+2xY8cO2PvE7/ezZs0a7HY7a9asCe/8GXehrq4u44UXXjAuXrxodHR0GKtWrTLOnj070LGMvLw8o6WlpdvYrl27jL179xqGYRh79+41du3aFbE8DQ0NxunTp42VK1f2mefw4cPGhg0bDL/fbxw/ftxYu3btgGV8++23jXffffemdc+ePWusWrXKuHbtmnHp0iXjhRdeMLq6uvotm8/nM06fPm0YhmFcuXLFyM/PN86ePWuaOewtn1nmzzAMw+/3G1evXjUMwzA6OjqMtWvXGsePHzeKioqMjz76yDAMw3jttdeM/fv3G4ZhGB9++KHx2muvGYZhGB999JGxefPmAcm3detW45///OdN6w/U++S9994zSkpKjE2bNhmGYYR1/u7Kw0E3Xn4iJiYmcPkJM/J4PGRlZQGQlZUV0ZwTJ068aa+jtzw1NTXMnj0bm83GhAkTaG9vp7m5eUAy9sbj8TBz5kxiY2MZNmwYI0aM4NSpU/2WLSUlJfBX3r333svIkSPx+XymmcPe8vUm0vMHYLPZuOeeewDo6uqiq6sLm81GQ0ND4JOB2dnZ3eYwOzsbgBkzZnD06FGMfvzsSm/5ejMQ7xOv10ttbS1z584FwDCMsM7fXVkCPp8Ph8MRuO1wOG75P38kbdiwgdWrVwcufdHS0kJKSgoAycnJtLS0DGS8XvP4fD6cTmdgvYGe0/3797Nq1SrKy8tpa2sDbn7d7XZ7xDI2NjZy5swZxo8fb8o5vDEfmGv+/H4/L774IkuWLGHSpEkMHz6c+Ph4oqOjb8pxY8bo6Gji4+NpbW2NaL709HQA/vznP7Nq1Sp27txJR0dHIF+kX+OdO3fy1FNPBcqptbU1rPN3154TMKOXX34Zu91OS0sLv/vd70hNTe223Gaz3fKvjEgzW55v/fjHP2bhwoUAvP322/zpT38iLy9vwPJ8/fXXFBUVsWjRosAx4m+ZYQ6/m89s8xcVFcUrr7xCe3s7r776KufPnx+wLD35br7//ve/PPHEEyQnJ9PZ2clrr73Gu+++G5jTSDp8+DBJSUmkpaXR0NDQL89xV+4JmPXyE99mSEpKYvr06Zw6dYqkpKTA7mJzc3PgZN1A6S2P3W6nqakpsN5AzmlycjJRUVFERUUxd+5cTp8+Hch44+vu8/n6PWNnZydFRUXMmjWLhx56CDDXHPaUz0zzd6PBgweTkZHBiRMnuHLlCl1dXTfluDFjV1cXV65cYciQIRHNV19fT0pKCjabjdjYWObMmRM4bBbp1/j48ePU1NTw/PPPU1JSwtGjR9m5c2dY5++uLAEzXn7i66+/5urVq4H//uSTTxgzZgyZmZkcOHAAgAMHDjB9+vSBjNlrnszMTA4ePIhhGJw4cYL4+PjAIY9Iu/EY67/+9S9Gjx4dyFhdXU1HRweNjY1cuHAhcPijPxiGwbZt2xg5ciSPPvpoYNwsc9hbPrPMH8BXX31Fe3s7cP2TOJ988gkjR44kIyODQ4cOAVBVVRV4/z744INUVVUB1686nJGR0a97Wr3l+3YODcPA4/F0m8NIvsZPPPEE27Zto6ysjIKCAu6//37y8/PDOn937TeGa2tref311/H7/cyZM4cFCxYMaJ5Lly7x6quvAtcb+Ec/+hELFiygtbWV4uJimpqaIv4R0ZKSEo4dO0ZraytJSUnk5uYyffr0HvMYhsGOHTs4cuQIcXFx5OXlMW7cuAHJ2NDQwH/+8x9sNhtDhw5l6dKlgTfanj17+Mc//kFUVBSLFi1i6tSp/Zbts88+Y/369YwZMybwRnr88cdJT083xRz2lu/jjz82xfwBfPHFF5SVleH3+zEMg4cffpiFCxdy6dIlSkpKaGtr47777mP58uXExsZy7do1tm7dypkzZ0hISKCgoCDw+yORzPfb3/6Wr776CoDvf//7LF26lHvuuWfA3icADQ0NvPfee6xZsyas83fXloCIiITurjwcJCIi4aESEBGxMJWAiIiFqQRERCxMJSAiYmEqARERC1MJiIhY2P8Dl50A9MDa97QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.8 s, sys: 138 ms, total: 1.93 s\n",
            "Wall time: 1.93 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "QGG9Ugo_SLzR",
        "colab_type": "text"
      },
      "source": [
        "create featuretfransformer like in https://www.depends-on-the-definition.com/introduction-named-entity-recognition-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls0zsDyVFtXV",
        "colab_type": "text"
      },
      "source": [
        "Feature engineering – 2 (1+1) \n",
        "* add quotes before and after as features  \n",
        " \n",
        "grammatical words = closed set (~ stop words)  \n",
        "Stemming + POS  \n",
        "Word shape  \n",
        "Ad hoc features ( +1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "n6vL4H0uSLzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:], #replace with BPE\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def get_sent_labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "DEWQp8ecSLzU",
        "colab_type": "code",
        "outputId": "1784977a-cd23-4f01-f8b1-df147ec3c964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "X = [sent2features(s) for s in word_pos_tag_sentences]\n",
        "y = [get_sent_labels(s) for s in word_pos_tag_sentences]\n",
        "\n",
        "#make a split while the data is still sequential\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=False, random_state=42)\n",
        "\n",
        "def get_flatten_and_lengths(X, y):\n",
        "    lengths = [len(x) for x in X]\n",
        "    flatten_X = [item for sublist in X for item in sublist]\n",
        "    flatten_y = [item for sublist in y for item in sublist]\n",
        "    assert len(flatten_X) == np.array(lengths).sum()\n",
        "    return flatten_X, flatten_y, lengths\n",
        "X_train_flatten, y_train_flatten, lengths_train = get_flatten_and_lengths(X_train, y_train)\n",
        "X_test_flatten, y_test_flatten, lengths_test = get_flatten_and_lengths(X_test, y_test)\n",
        "\n",
        "# check values for both: train and test\n",
        "voa_train_test = pd.concat([pd.Series(y_train_flatten).value_counts().rename('bio_tag_train'), \n",
        "                            pd.Series(y_test_flatten).value_counts().rename('bio_tag_test')], \n",
        "                            axis=1)\n",
        "voa_train_test.sort_values(by='bio_tag_train', ascending=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.43 s, sys: 764 ms, total: 4.19 s\n",
            "Wall time: 4.19 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4iDcFD5SLzi",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz-7GAisF3pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(y):\n",
        "    return list(chain.from_iterable(y))\n",
        "\n",
        "def _flattens_y(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(y_true, y_pred, *args, **kwargs):\n",
        "        y_true_flat = flatten(y_true)\n",
        "        y_pred_flat = flatten(y_pred)\n",
        "        return func(y_true_flat, y_pred_flat, *args, **kwargs)\n",
        "    return wrapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPpcblmfSLzn",
        "colab_type": "code",
        "outputId": "a10b9eae-7156-4479-a81a-9cc8da0add12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "def f1_macro(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "def fbeta_macro(y_true, y_pred, beta=2):\n",
        "    return fbeta_score(y_true, y_pred, average='macro', beta=beta)\n",
        "\n",
        "scoring = [bio_f_score, f1_macro, fbeta_macro]\n",
        "cv = KFold(n_splits=5, shuffle=False, random_state=42)\n",
        "sequence_cv = SequenceKFold(lengths_train, n_folds=5, n_iter=1, shuffle=False, random_state=42, yield_lengths=True)\n",
        "\n",
        "def evaluate_bio_clf_report(y_test, y_pred, labels, remove_O=True,\n",
        "                            do_flatten=False):\n",
        "    if remove_O:\n",
        "        labels.remove('O') # remove 'O' label from evaluation\n",
        "    sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
        "    if do_flatten:\n",
        "        report = flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3)\n",
        "    else:\n",
        "        report = classification_report(y_test, y_pred, labels=sorted_labels, digits=3)\n",
        "    return report\n",
        "\n",
        "def evaluate_entity_clf_report(y_test, y_pred, lengths_test):\n",
        "    \n",
        "    if len(y_pred) != len(y_test):\n",
        "        logging.info(\"lengths of y_pred and y_test are not equal. trying to unflat predictions via lengths\")\n",
        "        assert sum(lengths_test) == len(y_pred)\n",
        "        \n",
        "        y_pred_copy = deepcopy(y_pred)\n",
        "        y_pred_unflatten = []\n",
        "        for length in lengths_test:\n",
        "            y_pred_unflatten.append(y_pred_copy[:length].tolist())\n",
        "            y_pred_copy = np.delete(y_pred_copy, range(length))\n",
        "    else:\n",
        "        y_pred_unflatten = y_pred\n",
        "        \n",
        "    return entity_classification_report(y_test, y_pred_unflatten)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLB6GHZZWNx-",
        "colab_type": "text"
      },
      "source": [
        "todo: add classification report on entities and bio_tag levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n8APgvUyskaf"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEOKnlyZSLzs",
        "colab_type": "text"
      },
      "source": [
        "## HMM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFMRezuzaZPC",
        "colab_type": "text"
      },
      "source": [
        "###Supervised\n",
        "Given an observation sequence and the associated hidden states (real tags) we can learn the HMM parameters, that is, the matrices A and B.\n",
        "\n",
        "In a HHM supervised scenario this is done by applying the Maximum Likelihood Estimation principle, which will compute the matrices.\n",
        "\n",
        "This is achieved by counting how many times each event occurs in the corpus and normalizing the counts to form proper probability distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dNNFC2v_SL0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline([('vectorizer', DictVectorizer(sparse=True)),\n",
        "                 ('seq_clf', seqlearn_MHMM())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTw2uVfgO8u3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_seq_cross_validate(estimator, X, y, cv, scoring):\n",
        "    scores = dict((metric.__name__, []) for metric in scoring)\n",
        "    for train, lengths_train, test, lengths_test in tqdm(list(cv), total=len(list(cv))):\n",
        "        estimator_copy = deepcopy(estimator)\n",
        "        model_name = estimator_copy.steps[-1][0]\n",
        "        estimator_copy.fit(X[train], y[train], **{model_name+'__lengths': lengths_train})\n",
        "        pred = estimator_copy.predict(X[test], **{'lengths': lengths_test})\n",
        "        for metric in scoring:\n",
        "            scores[metric.__name__].append(metric(y_true=y[test], y_pred=pred))\n",
        "    \n",
        "    scores_df = pd.DataFrame.from_dict(scores)\n",
        "    scores_df.loc['mean'] = scores_df.mean()\n",
        "    return scores_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjOJdoBeY5O3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grid_seq_cross_validate(parameter_dict, pipe, **kwargs):\n",
        "    scores_dict = dict()\n",
        "    grid_params_list = list(ParameterGrid(parameter_dict))\n",
        "    for param_set in tqdm(grid_params_list, total=len(grid_params_list)):\n",
        "        pipe_copy = deepcopy(pipe)\n",
        "        # assuming that last step of pipeline is model\n",
        "        pipe_copy[-1].__dict__.update(param_set)\n",
        "        scores = my_seq_cross_validate(pipe_copy, **kwargs)\n",
        "        scores_dict[str(pipe_copy[-1])] = scores\n",
        "    return scores_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_7p4Jxheuw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameter_dict = {\n",
        "    #Given a trained HMM i.e., the transition matrixes A and B, and a new observation sequence W=w1,w2,…,wN we want to find the sequence of states T=t1,t2,…,tN that best explains it.\n",
        "    #This is can be achieved by using the Viterbi algorithm, that finds the best state assignment to the sequence T1…TN as a whole. \n",
        "    #There is another algorithm, Posterior Decoding (best-first) which consists in picking the highest state posterior for each position i in the sequence independently.\n",
        "    'decode':['viterbi', 'bestfirst'], \n",
        "    'alpha':[0.001, 0.01, 0.1, 1.0]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q4P4gNxf51n",
        "colab_type": "code",
        "outputId": "9c9dde7e-5f51-49ed-f8dd-e3347ebf3091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            "a4a84f1c06b34227b75d128a51a82d2f",
            "95fb0b243e234e989e5f166489e3bc88",
            "fccf7ed036694d76b071e11d1179a492",
            "d092bae32bdb48389c8b9c25df13d1a1",
            "5b6eab54021140d69405a6deedac5f9b",
            "0b8c015059d540a7b0780e7d78bb18c0",
            "1eff841162c54139bfaf5ba8aedd08f2",
            "40617a7d172a4536be5451cb810adafa",
            "f45ce16602f54f3ba34d3e95afbca514",
            "023bd140826c4d7daa3576bd1a691033",
            "26e43c5b2e874934b0c7c4494a71494c",
            "856486a7bef543e894694d65b869b1da",
            "a30bf3cfb5534b84932bb22b491d131f",
            "7a65114dca834a2bb32e23cac42cc27d",
            "1ba9e31825084b01be3c246ce85d674f",
            "94ef18e73685457a99107a8f35a691fa",
            "f656a91824324958a7ca8f8a22eb36fc",
            "03534413eeed48ea8e359ca1695a644f",
            "f3127767d1df49b5b2ba9bb345c9fa23",
            "9f608d24e8984e7d928787c01e8bcd63",
            "f357ac82ef704829ac8a6308bd8c4b0f",
            "fcbf26ca360b49a5849428b4f82ea9cf",
            "19b8e6d8d4ce478582ac51f569dc414e",
            "93c1e2c856004760910461e1c1eaa81f",
            "0c762f72c0d74610971f14419eb1f77d",
            "2e25ec04478248e89547194e43865bbb",
            "258a1f291fde4a40829cb581e10da680",
            "82c5f91a9d10441ba2ae035eb9de2936",
            "e9ec6e1dcb984412bfb75bc16850cadf",
            "da7bf79f5d4a49299f0d0c9970a62e9b",
            "3f247b1d89fc457eb87ec1a18eb30be4",
            "ca79a346472743068eb779252473c487",
            "3ef95639863848f586957fa4823e5da6",
            "941e276d3b124f8e8f6d6451edd9f4d9",
            "09e6562e30ff41a58c2dcd06089b1529",
            "4c6fbe7617844969a03f099c6cf329f3",
            "c3a33c390c5a4581bac946a16fa1eb9e",
            "415762ee983b44bdba02e9c3f62f59fa",
            "4b50024e4380498693d9c73e1ed61010",
            "1f1fdfe150cf49d38178680dd1428ec4",
            "fd85ee4310054709aa8c856a2e53419d",
            "a9bdacedde394392a26acc7aff38792e",
            "5bc090a8379b4cd6b97132dbceb1f09e",
            "7340797a41284319b19537f7fd03f5f5",
            "b071173e66bf4adcb618d0bd6a2a1413",
            "506f8fbe830b40b787b2a192ac7e1343",
            "93c9a83ceb654e00bb90981a8f0c1f5e",
            "d15bd90075f741138938b5aaa54319a2",
            "2ffde3a620b04824a654d45a691a79ac",
            "7e6b3b99f72d4a37af3779a308a7a04c",
            "9d0c85b3844847129b622807d516f3f0",
            "00b9587b903e41cb84180009bd409df9",
            "1a52761a5d5e4fac98121e01fb376fd5",
            "510186523d2544f6a2aff4376e2387e3",
            "92609aa187a9427493e2afe938f0c528",
            "a7a5845caf60444389c56007f48631b9",
            "bf55f18efc6748cb8a0b954fc02a3fd5",
            "d8f241b5c3d74f4da440208e8c21b066",
            "c5520c24070a409e899d40bab89eb22f",
            "810f5040b3c348cd8b0c3e34dccb7895",
            "551d39b97c96417d818b3cf2615e7777",
            "eaf12f3480934de994f71a09006ccb2f",
            "d94082cab95d4868a4236f81e429d44b",
            "db4359d585bc4157b3beea372b160458",
            "acbbe65d0025430d901ebc72ff226a4c",
            "1522f8813be74dd1a4c9a7f814f80f00",
            "730c83053c964a80b8bbe6e0a17a1078",
            "eb07ca7501504304ba77f3562ba1e786",
            "507719b20a9d4132bed5a478413ff1f5",
            "ee87667c7eeb4b449bc8f73c3922f166",
            "23036e6b27d546bc8a262b6228dcb35c",
            "bd184f0c8f7c44da85298b9c2ca47a19"
          ]
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "scores_dict = grid_seq_cross_validate(parameter_dict, \n",
        "                                      pipe, \n",
        "                                      X=np.array(X_train_flatten),\n",
        "                                      y=np.array(y_train_flatten),\n",
        "                                      cv=sequence_cv,\n",
        "                                      scoring=scoring)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4a84f1c06b34227b75d128a51a82d2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f45ce16602f54f3ba34d3e95afbca514",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f656a91824324958a7ca8f8a22eb36fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c762f72c0d74610971f14419eb1f77d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ef95639863848f586957fa4823e5da6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd85ee4310054709aa8c856a2e53419d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ffde3a620b04824a654d45a691a79ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf55f18efc6748cb8a0b954fc02a3fd5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acbbe65d0025430d901ebc72ff226a4c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "CPU times: user 2min 26s, sys: 1.59 s, total: 2min 28s\n",
            "Wall time: 2min 28s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTVgWv3juGMF",
        "colab_type": "code",
        "outputId": "a6b6a291-85f7-45ad-e97c-d928081dd9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "scores_df = pd.concat(scores_dict.values(), keys=scores_dict.keys(), axis=1)\n",
        "scores_df.T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.001, decode='viterbi')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.602240</td>\n",
              "      <td>0.592532</td>\n",
              "      <td>0.598458</td>\n",
              "      <td>0.600242</td>\n",
              "      <td>0.615618</td>\n",
              "      <td>0.601818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.286838</td>\n",
              "      <td>0.283691</td>\n",
              "      <td>0.286242</td>\n",
              "      <td>0.288546</td>\n",
              "      <td>0.291031</td>\n",
              "      <td>0.287269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.258712</td>\n",
              "      <td>0.254595</td>\n",
              "      <td>0.256610</td>\n",
              "      <td>0.258267</td>\n",
              "      <td>0.264240</td>\n",
              "      <td>0.258485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.001, decode='bestfirst')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.675595</td>\n",
              "      <td>0.662932</td>\n",
              "      <td>0.678801</td>\n",
              "      <td>0.679100</td>\n",
              "      <td>0.676098</td>\n",
              "      <td>0.674505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.402382</td>\n",
              "      <td>0.369598</td>\n",
              "      <td>0.364784</td>\n",
              "      <td>0.394159</td>\n",
              "      <td>0.383193</td>\n",
              "      <td>0.382823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.358670</td>\n",
              "      <td>0.330615</td>\n",
              "      <td>0.327697</td>\n",
              "      <td>0.352449</td>\n",
              "      <td>0.342234</td>\n",
              "      <td>0.342333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.01, decode='viterbi')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.569115</td>\n",
              "      <td>0.560307</td>\n",
              "      <td>0.564312</td>\n",
              "      <td>0.572064</td>\n",
              "      <td>0.584976</td>\n",
              "      <td>0.570155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.262675</td>\n",
              "      <td>0.260466</td>\n",
              "      <td>0.262267</td>\n",
              "      <td>0.263444</td>\n",
              "      <td>0.267787</td>\n",
              "      <td>0.263328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.233159</td>\n",
              "      <td>0.229876</td>\n",
              "      <td>0.231222</td>\n",
              "      <td>0.232294</td>\n",
              "      <td>0.238680</td>\n",
              "      <td>0.233046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.01, decode='bestfirst')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.675015</td>\n",
              "      <td>0.662304</td>\n",
              "      <td>0.679298</td>\n",
              "      <td>0.679219</td>\n",
              "      <td>0.675771</td>\n",
              "      <td>0.674321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.379256</td>\n",
              "      <td>0.335258</td>\n",
              "      <td>0.357550</td>\n",
              "      <td>0.376763</td>\n",
              "      <td>0.365923</td>\n",
              "      <td>0.362950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.340797</td>\n",
              "      <td>0.305155</td>\n",
              "      <td>0.322880</td>\n",
              "      <td>0.339774</td>\n",
              "      <td>0.329308</td>\n",
              "      <td>0.327583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.1, decode='viterbi')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.458375</td>\n",
              "      <td>0.450819</td>\n",
              "      <td>0.455397</td>\n",
              "      <td>0.462918</td>\n",
              "      <td>0.467546</td>\n",
              "      <td>0.459011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.202655</td>\n",
              "      <td>0.196163</td>\n",
              "      <td>0.198286</td>\n",
              "      <td>0.201613</td>\n",
              "      <td>0.206395</td>\n",
              "      <td>0.201022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.173546</td>\n",
              "      <td>0.168147</td>\n",
              "      <td>0.169579</td>\n",
              "      <td>0.172336</td>\n",
              "      <td>0.176715</td>\n",
              "      <td>0.172065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=0.1, decode='bestfirst')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.663210</td>\n",
              "      <td>0.653199</td>\n",
              "      <td>0.667042</td>\n",
              "      <td>0.667492</td>\n",
              "      <td>0.665416</td>\n",
              "      <td>0.663272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.333049</td>\n",
              "      <td>0.317296</td>\n",
              "      <td>0.321897</td>\n",
              "      <td>0.351280</td>\n",
              "      <td>0.339980</td>\n",
              "      <td>0.332700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.298961</td>\n",
              "      <td>0.285813</td>\n",
              "      <td>0.290552</td>\n",
              "      <td>0.312855</td>\n",
              "      <td>0.303870</td>\n",
              "      <td>0.298410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=1.0, decode='viterbi')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.161203</td>\n",
              "      <td>0.158475</td>\n",
              "      <td>0.154462</td>\n",
              "      <td>0.174607</td>\n",
              "      <td>0.153814</td>\n",
              "      <td>0.160512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.090295</td>\n",
              "      <td>0.088205</td>\n",
              "      <td>0.085900</td>\n",
              "      <td>0.090717</td>\n",
              "      <td>0.088769</td>\n",
              "      <td>0.088777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.082487</td>\n",
              "      <td>0.081023</td>\n",
              "      <td>0.079363</td>\n",
              "      <td>0.083036</td>\n",
              "      <td>0.081287</td>\n",
              "      <td>0.081439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">MultinomialHMM(alpha=1.0, decode='bestfirst')</th>\n",
              "      <th>bio_f_score</th>\n",
              "      <td>0.599918</td>\n",
              "      <td>0.589508</td>\n",
              "      <td>0.605466</td>\n",
              "      <td>0.605281</td>\n",
              "      <td>0.607337</td>\n",
              "      <td>0.601502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_macro</th>\n",
              "      <td>0.280395</td>\n",
              "      <td>0.273444</td>\n",
              "      <td>0.281261</td>\n",
              "      <td>0.284272</td>\n",
              "      <td>0.280005</td>\n",
              "      <td>0.279875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbeta_macro</th>\n",
              "      <td>0.244576</td>\n",
              "      <td>0.237947</td>\n",
              "      <td>0.246202</td>\n",
              "      <td>0.247634</td>\n",
              "      <td>0.245019</td>\n",
              "      <td>0.244275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                    0  ...      mean\n",
              "MultinomialHMM(alpha=0.001, decode='viterbi')   bio_f_score  0.602240  ...  0.601818\n",
              "                                                f1_macro     0.286838  ...  0.287269\n",
              "                                                fbeta_macro  0.258712  ...  0.258485\n",
              "MultinomialHMM(alpha=0.001, decode='bestfirst') bio_f_score  0.675595  ...  0.674505\n",
              "                                                f1_macro     0.402382  ...  0.382823\n",
              "                                                fbeta_macro  0.358670  ...  0.342333\n",
              "MultinomialHMM(alpha=0.01, decode='viterbi')    bio_f_score  0.569115  ...  0.570155\n",
              "                                                f1_macro     0.262675  ...  0.263328\n",
              "                                                fbeta_macro  0.233159  ...  0.233046\n",
              "MultinomialHMM(alpha=0.01, decode='bestfirst')  bio_f_score  0.675015  ...  0.674321\n",
              "                                                f1_macro     0.379256  ...  0.362950\n",
              "                                                fbeta_macro  0.340797  ...  0.327583\n",
              "MultinomialHMM(alpha=0.1, decode='viterbi')     bio_f_score  0.458375  ...  0.459011\n",
              "                                                f1_macro     0.202655  ...  0.201022\n",
              "                                                fbeta_macro  0.173546  ...  0.172065\n",
              "MultinomialHMM(alpha=0.1, decode='bestfirst')   bio_f_score  0.663210  ...  0.663272\n",
              "                                                f1_macro     0.333049  ...  0.332700\n",
              "                                                fbeta_macro  0.298961  ...  0.298410\n",
              "MultinomialHMM(alpha=1.0, decode='viterbi')     bio_f_score  0.161203  ...  0.160512\n",
              "                                                f1_macro     0.090295  ...  0.088777\n",
              "                                                fbeta_macro  0.082487  ...  0.081439\n",
              "MultinomialHMM(alpha=1.0, decode='bestfirst')   bio_f_score  0.599918  ...  0.601502\n",
              "                                                f1_macro     0.280395  ...  0.279875\n",
              "                                                fbeta_macro  0.244576  ...  0.244275\n",
              "\n",
              "[24 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD69jlYw43Jy",
        "colab_type": "text"
      },
      "source": [
        "Less alpha show better result. Ceteris paribus, bestfirst performs better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcZxLpOauX0F",
        "colab_type": "code",
        "outputId": "67dd430b-fdfe-443f-a981-6b670d4a20e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "%%time\n",
        "pipe = Pipeline([('vectorizer', DictVectorizer(sparse=True)),\n",
        "                 ('seq_clf', seqlearn_MHMM(alpha=0.001, decode='bestfirst'))])\n",
        "pipe.fit(X_train_flatten, y_train_flatten, **{'seq_clf__lengths': lengths_train})\n",
        "y_pred_flatten = pipe.predict(X_test_flatten, **{'lengths': lengths_test})\n",
        "print(y_pred_flatten[:15], '\\n', y_test_flatten[:15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'] \n",
            " ['O', 'B-org', 'O', 'B-per', 'I-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O']\n",
            "CPU times: user 4.14 s, sys: 25.8 ms, total: 4.16 s\n",
            "Wall time: 4.17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EzSsxeXYmY",
        "colab_type": "code",
        "outputId": "38b0f9e6-0712-4cd1-f678-1a2b6c523af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.unique(y_pred_flatten)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r41neoOIXcGg",
        "colab_type": "code",
        "outputId": "870a3c2e-92c1-435b-81b0-8f0ffa8fa169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "np.unique(y_test_flatten)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per',\n",
              "       'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org',\n",
              "       'I-per', 'I-tim', 'O'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8TSTKM0TJZ6",
        "colab_type": "code",
        "outputId": "05a6f05b-95f7-413f-f5fb-687713263c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bio_f_score(y_test_flatten, y_pred_flatten)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pkkTUSolvS2",
        "colab_type": "code",
        "outputId": "ddd0e9cc-d0c6-4085-cfc7-1ae51e91e9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bio_clf_report = evaluate_bio_clf_report(y_test_flatten, y_pred_flatten, \n",
        "                                         labels=list(estimator.classes_),\n",
        "                                         do_flatten=False)\n",
        "entity_clf_report = evaluate_entity_clf_report(y_test, y_pred_flatten, lengths_test)\n",
        "print('*****BIO-tag LEVEL*****\\n', bio_clf_report, '\\n*****ENTITY LEVEL*****\\n', entity_clf_report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*****BIO-tag LEVEL*****\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       B-art      0.000     0.000     0.000        72\n",
            "       I-art      0.000     0.000     0.000        54\n",
            "       B-eve      0.800     0.218     0.343        55\n",
            "       I-eve      0.000     0.000     0.000        41\n",
            "       B-geo      0.763     0.793     0.778      9387\n",
            "       I-geo      0.771     0.319     0.451      1744\n",
            "       B-gpe      0.979     0.816     0.890      3843\n",
            "       I-gpe      1.000     0.306     0.468        36\n",
            "       B-nat      0.625     0.167     0.263        30\n",
            "       I-nat      0.000     0.000     0.000         8\n",
            "       B-org      0.788     0.257     0.388      4999\n",
            "       I-org      0.468     0.020     0.039      4274\n",
            "       B-per      0.694     0.514     0.591      4291\n",
            "       I-per      0.873     0.544     0.670      4343\n",
            "       B-tim      0.913     0.678     0.778      4691\n",
            "       I-tim      0.991     0.081     0.150      1415\n",
            "\n",
            "   micro avg      0.816     0.519     0.635     39283\n",
            "   macro avg      0.604     0.295     0.363     39283\n",
            "weighted avg      0.783     0.519     0.585     39283\n",
            " \n",
            "*****ENTITY LEVEL*****\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "      geo       0.75      0.78      0.76      9387\n",
            "      tim       0.82      0.61      0.70      4691\n",
            "      org       0.72      0.24      0.35      4999\n",
            "      per       0.62      0.46      0.53      4291\n",
            "      gpe       0.98      0.81      0.89      3843\n",
            "      art       0.00      0.00      0.00        72\n",
            "      eve       0.80      0.22      0.34        55\n",
            "      nat       0.62      0.17      0.26        30\n",
            "\n",
            "micro avg       0.77      0.60      0.68     27368\n",
            "macro avg       0.77      0.60      0.65     27368\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--xswwSlfIJf",
        "colab_type": "text"
      },
      "source": [
        "###Handmade\n",
        "The most trivial model = supervised HMM:\n",
        "Take hmmlearn (former sklearn), modify MultinomialHMM (I.e. inherit a new class from _BaseHMM making it a modified copy of the latter) to allow for supervised HMM training. The states of the HMM model = the NE tags.  \n",
        "NOTE: may use NaiveBayes to learn emission probabilities in a supervized manner.\n",
        "Or implement from scratch (with Viterbi for prediction).  \n",
        "NOTE: use tuples of features for X (not just the word, but additional info).  \n",
        "NOTE: use smoothing for state transitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqh6q_GJfKN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hmmlearn.base import _BaseHMM\n",
        "import scipy.sparse as sp\n",
        "from scipy.special import logsumexp\n",
        "from sklearn.utils.extmath import safe_sparse_dot\n",
        "from sklearn.utils import check_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WePak4nrfYgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def array2d(X, dtype=None, order=None, copy=False):\n",
        "    \"\"\"Returns at least 2-d array with data from X\"\"\"\n",
        "    if sp.issparse(X):\n",
        "        raise TypeError('A sparse matrix was passed, but dense data '\n",
        "                        'is required. Use X.toarray() to convert to dense.')\n",
        "    X_2d = np.asarray(np.atleast_2d(X), dtype=dtype, order=order)\n",
        "    if X is X_2d and copy:\n",
        "        X_2d = safe_copy(X_2d)\n",
        "    return X_2d\n",
        "\n",
        "\n",
        "def _atleast2d_or_sparse(X, dtype, order, copy, sparse_class, convmethod,\n",
        "                         check_same_type):\n",
        "    if sp.issparse(X):\n",
        "        logging.info('X is sparse. Convert to csr if needed')\n",
        "        if check_same_type(X) and X.dtype == dtype:\n",
        "            X = getattr(X, convmethod)(copy=copy)\n",
        "        elif dtype is None or X.dtype == dtype:\n",
        "            X = getattr(X, convmethod)()\n",
        "        else:\n",
        "            X = sparse_class(X, dtype=dtype)\n",
        "        X.data = np.array(X.data, copy=False, order=order)\n",
        "    else:\n",
        "        logging.info('Converting X to array2d')\n",
        "        X = array2d(X, dtype=dtype, order=order, copy=copy)\n",
        "    return X\n",
        "\n",
        "\n",
        "def atleast2d_or_csr(X, dtype=None, order=None, copy=False):\n",
        "    \"\"\"Like numpy.atleast_2d, but converts sparse matrices to CSR format\n",
        "    Also, converts np.matrix to np.ndarray.\n",
        "    \"\"\"\n",
        "    return _atleast2d_or_sparse(X, dtype, order, copy, sp.csr_matrix,\n",
        "                                \"tocsr\", sp.isspmatrix_csr)\n",
        "\n",
        "\n",
        "def count_trans(y, n_classes):\n",
        "    \"\"\"Count transitions in a target vector.\n",
        "    Parameters\n",
        "    ----------\n",
        "    y : array of integers, shape = n_samples\n",
        "    n_classes : int\n",
        "        Number of distinct labels.\n",
        "    \"\"\"\n",
        "    trans = np.zeros((n_classes, n_classes), \n",
        "                     #dtype=np.intp\n",
        "                     )\n",
        "\n",
        "    for i in range(y.shape[0] - 1):\n",
        "        trans[y[i], y[i + 1]] += 1\n",
        "    return trans\n",
        "\n",
        "\n",
        "def iter_from_X_lengths(X, lengths):\n",
        "    if lengths is None:\n",
        "        yield 0, len(X)\n",
        "    else:\n",
        "        n_samples = X.shape[0]\n",
        "        end = np.cumsum(lengths).astype(np.int32)\n",
        "        start = end - lengths\n",
        "        if end[-1] > n_samples:\n",
        "            raise ValueError(\"more than {:d} samples in lengths array {!s}\"\n",
        "                             .format(n_samples, lengths))\n",
        "\n",
        "        for i in range(len(lengths)):\n",
        "            yield start[i], end[i]\n",
        "\n",
        "\n",
        "class my_hmm(hmmlearn_MHMM):\n",
        "    def __init__(self, algorithm=\"viterbi\", alpha=.01, **kwargs):\n",
        "        self.alpha = alpha\n",
        "        self.algorithm = algorithm\n",
        "        hmmlearn_MHMM.__init__(self, **kwargs)\n",
        "\n",
        "    def fit_supervised(self, X, y, lengths):\n",
        "        \"\"\"Fit HMM model to data by applying the Maximum Likelihood Estimation \n",
        "        principle, which will compute the matrices. This is achieved by counting \n",
        "        how many times each event occurs in the corpus and normalizing the \n",
        "        counts to form proper probability distributions.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        y : array-like, shape (n_samples,)\n",
        "            Target labels.\n",
        "        lengths : array-like of integers, shape (n_sequences,)\n",
        "            Lengths of the individual sequences in X, y. The sum of these\n",
        "            should be n_samples.\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.alpha\n",
        "        if alpha <= 0:\n",
        "            raise ValueError(\"alpha should be >0, got {0!r}\".format(alpha))\n",
        "\n",
        "        X = atleast2d_or_csr(X)\n",
        "        self.n_visible = X.shape[1]\n",
        "        classes, y_indices = np.unique(y, return_inverse=True)\n",
        "        self.n_hidden = len(classes)\n",
        "        self.classes = classes\n",
        "        lengths = np.asarray(lengths)\n",
        "        # to list of one-hot vectors shape of (n_samples, unique_labels)\n",
        "        Y = y_indices.reshape(-1, 1) == np.arange(len(classes))\n",
        "        #return X, Y\n",
        "\n",
        "        end_indices = np.cumsum(lengths)\n",
        "        start_indices = end_indices - lengths\n",
        "        end_indices -= 1\n",
        "\n",
        "        # how much times each tag was at the beginning of the sequence\n",
        "        log_init_prob = np.log(Y[start_indices].sum(axis=0) + alpha)\n",
        "        # softmax, smoothing here is also taken into account \n",
        "        # (alpha taken the number of times equal number of classes)\n",
        "        normalized_log_init_prob = log_init_prob - logsumexp(log_init_prob)\n",
        "        init_prob = np.exp(normalized_log_init_prob)\n",
        "        \n",
        "        # how many times each tag was at the end of the sequence\n",
        "        log_final_prob = np.log(Y[end_indices].sum(axis=0) + alpha)\n",
        "        normalized_log_final_prob = log_final_prob - logsumexp(log_final_prob)\n",
        "        final_prob = np.exp(normalized_log_final_prob)\n",
        "\n",
        "        # how many times each feature occured with each tag\n",
        "        log_emission_prob = np.log(safe_sparse_dot(Y.T, X) + alpha)\n",
        "        normalized_log_emission_prob = log_emission_prob - logsumexp(log_emission_prob, axis=1)[:, np.newaxis]\n",
        "        emission_prob = np.exp(normalized_log_emission_prob)\n",
        "\n",
        "        log_trans_prob = np.log(count_trans(y_indices, len(classes)) + alpha)\n",
        "        normalized_log_trans_prob = log_trans_prob - logsumexp(log_trans_prob, axis=1)[:, np.newaxis]\n",
        "        trans_prob = np.exp(normalized_log_trans_prob)\n",
        "\n",
        "        self.startprob_ = init_prob\n",
        "        self.transmat_ = trans_prob\n",
        "        self.emissionprob_ = emission_prob \n",
        "        self.n_components = self.n_hidden  \n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        \"\"\"Func to calculate forward probabilities, i.e. that the HMM will be in \n",
        "        a particular hidden state at a particular time step after emitting first\n",
        "        t number of visible words from input_seq.\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_seq : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        Returns\n",
        "        -------\n",
        "        forward_prob : np.array, shape(n_samples, n_hidden)\n",
        "            Matrix of forward probabilities\n",
        "        \"\"\"\n",
        "        input_seq_len = input_seq.shape[0]\n",
        "        input_seq = atleast2d_or_csr(input_seq)\n",
        "\n",
        "        forward_prob = np.zeros((input_seq_len, self.n_hidden))\n",
        "        # element-wise multiplication\n",
        "        forward_prob[0, :] = self.startprob_ * self.emissionprob_[:, input_seq[0]]\n",
        "    \n",
        "        for t in range(1, input_seq_len):\n",
        "            for j in range(self.n_hidden):\n",
        "                # probability that there will be a transition from any hidden \n",
        "                # state at (t−1) to a particular state j at time step t.\n",
        "                state_j_prob = forward_prob[t - 1].dot(selt.transmat_[:, j])\n",
        "                forward_prob[t, j] = state_j_prob * self.emissionprob_[j, input_seq[t]]\n",
        "        return forward_prob\n",
        "    \n",
        "    def backward(self, input_seq):\n",
        "        \"\"\"Func to calculate backward probabilities, i.e. that the HMM will be in \n",
        "        a particular hidden state at a particular time step and will generate \n",
        "        the remaining part visible words from input_seq.\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_seq : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        Returns\n",
        "        -------\n",
        "        backward_prob : np.array, shape(n_samples, n_hidden)\n",
        "            Matrix of backward probabilities\n",
        "        \"\"\"\n",
        "        input_seq_len = input_seq.shape[0]\n",
        "        input_seq = atleast2d_or_csr(input_seq)\n",
        "\n",
        "        backward_prob = np.zeros((input_seq_len, self.n_hidden))\n",
        "        # setting last column to 1\n",
        "        backward_prob[input_seq_len - 1] = np.ones((self.n_hidden))\n",
        "    \n",
        "        # Loop in backward way from T-1 to\n",
        "        # Due to python indexing the actual loop will be T-2 to 0\n",
        "        for t in range(input_seq_len - 2, -1, -1):\n",
        "            for j in range(self.n_hidden):\n",
        "                backward_prob[t, j] = (backward_prob[t + 1] * self.emissionprob_[:, input_seq[t + 1]]).dot(self.transmat_[j, :])\n",
        "        return backward_prob\n",
        "\n",
        "    def viterbi(self, input_seq):\n",
        "        \"\"\"Func to calculate forward probabilities, i.e. that the HMM will be in \n",
        "        a particular hidden state at a particular time step after emitting first\n",
        "        t number of visible words from input_seq.\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_seq : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        Returns\n",
        "        -------\n",
        "        forward_prob : np.array, shape(n_samples, n_hidden)\n",
        "            Matrix of forward probabilities\n",
        "        \"\"\"\n",
        "        input_seq_len = input_seq.shape[0]\n",
        "        input_seq = atleast2d_or_csr(input_seq)\n",
        "    \n",
        "        omega = np.zeros((input_seq_len, self.n_hidden))\n",
        "        omega[0, :] = self.startprob_ * self.emissionprob_[:, input_seq[0]]\n",
        "    \n",
        "        prev = np.zeros((input_seq_len - 1, self.n_hidden))\n",
        "    \n",
        "        for t in range(1, input_seq_len):\n",
        "            for j in range(self.n_hidden):\n",
        "                # Same as Forward Probability\n",
        "                state_j_prob = forward_prob[t - 1].dot(selt.transmat_[:, j])\n",
        "                forward_prob[t, j] = state_j_prob * self.emissionprob_[j, input_seq[t]]\n",
        "    \n",
        "                # This is the most probable state given previous state at time t (1)\n",
        "                prev[t - 1, j] = np.argmax(forward_prob)\n",
        "    \n",
        "                # This is the probability of the most probable state (2)\n",
        "                omega[t, j] = np.max(forward_prob)\n",
        "    \n",
        "        # Path Array\n",
        "        viterbi_path = np.zeros(input_seq_len)\n",
        "        # Find the most probable last hidden state\n",
        "        last_state = np.argmax(omega[input_seq_len - 1, :])\n",
        "        viterbi_path[0] = last_state\n",
        "    \n",
        "        backtrack_index = 1\n",
        "        for i in range(input_seq_len - 2, -1, -1):\n",
        "            viterbi_path[backtrack_index] = prev[i, int(last_state)]\n",
        "            last_state = prev[i, int(last_state)]\n",
        "            backtrack_index += 1\n",
        "    \n",
        "        # Flip the path array since we were backtracking\n",
        "        viterbi_path = np.flip(viterbi_path, axis=0)\n",
        "    \n",
        "        # Convert numeric values to actual hidden states\n",
        "        result = []\n",
        "        for s in viterbi_path:\n",
        "            result.append(self.classes[s])    \n",
        "        return result\n",
        "\n",
        "    def _decode_viterbi(self, X):\n",
        "        if sp.issparse(X):\n",
        "            X = X.toarray()\n",
        "        framelogprob = self._compute_log_likelihood(X)\n",
        "        return self._do_viterbi_pass(framelogprob)\n",
        "\n",
        "    def decode(self, X, lengths=None, algorithm=None):\n",
        "        \"\"\"Find most likely state sequence corresponding to ``X``.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape (n_samples, n_features)\n",
        "            Feature matrix of individual samples.\n",
        "        lengths : array-like of integers, shape (n_sequences, ), optional\n",
        "            Lengths of the individual sequences in ``X``. The sum of\n",
        "            these should be ``n_samples``.\n",
        "        algorithm : string\n",
        "            Decoder algorithm. Must be one of \"viterbi\" or \"map\".\n",
        "            If not given, :attr:`decoder` is used.\n",
        "        Returns\n",
        "        -------\n",
        "        logprob : float\n",
        "            Log probability of the produced state sequence.\n",
        "        state_sequence : array, shape (n_samples, )\n",
        "            Labels for each sample from ``X`` obtained via a given\n",
        "            decoder ``algorithm``.\n",
        "        See Also\n",
        "        --------\n",
        "        score_samples : Compute the log probability under the model and\n",
        "            posteriors.\n",
        "        score : Compute the log probability under the model.\n",
        "        \"\"\"\n",
        "        algorithm = algorithm or self.algorithm\n",
        "        decoder = {\n",
        "            \"viterbi\": self._decode_viterbi,\n",
        "            \"map\": self._decode_map\n",
        "        }[algorithm]\n",
        "\n",
        "        X = check_array(X, accept_sparse=True)\n",
        "        n_samples = X.shape[0]\n",
        "        logprob = 0\n",
        "        state_sequence = np.empty(n_samples, dtype=int)\n",
        "        for i, j in iter_from_X_lengths(X, lengths):\n",
        "            # XXX decoder works on a single sample at a time!\n",
        "            logprobij, state_sequenceij = decoder(X[i:j])\n",
        "            logprob += logprobij\n",
        "            state_sequence[i:j] = state_sequenceij\n",
        "\n",
        "        return logprob, state_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTnesATpM0oM",
        "colab_type": "code",
        "outputId": "842635e7-4871-4389-c408-0539c604e10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "%%time \n",
        "dv = DictVectorizer(sparse=True, dtype=int)\n",
        "X_train_flatten_vect = dv.fit_transform(X_train_flatten)\n",
        "display(X_train_flatten_vect, X_train_flatten_vect.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<984882x29197 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1984430 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(984882, 29197)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.14 s, sys: 10.1 ms, total: 2.15 s\n",
            "Wall time: 2.16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ-0tspfhPO8",
        "colab_type": "code",
        "outputId": "049c502d-d345-45e1-8d3a-83b52e94ee18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "inst = my_hmm()\n",
        "inst.fit_supervised(X_train_flatten_vect, y_train_flatten, lengths=lengths_train)\n",
        "print(inst.startprob_.shape)\n",
        "print(inst.transmat_.shape)\n",
        "print(inst.emissionprob_.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO      [2020-04-11 13:17:41,539] : X is sparse. Convert to csr if needed\n",
            "(17,)\n",
            "(17, 17)\n",
            "(17, 29197)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztw5v2FsY774",
        "colab_type": "code",
        "outputId": "7e83d2df-2641-4b1c-cade-a4c7efc76d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "inst.emissionprob_.max(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99982302, 0.99978742, 0.99989626, 0.99988842, 0.99975034,\n",
              "       0.99989546, 0.99989668, 0.99989834, 0.99979614, 0.99976735,\n",
              "       0.99989588, 0.99973787, 0.99927933, 0.99989821, 0.99989834,\n",
              "       0.99989455, 0.99989863])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbZWDLm7S1zX",
        "colab_type": "code",
        "outputId": "60dc47ef-a34a-4e10-ee8b-f01e4638ac68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "inst.emissionprob_.argmax(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxeyiyYqB9J8",
        "colab_type": "code",
        "outputId": "96fa3be1-184f-4ba8-f90d-8cf51cd0bbe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "inst.predict(X_train_flatten_vect[:np.cumsum(lengths_train[:2])[-1]].toarray(), lengths_train[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ff0eb12011ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mLabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \"\"\"\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-de887a8a4651>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, X, lengths, algorithm)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlogprobij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequenceij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mlogprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogprobij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mstate_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_sequenceij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4467141) into shape (153)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qYkgWJEyHE",
        "colab_type": "code",
        "outputId": "045ec166-41d2-4730-c410-a86c410c664f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.cumsum(lengths_train[:10])[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TKIyatDC2rv",
        "colab_type": "code",
        "outputId": "537920ef-a2f7-47ab-9e91-8ee82c90fb4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "inst = my_hmm(n_components=17, verbose=2)\n",
        "inst.fit(X_train_flatten_vect[:np.cumsum(lengths_train[:2])[-1]].toarray(), lengths_train[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         1    -5220923.2498             +nan\n",
            "         2       -6305.3314    +5214617.9184\n",
            "         3       -6304.7750          +0.5564\n",
            "         4       -6304.5293          +0.2457\n",
            "         5       -6304.4086          +0.1208\n",
            "         6       -6304.3395          +0.0690\n",
            "         7       -6304.2916          +0.0480\n",
            "         8       -6304.2517          +0.0399\n",
            "         9       -6304.2142          +0.0375\n",
            "        10       -6304.1764          +0.0378\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "my_hmm(algorithm='viterbi', alpha=0.01)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ2aFve66rO8",
        "colab_type": "code",
        "outputId": "b2a71a15-2d6d-48be-a1c7-c2f2835b243c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "inst.decode(X_train_flatten_vect, lengths=lengths_train, algorithm='viterbi')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-6e71e7e0c126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viterbi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-123-6898a5c0dc3d>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, X, lengths, algorithm)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mlogprobij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequenceij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlogprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogprobij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mstate_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_sequenceij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4467141) into shape (153)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSIfTIy5oO0N",
        "colab_type": "code",
        "outputId": "ae88863b-38ae-4d25-d963-52263204f52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "gen = iter_from_X_lengths(X_train_flatten_vect, lengths_train)\n",
        "start, stop = next(gen)\n",
        "X_train_flatten_vect[start:stop]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<153x29197 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 308 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erocSfJnzqgd",
        "colab_type": "code",
        "outputId": "889473de-58af-438a-bac5-ea5f6c3a3dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_train_flatten_vect[start:stop].toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True, False,  True, ..., False, False, False],\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       [False,  True,  True, ..., False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy24LdbKppSy",
        "colab_type": "code",
        "outputId": "23811cdd-7e15-4a7b-de5b-ed1fa64129a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.concatenate(X_train_flatten_vect[start:stop].toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False,  True, ..., False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wB4nTSJpk7j",
        "colab_type": "code",
        "outputId": "29cc8be7-0722-4f1b-bb89-c8fb55d7dd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "log_mask_zero(inst.emissionprob_)[:, np.concatenate(X_train_flatten_vect[start:stop].toarray())].T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-16829817842b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_mask_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissionprob_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 29197 but corresponding boolean dimension is 4467141"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8V64UIWMiMh",
        "colab_type": "code",
        "outputId": "7087999e-5629-4430-9522-307581141c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(X_train_flatten_vect[0].todense().tolist()[0]), inst.emissionprob_.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29197, (17, 29197))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C67GbUCiwoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "safe_sparse_dot(Y.T, X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV_aXgU3xrPQ",
        "colab_type": "code",
        "outputId": "497cea46-869e-4f26-8b7c-8713ea80e845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(X_train_flatten_vect[0].todense()).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 29197)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnl3DDyUyZRH",
        "colab_type": "code",
        "outputId": "702a7690-2a62-46b0-cde8-46b692f1dad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.concatenate(np.array(X_train_flatten_vect[0].todense())).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29197,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7NL0UfuL0A0",
        "colab_type": "code",
        "outputId": "6979ee58-6a0d-41b8-add6-38f654ee42a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "inst.emissionprob_[:, X_train_flatten_vect[0].todense().tolist()[0]].T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.79724896e-03, 2.53787974e-03, 3.19320133e-04, 1.47667295e-03,\n",
              "        3.05838456e-05, 3.38702267e-04, 3.09628844e-04, 8.62532772e-04,\n",
              "        1.96475234e-05, 2.61117059e-05, 7.78138170e-04, 3.02142188e-05,\n",
              "        3.24706952e-05, 3.20515902e-06, 2.36688071e-06, 1.11486449e-05,\n",
              "        5.13995696e-05],\n",
              "       [1.79724896e-03, 2.53787974e-03, 3.19320133e-04, 1.47667295e-03,\n",
              "        3.08896841e-03, 3.38702267e-04, 3.09628844e-04, 8.62532772e-04,\n",
              "        1.98439987e-03, 2.63728229e-03, 7.78138170e-04, 3.05163610e-03,\n",
              "        3.27954021e-03, 3.23721061e-04, 2.39054952e-04, 1.12601313e-03,\n",
              "        5.13995696e-05],\n",
              "       [1.77945442e-05, 2.51275222e-05, 3.16158547e-06, 1.46205243e-05,\n",
              "        3.05838456e-05, 3.35348779e-06, 3.06563212e-06, 8.53992844e-06,\n",
              "        1.96475234e-05, 2.61117059e-05, 7.78138170e-04, 3.02142188e-05,\n",
              "        3.24706952e-05, 3.20515902e-06, 2.36688071e-06, 1.11486449e-05,\n",
              "        5.13995696e-05]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdkLUzBsK0Ls",
        "colab_type": "code",
        "outputId": "1dc6fffd-13a0-4202-92ff-2220d3375d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "inst.emissionprob_[:, [1,2,3]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.42533719e-06, 3.60999840e-01, 9.42533719e-06],\n",
              "       [1.22553525e-05, 3.19876956e-01, 1.22553525e-05],\n",
              "       [1.05579543e-04, 4.90793424e-01, 1.31809666e-07],\n",
              "       [6.07912480e-05, 4.72599328e-01, 3.02444020e-07],\n",
              "       [1.46634016e-05, 2.85950995e-01, 1.46634016e-05],\n",
              "       [5.13567771e-05, 4.88886112e-01, 2.55506354e-07],\n",
              "       [2.87985504e-07, 4.91821932e-01, 2.87985504e-07],\n",
              "       [2.69103913e-05, 4.95870854e-01, 2.66439518e-07],\n",
              "       [1.17100132e-05, 3.29063082e-01, 1.17100132e-05],\n",
              "       [1.36617621e-05, 3.00572428e-01, 1.36617621e-05],\n",
              "       [6.88611807e-07, 4.89879128e-01, 6.88611807e-07],\n",
              "       [1.53381291e-05, 2.76101661e-01, 1.53381291e-05],\n",
              "       [2.59087494e-05, 1.21797031e-01, 2.59087494e-05],\n",
              "       [3.07955278e-05, 4.95533886e-01, 3.04906215e-07],\n",
              "       [2.84058872e-07, 4.95853451e-01, 2.84058872e-07],\n",
              "       [1.81835123e-04, 4.86703872e-01, 9.04652356e-07],\n",
              "       [4.38063264e-03, 4.96572206e-01, 1.45422796e-03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehgVqF9D7kTe",
        "colab_type": "code",
        "outputId": "d67b981f-5534-4632-a025-3f7b4ea65ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "inst.emissionprob_[:, X_train_flatten_vect[0]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-4e1d5c8bb037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissionprob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Iq0uxNjTZI",
        "colab_type": "code",
        "outputId": "0be4c2d1-cfba-4f7f-9b13-8aa8e8b2b1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.unique(X_train_flatten_vect[0].todense().tolist())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH3IfP1x7465",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNHemq9HhHb1",
        "colab_type": "code",
        "outputId": "b0e37ad6-4d4c-440f-f775-a725427ccbfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "atleast2d_or_csr(X_train_flatten_vect)[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO      [2020-04-07 12:11:03,465] : X is sparse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x29197 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRfRHqOwgdWS",
        "colab_type": "code",
        "outputId": "be635a72-41dd-4047-fdd4-54673adf6a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "inst.viterbi(X_train_flatten_vect)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-6c0827312ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-7e8f3d045c35>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0momega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0momega\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartprob_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissionprob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmmtX5Iykd2I",
        "colab_type": "code",
        "outputId": "152179a7-8797-43f8-f3a3-649af19381e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "inst.emissionprob_[:, X_train_flatten_vect[0].todense()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-9033f66c877f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissionprob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten_X_train_vect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt8iL4ISaeg8",
        "colab_type": "text"
      },
      "source": [
        "###Unsupervised\n",
        "use hmmlearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGHM9BdM36Xm",
        "colab_type": "code",
        "outputId": "daa2465b-54de-4418-804c-9744bcf9817f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.array(X_train_flatten).reshape(-1, 1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(984882, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZytmoLKE3MBN",
        "colab_type": "code",
        "outputId": "d1750d40-d0fe-4b8f-8534-d04fbdbfe63f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.array(X_train_flatten).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(984882,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b376pG-vy_91",
        "colab_type": "code",
        "outputId": "9b35590c-15eb-4b3a-a7a1-8e370c661790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unsupervised_hmm = hmmlearn_MHMM(n_components=unique_labels)\n",
        "unsupervised_hmm.fit(np.array(X_train_flatten).reshape(-1, 1), lengths_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-4fa41e469ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munsupervised_hmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmmlearn_MHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munsupervised_hmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \"\"\"\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIhTA47mSL0d",
        "colab_type": "text"
      },
      "source": [
        "## CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPsUagYYl0c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_rand_search(X_train, y_train, parameters):\n",
        "    search = RandomizedSearchCV(estimator=CRF(),\n",
        "                            param_distributions=parameters,\n",
        "                            n_iter=10, scoring={metric.__name__:make_scorer(_flattens_y(metric)) for metric in scoring}, \n",
        "                            n_jobs=-1,\n",
        "                            verbose=2,\n",
        "                            cv=KFold(n_splits=3, shuffle=False, random_state=42),\n",
        "                            refit='bio_f_score'#False,\n",
        "                            )\n",
        "    search.fit(X_train, y_train)\n",
        "    return search\n",
        "\n",
        "def show_search_results(search):\n",
        "    full_df = pd.DataFrame(search.cv_results_)\n",
        "    df_cutted = full_df.drop([k for k in search.cv_results_.keys() if any(col in k for col in ['split','std', 'params'])], axis=1)\n",
        "\n",
        "    print('best params:', search.best_params_)\n",
        "    print('best CV score:', search.best_score_)\n",
        "    print('model size: {:0.2f}M'.format(search.best_estimator_.size_ / 1000000))\n",
        "\n",
        "    pred_unflatten = search.predict(X_test)\n",
        "    bio_clf_report = evaluate_bio_clf_report(y_test, pred_unflatten, \n",
        "                                            labels=list(search.best_estimator_.classes_),\n",
        "                                            do_flatten=True)\n",
        "    entity_clf_report = evaluate_entity_clf_report(y_test, pred_unflatten, lengths_test)\n",
        "    print('*****BIO-tag LEVEL*****\\n', bio_clf_report, '\\n*****ENTITY LEVEL*****\\n', entity_clf_report)\n",
        "\n",
        "    return full_df, df_cutted, pred_unflatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X872piziZBlS",
        "colab_type": "text"
      },
      "source": [
        "####Simple features (bias, lower, BOS, EOS) without tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tlFaU1qTSL0k",
        "colab_type": "code",
        "outputId": "fb65cdf9-ad47-4206-d731-1bf0985769df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "crf=CRF(algorithm='lbfgs',\n",
        "         c1=0.1,\n",
        "         c2=0.1,\n",
        "         max_iterations=100,\n",
        "         all_possible_transitions=False)\n",
        "\n",
        "scores = cross_validate(crf, X_train, y_train, cv=cv, n_jobs=-1, \n",
        "                        scoring={metric.__name__:make_scorer(_flattens_y(metric)) for metric in scoring}, \n",
        "                        verbose=100, return_estimator=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pickling array (shape=(5866,), dtype=int64).\n",
            "Pickling array (shape=(1467,), dtype=int64).\n",
            "Pickling array (shape=(5866,), dtype=int64).\n",
            "Pickling array (shape=(1467,), dtype=int64).\n",
            "Pickling array (shape=(5866,), dtype=int64).\n",
            "Pickling array (shape=(1467,), dtype=int64).\n",
            "Pickling array (shape=(5867,), dtype=int64).\n",
            "Pickling array (shape=(1466,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.8min\n",
            "Pickling array (shape=(5867,), dtype=int64).\n",
            "Pickling array (shape=(1466,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.3min remaining:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  2.6min remaining:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.1min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.1min finished\n",
            "CPU times: user 1min 44s, sys: 564 ms, total: 1min 44s\n",
            "Wall time: 3min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd9e9nYgSL0m",
        "colab_type": "code",
        "outputId": "c0699384-1275-4216-9c7b-aadc71fef2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "pd.DataFrame({k:v for k,v in scores.items() if 'test_' in k})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_bio_f_score</th>\n",
              "      <th>test_f1_macro</th>\n",
              "      <th>test_fbeta_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053810</td>\n",
              "      <td>0.056710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053813</td>\n",
              "      <td>0.056711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053776</td>\n",
              "      <td>0.056695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053782</td>\n",
              "      <td>0.056698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053735</td>\n",
              "      <td>0.056677</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_bio_f_score  test_f1_macro  test_fbeta_macro\n",
              "0               0.0       0.053810          0.056710\n",
              "1               0.0       0.053813          0.056711\n",
              "2               0.0       0.053776          0.056695\n",
              "3               0.0       0.053782          0.056698\n",
              "4               0.0       0.053735          0.056677"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNm0OHjjfbeF",
        "colab_type": "text"
      },
      "source": [
        "#### All features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwQJMwalA1f2",
        "colab_type": "text"
      },
      "source": [
        "#### GB methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22x6QgNVWo2l",
        "colab_type": "code",
        "outputId": "72747953-faff-4b9b-8c1b-43f8530f52e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "parameters = {'algorithm': ['lbfgs'], \n",
        "              'c1': [0.1, 0.01], \n",
        "              'c2': [0.1, 0.01],\n",
        "              'all_possible_transitions': [True, False]}\n",
        "\n",
        "search = run_rand_search(X_train, y_train, parameters)\n",
        "full_df, df_cutted, pred_unflatten = show_search_results(search)\n",
        "df_cutted"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 575.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best params: {'c2': 0.1, 'c1': 0.1, 'all_possible_transitions': True, 'algorithm': 'lbfgs'}\n",
            "best CV score: 0.8442490525177447\n",
            "model size: 3.13M\n",
            "*****BIO-tag LEVEL*****\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       B-art      0.452     0.194     0.272        72\n",
            "       I-art      0.467     0.259     0.333        54\n",
            "       B-eve      0.386     0.309     0.343        55\n",
            "       I-eve      0.194     0.146     0.167        41\n",
            "       B-geo      0.872     0.910     0.890      9387\n",
            "       I-geo      0.813     0.818     0.815      1744\n",
            "       B-gpe      0.974     0.956     0.965      3843\n",
            "       I-gpe      0.812     0.722     0.765        36\n",
            "       B-nat      0.846     0.367     0.512        30\n",
            "       I-nat      0.833     0.625     0.714         8\n",
            "       B-org      0.805     0.729     0.765      4999\n",
            "       I-org      0.822     0.782     0.802      4274\n",
            "       B-per      0.836     0.839     0.838      4291\n",
            "       I-per      0.835     0.893     0.863      4343\n",
            "       B-tim      0.923     0.876     0.898      4691\n",
            "       I-tim      0.829     0.700     0.759      1415\n",
            "\n",
            "   micro avg      0.860     0.848     0.854     39283\n",
            "   macro avg      0.731     0.633     0.669     39283\n",
            "weighted avg      0.859     0.848     0.852     39283\n",
            " \n",
            "*****ENTITY LEVEL*****\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "      per       0.77      0.77      0.77      4291\n",
            "      tim       0.90      0.85      0.88      4691\n",
            "      nat       0.85      0.37      0.51        30\n",
            "      gpe       0.97      0.96      0.96      3843\n",
            "      geo       0.87      0.90      0.89      9387\n",
            "      org       0.77      0.70      0.74      4999\n",
            "      eve       0.36      0.29      0.32        55\n",
            "      art       0.45      0.19      0.27        72\n",
            "\n",
            "micro avg       0.85      0.84      0.85     27368\n",
            "macro avg       0.85      0.84      0.85     27368\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>param_c2</th>\n",
              "      <th>param_c1</th>\n",
              "      <th>param_all_possible_transitions</th>\n",
              "      <th>param_algorithm</th>\n",
              "      <th>mean_test_bio_f_score</th>\n",
              "      <th>rank_test_bio_f_score</th>\n",
              "      <th>mean_test_f1_macro</th>\n",
              "      <th>rank_test_f1_macro</th>\n",
              "      <th>mean_test_fbeta_macro</th>\n",
              "      <th>rank_test_fbeta_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5078.268208</td>\n",
              "      <td>13.006236</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.844249</td>\n",
              "      <td>1</td>\n",
              "      <td>0.639689</td>\n",
              "      <td>3</td>\n",
              "      <td>0.623642</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7884.569026</td>\n",
              "      <td>14.014825</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.839618</td>\n",
              "      <td>6</td>\n",
              "      <td>0.633747</td>\n",
              "      <td>6</td>\n",
              "      <td>0.620083</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5042.338612</td>\n",
              "      <td>13.442750</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>True</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.843070</td>\n",
              "      <td>4</td>\n",
              "      <td>0.639646</td>\n",
              "      <td>4</td>\n",
              "      <td>0.624001</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8294.303088</td>\n",
              "      <td>12.860991</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>True</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.833200</td>\n",
              "      <td>8</td>\n",
              "      <td>0.624828</td>\n",
              "      <td>7</td>\n",
              "      <td>0.614282</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3874.859576</td>\n",
              "      <td>13.421319</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>False</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.844139</td>\n",
              "      <td>2</td>\n",
              "      <td>0.640371</td>\n",
              "      <td>2</td>\n",
              "      <td>0.624631</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5902.170344</td>\n",
              "      <td>14.100148</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.1</td>\n",
              "      <td>False</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.839809</td>\n",
              "      <td>5</td>\n",
              "      <td>0.635455</td>\n",
              "      <td>5</td>\n",
              "      <td>0.623602</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3715.930987</td>\n",
              "      <td>13.114199</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.843072</td>\n",
              "      <td>3</td>\n",
              "      <td>0.641796</td>\n",
              "      <td>1</td>\n",
              "      <td>0.627176</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4059.283186</td>\n",
              "      <td>8.828271</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.833361</td>\n",
              "      <td>7</td>\n",
              "      <td>0.623698</td>\n",
              "      <td>8</td>\n",
              "      <td>0.613546</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  ... mean_test_fbeta_macro rank_test_fbeta_macro\n",
              "0    5078.268208        13.006236  ...              0.623642                     4\n",
              "1    7884.569026        14.014825  ...              0.620083                     6\n",
              "2    5042.338612        13.442750  ...              0.624001                     3\n",
              "3    8294.303088        12.860991  ...              0.614282                     7\n",
              "4    3874.859576        13.421319  ...              0.624631                     2\n",
              "5    5902.170344        14.100148  ...              0.623602                     5\n",
              "6    3715.930987        13.114199  ...              0.627176                     1\n",
              "7    4059.283186         8.828271  ...              0.613546                     8\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eXPr1Nyl_2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cf23fcc-1ffc-4345-dbe7-e2d7c568849c"
      },
      "source": [
        "parameters = {'algorithm': ['l2sgd'], \n",
        "              'c2': [0.1, 0.01],\n",
        "              'all_possible_transitions': [True, False]}\n",
        "\n",
        "search = run_rand_search(X_train, y_train, parameters)\n",
        "full_df, df_cutted, pred_unflatten = show_search_results(search)\n",
        "df_cutted"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 36.5min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 36.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best params: {'c2': 0.1, 'all_possible_transitions': True, 'algorithm': 'l2sgd'}\n",
            "best CV score: 0.8391407477825762\n",
            "model size: 8.93M\n",
            "*****BIO-tag LEVEL*****\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       B-art      0.419     0.181     0.252        72\n",
            "       I-art      0.370     0.185     0.247        54\n",
            "       B-eve      0.386     0.309     0.343        55\n",
            "       I-eve      0.222     0.244     0.233        41\n",
            "       B-geo      0.848     0.929     0.886      9387\n",
            "       I-geo      0.769     0.833     0.799      1744\n",
            "       B-gpe      0.974     0.956     0.965      3843\n",
            "       I-gpe      0.844     0.750     0.794        36\n",
            "       B-nat      0.684     0.433     0.531        30\n",
            "       I-nat      0.714     0.625     0.667         8\n",
            "       B-org      0.829     0.701     0.760      4999\n",
            "       I-org      0.857     0.743     0.796      4274\n",
            "       B-per      0.819     0.839     0.829      4291\n",
            "       I-per      0.814     0.908     0.858      4343\n",
            "       B-tim      0.921     0.881     0.900      4691\n",
            "       I-tim      0.832     0.706     0.764      1415\n",
            "\n",
            "   micro avg      0.853     0.847     0.850     39283\n",
            "   macro avg      0.706     0.639     0.664     39283\n",
            "weighted avg      0.854     0.847     0.848     39283\n",
            " \n",
            "*****ENTITY LEVEL*****\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "      per       0.75      0.77      0.76      4291\n",
            "      tim       0.90      0.86      0.88      4691\n",
            "      nat       0.68      0.43      0.53        30\n",
            "      gpe       0.97      0.96      0.96      3843\n",
            "      geo       0.84      0.92      0.88      9387\n",
            "      org       0.80      0.67      0.73      4999\n",
            "      eve       0.36      0.29      0.32        55\n",
            "      art       0.42      0.18      0.25        72\n",
            "\n",
            "micro avg       0.85      0.84      0.84     27368\n",
            "macro avg       0.85      0.84      0.84     27368\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>param_c2</th>\n",
              "      <th>param_all_possible_transitions</th>\n",
              "      <th>param_algorithm</th>\n",
              "      <th>mean_test_bio_f_score</th>\n",
              "      <th>rank_test_bio_f_score</th>\n",
              "      <th>mean_test_f1_macro</th>\n",
              "      <th>rank_test_f1_macro</th>\n",
              "      <th>mean_test_fbeta_macro</th>\n",
              "      <th>rank_test_fbeta_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>537.090520</td>\n",
              "      <td>15.092035</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>l2sgd</td>\n",
              "      <td>0.839141</td>\n",
              "      <td>1</td>\n",
              "      <td>0.627980</td>\n",
              "      <td>4</td>\n",
              "      <td>0.616956</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>454.976540</td>\n",
              "      <td>14.281680</td>\n",
              "      <td>0.01</td>\n",
              "      <td>True</td>\n",
              "      <td>l2sgd</td>\n",
              "      <td>0.826727</td>\n",
              "      <td>4</td>\n",
              "      <td>0.635371</td>\n",
              "      <td>3</td>\n",
              "      <td>0.623382</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>639.355750</td>\n",
              "      <td>14.025988</td>\n",
              "      <td>0.1</td>\n",
              "      <td>False</td>\n",
              "      <td>l2sgd</td>\n",
              "      <td>0.839034</td>\n",
              "      <td>2</td>\n",
              "      <td>0.639518</td>\n",
              "      <td>2</td>\n",
              "      <td>0.624699</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>397.214507</td>\n",
              "      <td>8.920340</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>l2sgd</td>\n",
              "      <td>0.835731</td>\n",
              "      <td>3</td>\n",
              "      <td>0.645080</td>\n",
              "      <td>1</td>\n",
              "      <td>0.626771</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  ... mean_test_fbeta_macro rank_test_fbeta_macro\n",
              "0     537.090520        15.092035  ...              0.616956                     4\n",
              "1     454.976540        14.281680  ...              0.623382                     3\n",
              "2     639.355750        14.025988  ...              0.624699                     2\n",
              "3     397.214507         8.920340  ...              0.626771                     1\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcPk8a5EA6Lk",
        "colab_type": "text"
      },
      "source": [
        "#### Non-GB methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lFlBTr7BHTw",
        "colab_type": "code",
        "outputId": "1710ff08-92f2-4d3a-add5-744b7711a03e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "parameters = {'algorithm': ['ap', 'pa', 'arow']}\n",
        "\n",
        "search = run_rand_search(X_train, y_train, parameters)\n",
        "full_df, df_cutted, pred_unflatten = show_search_results(search)\n",
        "df_cutted"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed: 16.2min remaining:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 18.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best params: {'algorithm': 'pa'}\n",
            "best CV score: 0.8419118105485338\n",
            "model size: 5.10M\n",
            "*****BIO-tag LEVEL*****\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       B-art      0.381     0.222     0.281        72\n",
            "       I-art      0.481     0.241     0.321        54\n",
            "       B-eve      0.438     0.382     0.408        55\n",
            "       I-eve      0.303     0.244     0.270        41\n",
            "       B-geo      0.871     0.909     0.890      9387\n",
            "       I-geo      0.813     0.814     0.814      1744\n",
            "       B-gpe      0.970     0.957     0.964      3843\n",
            "       I-gpe      0.844     0.750     0.794        36\n",
            "       B-nat      0.812     0.433     0.565        30\n",
            "       I-nat      1.000     0.625     0.769         8\n",
            "       B-org      0.800     0.729     0.763      4999\n",
            "       I-org      0.845     0.764     0.802      4274\n",
            "       B-per      0.826     0.841     0.833      4291\n",
            "       I-per      0.832     0.895     0.862      4343\n",
            "       B-tim      0.921     0.879     0.900      4691\n",
            "       I-tim      0.853     0.683     0.759      1415\n",
            "\n",
            "   micro avg      0.861     0.846     0.853     39283\n",
            "   macro avg      0.749     0.648     0.687     39283\n",
            "weighted avg      0.860     0.846     0.852     39283\n",
            " \n",
            "*****ENTITY LEVEL*****\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "      per       0.76      0.77      0.76      4291\n",
            "      tim       0.90      0.86      0.88      4691\n",
            "      nat       0.81      0.43      0.57        30\n",
            "      gpe       0.97      0.96      0.96      3843\n",
            "      geo       0.87      0.90      0.88      9387\n",
            "      org       0.77      0.70      0.73      4999\n",
            "      eve       0.42      0.36      0.39        55\n",
            "      art       0.38      0.22      0.28        72\n",
            "\n",
            "micro avg       0.85      0.84      0.85     27368\n",
            "macro avg       0.85      0.84      0.84     27368\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>param_algorithm</th>\n",
              "      <th>mean_test_bio_f_score</th>\n",
              "      <th>rank_test_bio_f_score</th>\n",
              "      <th>mean_test_f1_macro</th>\n",
              "      <th>rank_test_f1_macro</th>\n",
              "      <th>mean_test_fbeta_macro</th>\n",
              "      <th>rank_test_fbeta_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>215.801909</td>\n",
              "      <td>12.645297</td>\n",
              "      <td>ap</td>\n",
              "      <td>0.840907</td>\n",
              "      <td>2</td>\n",
              "      <td>0.643963</td>\n",
              "      <td>2</td>\n",
              "      <td>0.627523</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246.379716</td>\n",
              "      <td>11.997287</td>\n",
              "      <td>pa</td>\n",
              "      <td>0.841912</td>\n",
              "      <td>1</td>\n",
              "      <td>0.645208</td>\n",
              "      <td>1</td>\n",
              "      <td>0.628318</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>205.178590</td>\n",
              "      <td>8.887510</td>\n",
              "      <td>arow</td>\n",
              "      <td>0.755875</td>\n",
              "      <td>3</td>\n",
              "      <td>0.578727</td>\n",
              "      <td>3</td>\n",
              "      <td>0.572033</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  ... mean_test_fbeta_macro  rank_test_fbeta_macro\n",
              "0     215.801909        12.645297  ...              0.627523                      2\n",
              "1     246.379716        11.997287  ...              0.628318                      1\n",
              "2     205.178590         8.887510  ...              0.572033                      3\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww7d_H8byxmK",
        "colab_type": "text"
      },
      "source": [
        "##Bi-LSTM:\n",
        "Use keras or tensorflow;  \n",
        "https://github.com/hse-aml/natural-language-processing/blob/master/week2/week2-NER.ipynb  \n",
        "A plus for incorporating CNN-layers;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zfAB5LyyzaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = list(set(dataset[\"word\"].values))\n",
        "words.append(\"ENDPAD\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJO5P0mQZaeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxPM5Fy7ZmXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBRxidduZ1bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
        "X = pad_sequences(maxlen=170, sequences=X, padding=\"post\", value=len(words) - 1) # ENDPAD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcwGMd1LafDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=140, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
        "from keras.utils import to_categorical\n",
        "y = [to_categorical(i, num_classes=n_tags) for i in y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_iXeLrdbE6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G4kE107auwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [sent2features(s) for s in word_pos_tag_sentences]\n",
        "y = [get_sent_labels(s) for s in word_pos_tag_sentences]\n",
        "\n",
        "#make a split while the data is still sequential\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=False, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}