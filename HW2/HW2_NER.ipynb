{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# About notebook\n",
    "Dataset\n",
    "*\tGroningen Meaning Bank (version 2.2.0)\n",
    "*\tTask: named entity recognition\n",
    "*\tTarget – named entity tags (BIO + entity type)\n",
    "*\tInput data: \n",
    "  * Use “en.met” files to extract the subcorpus\n",
    "  corpus = 'Voice of America' (for honogeneity of the input data set)\n",
    "  * Use \"en.tags\" files for the main input data:\n",
    "      *\traw tokens + may use the lemmas and the POS-tags \n",
    "  (i.e. take the “golden” POS-tagging);\n",
    "      *\twhich means:\n",
    "        *\tfirst three columns for input: ['word', 'pos', 'lemma']\n",
    "        *\tthe fourth column for target variable (‘ne_tags’)\n",
    "        (BIO annotation + the named-entity type in one tag)  \n",
    "\n",
    "# Tasks\n",
    "1.\tThe most trivial model = supervised HMM:\n",
    "  *\tTake hmmlearn (former sklearn), modify MultinomialHMM (I.e. inherit a new class from _BaseHMM making it a modified copy of the latter) to allow for supervised HMM training. The states of the HMM model = the NE tags.\n",
    "  *\tNOTE: may use NaiveBayes to learn emission probabilities in a supervized manner.\n",
    "  *\tOr implement from scratch (with Viterbi for prediction).\n",
    "  *\tNOTE: use tuples of features for X (not just the word, but additional info).\n",
    "  *\tNOTE: use smoothing for state transitions.\n",
    "2.\tCRF\n",
    "  *\tModify the input features;\n",
    "  *\tUse CRFSuite.\n",
    "3.\tBi-LSTM:\n",
    "  *\tUse keras or tensorflow;\n",
    "  *\thttps://github.com/hse-aml/natural-language-processing/blob/master/week2/week2-NER.ipynb\n",
    "  *\tA plus for incorporating CNN-layers;\n",
    "\n",
    "# Metrics\n",
    "* normalized confusion matrices, precision, recall, F-score \n",
    "(macro- and micro-) \n",
    "* (token level, entity level, partial matching (i.e. boundary-detection problem), binary).  \n",
    "NOTE: taking into account vocabulary transfer is a plus.\n",
    "\n",
    "# Evaluation Criteria\n",
    "Scoring (14.5 max):  \n",
    "*\tDataset overview – 0.5\n",
    "  *\ttext lengths, vocabulary size, frequencies of patterns (<UNK-type-i>) \n",
    "  *\tstats over the target tags\n",
    "*\tFeature engineering – 2 (1+1)\n",
    "  *\tgrammatical words = closed set (~ stop words)\n",
    "  *\tStemming + POS\n",
    "  *\tWord shape\n",
    "  *\tAd hoc features ( +1)  \n",
    "*\tWord patterns -> encode types of unknown words +0.5\n",
    "*\tSmoothing in HMM – 0.5 \n",
    "  *\tIn HMM: for state transitions.\n",
    "*\tIncorporating tupled features in HMM (on top of tokens) – 1\n",
    "*\tThe correct HMM implementation – 1\n",
    "*\tMore fine-grained feature engineering for the Neural Network + 0.5\n",
    "  *\tDifferentiate between POS-relevancy for the word and the context, etc.\n",
    "  *\tSentence-level features (may use “golden” sentence-splitting)\n",
    "*\tEvaluation (on all levels) – 1\n",
    "*\tConclusion on HMM deficiency (as a model) – 1\n",
    "*\tCRF: 1 point for use and evaluation, + 0.5 points for comparison and conclusions;\n",
    "*\tNN:\n",
    "  *\tMain network: 4\n",
    "  *\tCNN layers: +2  \n",
    "\n",
    "Libraries: hmmlearn, crfsuite, tensorflow, keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30D0Scxk4kn3"
   },
   "source": [
    "# Libs import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ZnXUdrxQ3TAN",
    "outputId": "910fb799-41ed-4c9b-98ca-55a44b62566f"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "import os\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "VD2z8D2V7Dod"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "auzLnrdK51Rg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data found: ['p00', 'p01', 'p02', 'p03', 'p04', 'p05', 'p06', 'p07', 'p08', 'p09', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'p66', 'p67', 'p68', 'p69', 'p70', 'p71', 'p72', 'p73', 'p74', 'p75', 'p76', 'p77', 'p78', 'p79', 'p80', 'p81', 'p82', 'p83', 'p84', 'p85', 'p86', 'p87', 'p88', 'p89', 'p90', 'p91', 'p92', 'p93', 'p94', 'p95', 'p96', 'p97', 'p98', 'p99']\n"
     ]
    }
   ],
   "source": [
    "data_path = 'D:\\Data\\gmb-2.2.0\\data'\n",
    "print('data found:', os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subcorpus = 'Voice of America'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "tgwhO8ngi-A4"
   },
   "source": [
    "Parsing data from \"Voice of America\" subcorpus. According to the instructions we take first four columns and additional column to separate data on texts, sentences or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "-UBeZ_eui-A5",
    "outputId": "5308f75a-eaa2-42e3-ecae-4f6aa512ec36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [06:26<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "voa_data = pd.DataFrame(columns=['word', 'pos', 'lemma', 'ne_tags', 'text_id'])\n",
    "\n",
    "os.chdir(data_path)\n",
    "part_paths = os.listdir()\n",
    "\n",
    "for part_path in tqdm(part_paths, total=len(part_paths)):\n",
    "    os.chdir(part_path)\n",
    "    document_paths = os.listdir()\n",
    "    for document_path in document_paths:\n",
    "        os.chdir(document_path)\n",
    "        f = codecs.open(\"en.met\",'r', \"utf_8_sig\")\n",
    "        file_met = f.read()\n",
    "        if('subcorpus: {}'.format(subcorpus) in file_met):\n",
    "            subcorpus = pd.read_csv('en.tags', sep='\\t',\n",
    "                                    header=None, \n",
    "                                    names=['word', 'pos', 'lemma', 'ne_tags'],\n",
    "                                    usecols=[0,1,2,3],\n",
    "                                    error_bad_lines=False)\n",
    "            subcorpus['text_id'] = str(part_path)+'_'+str(document_path)\n",
    "            main_input_data = main_input_data.append(subcorpus, ignore_index=True)\n",
    "        f.close()\n",
    "        os.chdir('..')   \n",
    "    os.chdir('..')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "UX1ViqnKi-A-",
    "outputId": "c391cb23-3288-4f4f-db22-f5afc86f4fa2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage:  46.969688415527344  MB\n"
     ]
    }
   ],
   "source": [
    "print(\"memory usage: \",voa_data.memory_usage().sum()/1024/1024, \" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrator</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos         lemma ne_tags    text_id\n",
       "0      Thousands  NNS      thousand       O  p00_d0018\n",
       "1             of   IN            of       O  p00_d0018\n",
       "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
       "3           have  VBP          have       O  p00_d0018\n",
       "4        marched  VBN         march       O  p00_d0018"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "kUrX7pvxi-BB",
    "outputId": "f42abe57-ad1b-4a64-a7b3-6bf93acb5155",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1231279, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "8vWQ-w4Qi-BF"
   },
   "source": [
    "Number of tokens coincided with the declared in README file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "voa_data.to_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "15GVrJYa717o"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrator</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos         lemma ne_tags    text_id\n",
       "0      Thousands  NNS      thousand       O  p00_d0018\n",
       "1             of   IN            of       O  p00_d0018\n",
       "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
       "3           have  VBP          have       O  p00_d0018\n",
       "4        marched  VBN         march       O  p00_d0018"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data = pd.read_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus))\n",
    "voa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "b1Y2cJhli-BG",
    "outputId": "31c7858e-e9f0-45de-fd83-9c7ff746db38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average text length:  134.31646121959201\n"
     ]
    }
   ],
   "source": [
    "def average_text_length(text_id):\n",
    "    doc_lengths = list(dict(Counter(text_id)).values())\n",
    "    sum = 0\n",
    "    for length in doc_lengths:\n",
    "        sum += length\n",
    "    return sum/len(doc_lengths)\n",
    "\n",
    "print(\"average text length: \", average_text_length(voa_data['text_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>35154</td>\n",
       "      <td>48</td>\n",
       "      <td>27209</td>\n",
       "      <td>25</td>\n",
       "      <td>9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>61398</td>\n",
       "      <td>168817</td>\n",
       "      <td>74941</td>\n",
       "      <td>1032479</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word      pos    lemma  ne_tags    text_id\n",
       "count   1231279  1231279  1231279  1231279    1231279\n",
       "unique    35154       48    27209       25       9167\n",
       "top         the       NN      the        O  p00_d0090\n",
       "freq      61398   168817    74941  1032479        388"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(df):\n",
    "    \"\"\"func to Get the sentences in this format:\n",
    "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_1, Tag_1)]\"\"\"\n",
    "    \n",
    "    agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                       s[\"pos\"].values.tolist(),\n",
    "                                                       s[\"ne_tags\"].values.tolist())]\n",
    "    grouped = df.groupby(\"text_id\").apply(agg_func)\n",
    "    sentences = [s for s in grouped]\n",
    "    \n",
    "    return sentences\n",
    "        \n",
    "word_pos_tag_sentences = get_sentences(voa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Thousands', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('demonstrators', 'NNS', 'O'),\n",
       "  ('have', 'VBP', 'O'),\n",
       "  ('marched', 'VBN', 'O'),\n",
       "  ('through', 'IN', 'O'),\n",
       "  ('London', 'NNP', 'geo-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('protest', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('war', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Iraq', 'NNP', 'geo-nam'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('demand', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('withdrawal', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('British', 'JJ', 'gpe-nam'),\n",
       "  ('troops', 'NNS', 'O'),\n",
       "  ('from', 'IN', 'O'),\n",
       "  ('that', 'DT', 'O'),\n",
       "  ('country', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Families', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('soldiers', 'NNS', 'O'),\n",
       "  ('killed', 'VBN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('conflict', 'NN', 'O'),\n",
       "  ('joined', 'VBD', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('protesters', 'NNS', 'O'),\n",
       "  ('who', 'WP', 'O'),\n",
       "  ('carried', 'VBD', 'O'),\n",
       "  ('banners', 'NNS', 'O'),\n",
       "  ('with', 'IN', 'O'),\n",
       "  ('such', 'JJ', 'O'),\n",
       "  ('slogans', 'NNS', 'O'),\n",
       "  ('as', 'IN', 'O'),\n",
       "  ('\\tLQU\\t', 'O', '[]'),\n",
       "  ('Bush', 'NNP', 'per-fam'),\n",
       "  ('Number', 'NN', 'O'),\n",
       "  ('One', 'CD', 'O'),\n",
       "  ('Terrorist', 'NN', 'O'),\n",
       "  ('\\tRQU\\t', 'O', '[]'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('\\tLQU\\t', 'O', '[]'),\n",
       "  ('Stop', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Bombings', 'NNS', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('\\tLQU\\t', 'O', '[]'),\n",
       "  ('They', 'PRP', 'O'),\n",
       "  ('marched', 'VBD', 'O'),\n",
       "  ('from', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Houses', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('Parliament', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('a', 'DT', 'O'),\n",
       "  ('rally', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Hyde', 'NNP', 'geo-nam'),\n",
       "  ('Park', 'NNP', 'geo-nam'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Police', 'NNS', 'O'),\n",
       "  ('put', 'VBD', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('number', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('marchers', 'NNS', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('10,000', 'CD', 'O'),\n",
       "  ('while', 'IN', 'O'),\n",
       "  ('organizers', 'NNS', 'O'),\n",
       "  ('claimed', 'VBD', 'O'),\n",
       "  ('it', 'PRP', 'O'),\n",
       "  ('was', 'VBD', 'O'),\n",
       "  ('100,000', 'CD', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('protest', 'NN', 'O'),\n",
       "  ('comes', 'VBZ', 'O'),\n",
       "  ('on', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('eve', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('annual', 'JJ', 'O'),\n",
       "  ('conference', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('Britain', 'NNP', 'geo-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('ruling', 'VBG', 'O'),\n",
       "  ('Labor', 'NNP', 'org-nam'),\n",
       "  ('Party', 'NNP', 'org-nam'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('southern', 'JJ', 'O'),\n",
       "  ('English', 'JJ', 'gpe-nam'),\n",
       "  ('seaside', 'NN', 'O'),\n",
       "  ('resort', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('Brighton', 'NNP', 'geo-nam'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('party', 'NN', 'O'),\n",
       "  ('is', 'VBZ', 'O'),\n",
       "  ('divided', 'VBN', 'O'),\n",
       "  ('over', 'IN', 'O'),\n",
       "  ('Britain', 'NNP', 'gpe-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('participation', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Iraq', 'NNP', 'geo-nam'),\n",
       "  ('conflict', 'NN', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('continued', 'JJ', 'O'),\n",
       "  ('deployment', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('8,500', 'CD', 'O'),\n",
       "  ('British', 'JJ', 'gpe-nam'),\n",
       "  ('troops', 'NNS', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('that', 'DT', 'O'),\n",
       "  ('country', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('London', 'NNP', 'geo-nam'),\n",
       "  ('march', 'NN', 'O'),\n",
       "  ('came', 'VBD', 'O'),\n",
       "  ('ahead', 'RB', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('anti-war', 'JJ', 'O'),\n",
       "  ('protests', 'NNS', 'O'),\n",
       "  ('today', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('other', 'JJ', 'O'),\n",
       "  ('cities', 'NNS', 'O'),\n",
       "  (',', ',', 'O'),\n",
       "  ('including', 'VBG', 'O'),\n",
       "  ('Rome', 'NNP', 'geo-nam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('Paris', 'NNP', 'geo-nam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('Madrid', 'NNP', 'geo-nam'),\n",
       "  ('.', '.', 'O')],\n",
       " [('The', 'DT', 'O'),\n",
       "  ('International', 'NNP', 'org-nam'),\n",
       "  ('Atomic', 'NNP', 'org-nam'),\n",
       "  ('Energy', 'NNP', 'org-nam'),\n",
       "  ('Agency', 'NNP', 'org-nam'),\n",
       "  ('is', 'VBZ', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('hold', 'VB', 'O'),\n",
       "  ('second', 'JJ', 'O'),\n",
       "  ('day', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('talks', 'NNS', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Vienna', 'NNP', 'geo-nam'),\n",
       "  ('Wednesday', 'NNP', 'tim-dow'),\n",
       "  ('on', 'IN', 'O'),\n",
       "  ('how', 'WRB', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('respond', 'VB', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('resumption', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('low-level', 'JJ', 'O'),\n",
       "  ('uranium', 'NN', 'O'),\n",
       "  ('conversion', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  ('this', 'DT', 'O'),\n",
       "  ('week', 'NN', 'O'),\n",
       "  ('restarted', 'VBD', 'O'),\n",
       "  ('parts', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('conversion', 'NN', 'O'),\n",
       "  ('process', 'NN', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('its', 'PRP$', 'O'),\n",
       "  ('Isfahan', 'NNP', 'geo-nam'),\n",
       "  ('nuclear', 'JJ', 'O'),\n",
       "  ('plant', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Iranian', 'JJ', 'gpe-nam'),\n",
       "  ('officials', 'NNS', 'O'),\n",
       "  ('say', 'VBP', 'O'),\n",
       "  ('they', 'PRP', 'O'),\n",
       "  ('expect', 'VBP', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('get', 'VB', 'O'),\n",
       "  ('access', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('sealed', 'JJ', 'O'),\n",
       "  ('sensitive', 'JJ', 'O'),\n",
       "  ('parts', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('plant', 'NN', 'O'),\n",
       "  ('Wednesday', 'NNP', 'tim-dow'),\n",
       "  (',', ',', 'O'),\n",
       "  ('after', 'IN', 'O'),\n",
       "  ('an', 'DT', 'O'),\n",
       "  ('IAEA', 'NNP', 'org-nam'),\n",
       "  ('surveillance', 'NN', 'O'),\n",
       "  ('system', 'NN', 'O'),\n",
       "  ('begins', 'VBZ', 'O'),\n",
       "  ('functioning', 'VBG', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('step', 'NN', 'O'),\n",
       "  ('will', 'MD', 'O'),\n",
       "  ('allow', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('facility', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('operate', 'VB', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('full', 'JJ', 'O'),\n",
       "  ('capacity', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('European', 'NNP', 'org-nam'),\n",
       "  ('Union', 'NNP', 'org-nam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('with', 'IN', 'O'),\n",
       "  ('U.S.', 'NNP', 'gpe-nam'),\n",
       "  ('backing', 'NN', 'O'),\n",
       "  (',', ',', 'O'),\n",
       "  ('has', 'VBZ', 'O'),\n",
       "  ('threatened', 'VBN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('refer', 'VB', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('U.N.', 'NNP', 'org-nam'),\n",
       "  ('Security', 'NNP', 'org-nam'),\n",
       "  ('Council', 'NNP', 'org-nam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('which', 'WDT', 'O'),\n",
       "  ('could', 'MD', 'O'),\n",
       "  ('impose', 'VB', 'O'),\n",
       "  ('sanctions', 'NNS', 'O'),\n",
       "  ('if', 'IN', 'O'),\n",
       "  ('it', 'PRP', 'O'),\n",
       "  ('finds', 'VBZ', 'O'),\n",
       "  ('Tehran', 'NNP', 'gpe-nam'),\n",
       "  ('has', 'VBZ', 'O'),\n",
       "  ('violated', 'VBN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Nuclear', 'NNP', 'art-nam'),\n",
       "  ('Non-Proliferation', 'NNP', 'art-nam'),\n",
       "  ('treaty', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('new', 'JJ', 'O'),\n",
       "  ('President', 'NNP', 'per-tit'),\n",
       "  ('Mahmoud', 'NNP', 'per-giv'),\n",
       "  ('Ahmadinejad', 'NNP', 'per-fam'),\n",
       "  ('said', 'VBD', 'O'),\n",
       "  ('Tuesday', 'NNP', 'tim-dow'),\n",
       "  ('that', 'IN', 'O'),\n",
       "  ('European', 'JJ', 'gpe-nam'),\n",
       "  ('incentives', 'NNS', 'O'),\n",
       "  ('aimed', 'VBN', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('persuading', 'VBG', 'O'),\n",
       "  ('Iran', 'NNP', 'gpe-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('end', 'VB', 'O'),\n",
       "  ('its', 'PRP$', 'O'),\n",
       "  ('nuclear', 'JJ', 'O'),\n",
       "  ('fuel', 'NN', 'O'),\n",
       "  ('program', 'NN', 'O'),\n",
       "  ('are', 'VBP', 'O'),\n",
       "  ('an', 'DT', 'O'),\n",
       "  ('insult', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Iranian', 'JJ', 'gpe-nam'),\n",
       "  ('nation', 'NN', 'O'),\n",
       "  ('.', '.', 'O')],\n",
       " [('Two', 'CD', 'O'),\n",
       "  ('Germans', 'NNS', 'gpe-nam'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('four', 'CD', 'O'),\n",
       "  ('Nigerian', 'JJ', 'gpe-nam'),\n",
       "  ('oil', 'NN', 'O'),\n",
       "  ('workers', 'NNS', 'O'),\n",
       "  ('were', 'VBD', 'O'),\n",
       "  ('kidnapped', 'VBN', 'O'),\n",
       "  ('by', 'IN', 'O'),\n",
       "  ('armed', 'JJ', 'O'),\n",
       "  ('militants', 'NNS', 'O'),\n",
       "  ('during', 'IN', 'O'),\n",
       "  ('a', 'DT', 'O'),\n",
       "  ('raid', 'NN', 'O'),\n",
       "  ('on', 'IN', 'O'),\n",
       "  ('a', 'DT', 'O'),\n",
       "  ('boat', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Nigeria', 'NNP', 'geo-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('southern', 'JJ', 'O'),\n",
       "  ('oil-rich', 'JJ', 'O'),\n",
       "  ('Delta', 'NNP', 'geo-nam'),\n",
       "  ('region', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('An', 'DT', 'O'),\n",
       "  ('official', 'NN', 'O'),\n",
       "  ('with', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('German', 'JJ', 'gpe-nam'),\n",
       "  ('firm', 'NN', 'O'),\n",
       "  ('Bilfinger', 'NNP', 'org-nam'),\n",
       "  ('Berger', 'NNP', 'org-nam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('Thomas', 'NNP', 'per-giv'),\n",
       "  ('Horbach', 'NNP', 'per-fam'),\n",
       "  (',', ',', 'O'),\n",
       "  ('said', 'VBD', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('gunmen', 'NNS', 'O'),\n",
       "  ('stopped', 'VBD', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('supply', 'NN', 'O'),\n",
       "  ('boat', 'NN', 'O'),\n",
       "  ('Wednesday', 'NNP', 'tim-dow'),\n",
       "  ('as', 'IN', 'O'),\n",
       "  ('it', 'PRP', 'O'),\n",
       "  ('sailed', 'VBD', 'O'),\n",
       "  ('from', 'IN', 'O'),\n",
       "  ('Delta', 'NNP', 'geo-nam'),\n",
       "  ('State', 'NNP', 'geo-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('Bayelsa', 'NNP', 'geo-nam'),\n",
       "  ('State', 'NNP', 'geo-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('inspect', 'VB', 'O'),\n",
       "  ('an', 'DT', 'O'),\n",
       "  ('offshore', 'JJ', 'O'),\n",
       "  ('oil', 'NN', 'O'),\n",
       "  ('field', 'NN', 'O'),\n",
       "  ('owned', 'VBN', 'O'),\n",
       "  ('by', 'IN', 'O'),\n",
       "  ('Royal-Dutch', 'NNP', 'org-nam'),\n",
       "  ('Shell', 'NNP', 'org-nam'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('German', 'JJ', 'gpe-nam'),\n",
       "  ('firm', 'NN', 'O'),\n",
       "  ('works', 'VBZ', 'O'),\n",
       "  ('as', 'IN', 'O'),\n",
       "  ('a', 'DT', 'O'),\n",
       "  ('sub-contractor', 'NN', 'O'),\n",
       "  ('for', 'IN', 'O'),\n",
       "  ('Shell', 'NNP', 'org-nam'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Militant', 'JJ', 'O'),\n",
       "  ('groups', 'NNS', 'O'),\n",
       "  ('frequently', 'RB', 'O'),\n",
       "  ('attack', 'VBP', 'O'),\n",
       "  ('oil', 'NN', 'O'),\n",
       "  ('operations', 'NNS', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Niger', 'NNP', 'geo-nam'),\n",
       "  ('Delta', 'NNP', 'geo-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('demand', 'VB', 'O'),\n",
       "  ('social', 'JJ', 'O'),\n",
       "  ('services', 'NNS', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('better', 'JJR', 'O'),\n",
       "  ('job', 'NN', 'O'),\n",
       "  ('opportunities', 'NNS', 'O'),\n",
       "  ('from', 'IN', 'O'),\n",
       "  ('multinational', 'JJ', 'O'),\n",
       "  ('companies', 'NNS', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Poor', 'JJ', 'O'),\n",
       "  ('residents', 'NNS', 'O'),\n",
       "  ('often', 'RB', 'O'),\n",
       "  ('complain', 'VBP', 'O'),\n",
       "  ('they', 'PRP', 'O'),\n",
       "  ('have', 'VBP', 'O'),\n",
       "  ('been', 'VBN', 'O'),\n",
       "  ('cheated', 'VBN', 'O'),\n",
       "  ('out', 'IN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('huge', 'JJ', 'O'),\n",
       "  ('riches', 'NNS', 'O'),\n",
       "  ('extracted', 'VBN', 'O'),\n",
       "  ('from', 'IN', 'O'),\n",
       "  ('their', 'PRP$', 'O'),\n",
       "  ('tribal', 'JJ', 'O'),\n",
       "  ('lands', 'NNS', 'O'),\n",
       "  ('-', ':', 'O'),\n",
       "  ('where', 'WRB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('bulk', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('Nigeria', 'NNP', 'gpe-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('2.3', 'CD', 'O'),\n",
       "  ('million', 'CD', 'O'),\n",
       "  ('barrels', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('petroleum', 'NN', 'O'),\n",
       "  ('are', 'VBP', 'O'),\n",
       "  ('pumped', 'VBN', 'O'),\n",
       "  ('daily', 'RB', 'O'),\n",
       "  ('.', '.', 'O')],\n",
       " [('Suspected', 'JJ', 'O'),\n",
       "  ('Islamist', 'JJ', 'O'),\n",
       "  ('rebels', 'NNS', 'O'),\n",
       "  ('have', 'VBP', 'O'),\n",
       "  ('fired', 'VBN', 'O'),\n",
       "  ('mortar', 'NN', 'O'),\n",
       "  ('shells', 'NNS', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('palace', 'NN', 'O'),\n",
       "  ('used', 'VBN', 'O'),\n",
       "  ('by', 'IN', 'O'),\n",
       "  ('Somalia', 'NNP', 'geo-nam'),\n",
       "  (\"'s\", 'POS', 'O'),\n",
       "  ('interim', 'JJ', 'O'),\n",
       "  ('President', 'NNP', 'per-tit'),\n",
       "  ('Abdullahi', 'NNP', 'per-giv'),\n",
       "  ('Yusuf', 'NNP', 'per-nam'),\n",
       "  ('Ahmad', 'NNP', 'per-fam'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('It', 'PRP', 'O'),\n",
       "  ('was', 'VBD', 'O'),\n",
       "  ('not', 'RB', 'O'),\n",
       "  ('immediately', 'RB', 'O'),\n",
       "  ('clear', 'JJ', 'O'),\n",
       "  ('if', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('president', 'NN', 'O'),\n",
       "  ('was', 'VBD', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('palace', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Mogadishu', 'NNP', 'geo-nam'),\n",
       "  ('when', 'WRB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('attack', 'NN', 'O'),\n",
       "  ('occurred', 'VBD', 'O'),\n",
       "  ('or', 'CC', 'O'),\n",
       "  ('if', 'IN', 'O'),\n",
       "  ('anyone', 'DT', 'O'),\n",
       "  ('was', 'VBD', 'O'),\n",
       "  ('hurt', 'VBN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Local', 'JJ', 'O'),\n",
       "  ('news', 'NN', 'O'),\n",
       "  ('reports', 'NNS', 'O'),\n",
       "  ('said', 'VBD', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('least', 'JJS', 'O'),\n",
       "  ('five', 'CD', 'O'),\n",
       "  ('mortar', 'NN', 'O'),\n",
       "  ('shells', 'NNS', 'O'),\n",
       "  ('hit', 'VBD', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('palace', 'NN', 'O'),\n",
       "  ('compound', 'NN', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('other', 'JJ', 'O'),\n",
       "  ('mortars', 'NNS', 'O'),\n",
       "  ('were', 'VBD', 'O'),\n",
       "  ('fired', 'VBN', 'O'),\n",
       "  ('elsewhere', 'RB', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Mogadishu', 'NNP', 'geo-nam'),\n",
       "  ('Wednesday', 'NNP', 'tim-dow'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('The', 'DT', 'O'),\n",
       "  ('attacks', 'NNS', 'O'),\n",
       "  ('occurred', 'VBD', 'O'),\n",
       "  ('after', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('government', 'NN', 'O'),\n",
       "  ('said', 'VBD', 'O'),\n",
       "  ('it', 'PRP', 'O'),\n",
       "  ('will', 'MD', 'O'),\n",
       "  ('go', 'VB', 'O'),\n",
       "  ('ahead', 'RB', 'O'),\n",
       "  ('with', 'IN', 'O'),\n",
       "  ('a', 'DT', 'O'),\n",
       "  ('reconciliation', 'NN', 'O'),\n",
       "  ('conference', 'NN', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('which', 'WDT', 'O'),\n",
       "  ('more', 'JJR', 'O'),\n",
       "  ('than', 'IN', 'O'),\n",
       "  ('1,300', 'CD', 'O'),\n",
       "  ('Somali', 'JJ', 'gpe-nam'),\n",
       "  ('elders', 'NNS', 'O'),\n",
       "  (',', ',', 'O'),\n",
       "  ('warlords', 'NNS', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('politicians', 'NNS', 'O'),\n",
       "  ('are', 'VBP', 'O'),\n",
       "  ('invited', 'VBN', 'O'),\n",
       "  ('.', '.', 'O')],\n",
       " [('Iraqi', 'JJ', 'gpe-nam'),\n",
       "  ('military', 'JJ', 'O'),\n",
       "  ('officials', 'NNS', 'O'),\n",
       "  ('say', 'VBP', 'O'),\n",
       "  ('tanks', 'NNS', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('troops', 'NNS', 'O'),\n",
       "  ('have', 'VBP', 'O'),\n",
       "  ('arrived', 'VBN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('northern', 'JJ', 'O'),\n",
       "  ('city', 'NN', 'O'),\n",
       "  ('Mosul', 'NNP', 'geo-nam'),\n",
       "  ('for', 'IN', 'O'),\n",
       "  ('a', 'DT', 'O'),\n",
       "  ('new', 'JJ', 'O'),\n",
       "  ('offensive', 'NN', 'O'),\n",
       "  ('against', 'IN', 'O'),\n",
       "  ('al', 'NNP', 'org-nam'),\n",
       "  ('Qaida', 'NNP', 'org-nam'),\n",
       "  ('in', 'IN', 'org-nam'),\n",
       "  ('Iraq', 'NNP', 'org-nam'),\n",
       "  ('fighters', 'NNS', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Officials', 'NNS', 'O'),\n",
       "  ('will', 'MD', 'O'),\n",
       "  ('not', 'RB', 'O'),\n",
       "  ('say', 'VB', 'O'),\n",
       "  ('how', 'WRB', 'O'),\n",
       "  ('many', 'JJ', 'O'),\n",
       "  ('troops', 'NNS', 'O'),\n",
       "  ('have', 'VBP', 'O'),\n",
       "  ('arrived', 'VBN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('Sunni', 'NNP', 'geo-nam'),\n",
       "  ('Arab', 'NNP', 'geo-nam'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('Kurdish', 'NNP', 'geo-nam'),\n",
       "  ('city', 'NN', 'O'),\n",
       "  (',', ',', 'O'),\n",
       "  ('where', 'WRB', 'O'),\n",
       "  ('bombings', 'NNS', 'O'),\n",
       "  ('last', 'JJ', 'O'),\n",
       "  ('week', 'NN', 'O'),\n",
       "  ('killed', 'VBD', 'O'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('least', 'JJS', 'O'),\n",
       "  ('34', 'CD', 'O'),\n",
       "  ('people', 'NNS', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('wounded', 'VBD', 'O'),\n",
       "  ('more', 'JJR', 'O'),\n",
       "  ('than', 'IN', 'O'),\n",
       "  ('200', 'CD', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('U.S.', 'NNP', 'gpe-nam'),\n",
       "  ('commanders', 'NNS', 'O'),\n",
       "  ('have', 'VBP', 'O'),\n",
       "  ('not', 'RB', 'O'),\n",
       "  ('explained', 'VBN', 'O'),\n",
       "  ('how', 'WRB', 'O'),\n",
       "  ('American', 'JJ', 'gpe-nam'),\n",
       "  ('forces', 'NNS', 'O'),\n",
       "  ('will', 'MD', 'O'),\n",
       "  ('participate', 'VB', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('offensive', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Officials', 'NNS', 'O'),\n",
       "  ('say', 'VBP', 'O'),\n",
       "  ('al', 'NNP', 'org-nam'),\n",
       "  ('Qaida', 'NNP', 'org-nam'),\n",
       "  ('in', 'IN', 'org-nam'),\n",
       "  ('Iraq', 'NNP', 'org-nam'),\n",
       "  ('fighters', 'NNS', 'O'),\n",
       "  ('have', 'VBP', 'O'),\n",
       "  ('fled', 'VBN', 'O'),\n",
       "  ('successful', 'JJ', 'O'),\n",
       "  ('campaigns', 'NNS', 'O'),\n",
       "  ('against', 'IN', 'O'),\n",
       "  ('them', 'PRP', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Anbar', 'NNP', 'geo-nam'),\n",
       "  ('province', 'NN', 'O'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('Baghdad', 'NNP', 'geo-nam'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('other', 'JJ', 'O'),\n",
       "  ('northern', 'JJ', 'O'),\n",
       "  ('provinces', 'NNS', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('Mosul', 'NNP', 'geo-nam'),\n",
       "  ('is', 'VBZ', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('largest', 'JJS', 'O'),\n",
       "  ('city', 'NN', 'O'),\n",
       "  ('north', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('Baghdad', 'NNP', 'geo-nam'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('has', 'VBZ', 'O'),\n",
       "  ('long', 'RB', 'O'),\n",
       "  ('been', 'VBN', 'O'),\n",
       "  ('a', 'DT', 'O'),\n",
       "  ('stronghold', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('Sunni', 'NNP', 'org-nam'),\n",
       "  ('militant', 'JJ', 'O'),\n",
       "  ('fighters', 'NNS', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('In', 'IN', 'O'),\n",
       "  ('other', 'JJ', 'O'),\n",
       "  ('violence', 'NN', 'O'),\n",
       "  (',', ',', 'O'),\n",
       "  ('U.S.', 'NNP', 'gpe-nam'),\n",
       "  ('officials', 'NNS', 'O'),\n",
       "  ('said', 'VBD', 'O'),\n",
       "  ('one', 'CD', 'O'),\n",
       "  ('American', 'JJ', 'gpe-nam'),\n",
       "  ('soldier', 'NN', 'O'),\n",
       "  ('was', 'VBD', 'O'),\n",
       "  ('killed', 'VBN', 'O'),\n",
       "  ('while', 'IN', 'O'),\n",
       "  ('on', 'IN', 'O'),\n",
       "  ('patrol', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Baghdad', 'NNP', 'geo-nam'),\n",
       "  ('Sunday', 'NNP', 'tim-dow'),\n",
       "  ('.', '.', 'O')]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pos_tag_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8APgvUyskaf"
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in word_pos_tag_sentences]\n",
    "y = [sent2labels(s) for s in word_pos_tag_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.metrics import recall_score\n",
    ">>> scoring = ['precision_macro', 'recall_macro']\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "Pickling array (shape=(7333,), dtype=int32).\n",
      "Pickling array (shape=(1834,), dtype=int32).\n",
      "Pickling array (shape=(7333,), dtype=int32).\n",
      "Pickling array (shape=(1834,), dtype=int32).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling array (shape=(7334,), dtype=int32).\n",
      "Pickling array (shape=(1833,), dtype=int32).\n",
      "Pickling array (shape=(7334,), dtype=int32).\n",
      "Pickling array (shape=(1833,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  9.0min\n",
      "Pickling array (shape=(7334,), dtype=int32).\n",
      "Pickling array (shape=(1833,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 10.8min remaining: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed: 13.7min remaining:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 16.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 16.9min finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(crf, X, y, cv=5, n_jobs=-1, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97032539, 0.97388456, 0.97253039, 0.97323582, 0.97233593])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)\n",
    "crf.fit(X_train, y_train)\n",
    "Out[15]:\n",
    "CRF(algorithm='lbfgs', all_possible_states=None,\n",
    "  all_possible_transitions=False, averaging=None, c=None, c1=0.1, c2=0.1,\n",
    "  calibration_candidates=None, calibration_eta=None,\n",
    "  calibration_max_trials=None, calibration_rate=None,\n",
    "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
    "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
    "  max_linesearch=None, min_freq=None, model_filename=None,\n",
    "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
    "  variance=None, verbose=False)\n",
    "In [16]:\n",
    "#Predicting on the test set.\n",
    "y_pred = crf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "HW1. NER.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
