{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVRaU_zG-PaI"
   },
   "source": [
    "# About notebook\n",
    "Dataset\n",
    "*\tGroningen Meaning Bank (version 2.2.0)\n",
    "*\tTask: named entity recognition\n",
    "*\tTarget – named entity tags (BIO + entity type)\n",
    "*\tInput data: \n",
    "  * Use “en.met” files to extract the subcorpus\n",
    "  corpus = 'Voice of America' (for honogeneity of the input data set)\n",
    "  * Use \"en.tags\" files for the main input data:\n",
    "      *\traw tokens + may use the lemmas and the POS-tags \n",
    "  (i.e. take the “golden” POS-tagging);\n",
    "      *\twhich means:\n",
    "        *\tfirst three columns for input: ['word', 'pos', 'lemma']\n",
    "        *\tthe fourth column for target variable (‘ne_tags’)\n",
    "        (BIO annotation + the named-entity type in one tag)  \n",
    "\n",
    "# Tasks\n",
    "1.\tThe most trivial model = supervised HMM:\n",
    "  *\tTake hmmlearn (former sklearn), modify MultinomialHMM (I.e. inherit a new class from _BaseHMM making it a modified copy of the latter) to allow for supervised HMM training. The states of the HMM model = the NE tags.\n",
    "  *\tNOTE: may use NaiveBayes to learn emission probabilities in a supervized manner.\n",
    "  *\tOr implement from scratch (with Viterbi for prediction).\n",
    "  *\tNOTE: use tuples of features for X (not just the word, but additional info).\n",
    "  *\tNOTE: use smoothing for state transitions.\n",
    "2.\tCRF\n",
    "  *\tModify the input features;\n",
    "  *\tUse CRFSuite.\n",
    "3.\tBi-LSTM:\n",
    "  *\tUse keras or tensorflow;\n",
    "  *\thttps://github.com/hse-aml/natural-language-processing/blob/master/week2/week2-NER.ipynb\n",
    "  *\tA plus for incorporating CNN-layers;\n",
    "\n",
    "# Metrics\n",
    "* normalized confusion matrices, precision, recall, F-score \n",
    "(macro- and micro-) \n",
    "* (token level, entity level, partial matching (i.e. boundary-detection problem), binary).  \n",
    "NOTE: taking into account vocabulary transfer is a plus.\n",
    "\n",
    "# Evaluation Criteria\n",
    "Scoring (14.5 max):  \n",
    "*\tDataset overview – 0.5\n",
    "  *\ttext lengths, vocabulary size, frequencies of patterns (<UNK-type-i>) \n",
    "  *\tstats over the target tags\n",
    "*\tFeature engineering – 2 (1+1)\n",
    "  *\tgrammatical words = closed set (~ stop words)\n",
    "  *\tStemming + POS\n",
    "  *\tWord shape\n",
    "  *\tAd hoc features ( +1)  \n",
    "*\tWord patterns -> encode types of unknown words +0.5\n",
    "*\tSmoothing in HMM – 0.5 \n",
    "  *\tIn HMM: for state transitions.\n",
    "*\tIncorporating tupled features in HMM (on top of tokens) – 1\n",
    "*\tThe correct HMM implementation – 1\n",
    "*\tMore fine-grained feature engineering for the Neural Network + 0.5\n",
    "  *\tDifferentiate between POS-relevancy for the word and the context, etc.\n",
    "  *\tSentence-level features (may use “golden” sentence-splitting)\n",
    "*\tEvaluation (on all levels) – 1\n",
    "*\tConclusion on HMM deficiency (as a model) – 1\n",
    "*\tCRF: 1 point for use and evaluation, + 0.5 points for comparison and conclusions;\n",
    "*\tNN:\n",
    "  *\tMain network: 4\n",
    "  *\tCNN layers: +2  \n",
    "\n",
    "Libraries: hmmlearn, crfsuite, tensorflow, keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "30D0Scxk4kn3"
   },
   "source": [
    "# Libs import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "hidden": true,
    "id": "ZnXUdrxQ3TAN",
    "outputId": "910fb799-41ed-4c9b-98ca-55a44b62566f"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "import os\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_validate, ShuffleSplit\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.metrics import recall_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "VD2z8D2V7Dod"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "auzLnrdK51Rg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data found: ['p00', 'p01', 'p02', 'p03', 'p04', 'p05', 'p06', 'p07', 'p08', 'p09', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'p66', 'p67', 'p68', 'p69', 'p70', 'p71', 'p72', 'p73', 'p74', 'p75', 'p76', 'p77', 'p78', 'p79', 'p80', 'p81', 'p82', 'p83', 'p84', 'p85', 'p86', 'p87', 'p88', 'p89', 'p90', 'p91', 'p92', 'p93', 'p94', 'p95', 'p96', 'p97', 'p98', 'p99']\n"
     ]
    }
   ],
   "source": [
    "data_path = 'D:\\Data\\gmb-2.2.0\\data'\n",
    "print('data found:', os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subcorpus = 'Voice of America'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "tgwhO8ngi-A4"
   },
   "source": [
    "Parsing data from \"Voice of America\" subcorpus. According to the instructions we take first four columns and additional column to separate data on texts, sentences or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "-UBeZ_eui-A5",
    "outputId": "5308f75a-eaa2-42e3-ecae-4f6aa512ec36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [06:26<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "voa_data = pd.DataFrame(columns=['word', 'pos', 'lemma', 'ne_tags', 'text_id'])\n",
    "\n",
    "os.chdir(data_path)\n",
    "part_paths = os.listdir()\n",
    "\n",
    "for part_path in tqdm(part_paths, total=len(part_paths)):\n",
    "    os.chdir(part_path)\n",
    "    document_paths = os.listdir()\n",
    "    for document_path in document_paths:\n",
    "        os.chdir(document_path)\n",
    "        f = codecs.open(\"en.met\",'r', \"utf_8_sig\")\n",
    "        file_met = f.read()\n",
    "        if('subcorpus: {}'.format(subcorpus) in file_met):\n",
    "            subcorpus = pd.read_csv('en.tags', sep='\\t',\n",
    "                                    header=None, \n",
    "                                    names=['word', 'pos', 'lemma', 'ne_tags'],\n",
    "                                    usecols=[0,1,2,3],\n",
    "                                    error_bad_lines=False)\n",
    "            subcorpus['text_id'] = str(part_path)+'_'+str(document_path)\n",
    "            main_input_data = main_input_data.append(subcorpus, ignore_index=True)\n",
    "        f.close()\n",
    "        os.chdir('..')   \n",
    "    os.chdir('..')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "UX1ViqnKi-A-",
    "outputId": "c391cb23-3288-4f4f-db22-f5afc86f4fa2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage:  46.969688415527344  MB\n"
     ]
    }
   ],
   "source": [
    "print(\"memory usage: \",voa_data.memory_usage().sum()/1024/1024, \" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrator</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos         lemma ne_tags    text_id\n",
       "0      Thousands  NNS      thousand       O  p00_d0018\n",
       "1             of   IN            of       O  p00_d0018\n",
       "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
       "3           have  VBP          have       O  p00_d0018\n",
       "4        marched  VBN         march       O  p00_d0018"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "kUrX7pvxi-BB",
    "outputId": "f42abe57-ad1b-4a64-a7b3-6bf93acb5155",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1231279, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "8vWQ-w4Qi-BF"
   },
   "source": [
    "Number of tokens coincided with the declared in README file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "voa_data.to_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "15GVrJYa717o"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>thousand</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrator</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos         lemma ne_tags    text_id\n",
       "0      Thousands  NNS      thousand       O  p00_d0018\n",
       "1             of   IN            of       O  p00_d0018\n",
       "2  demonstrators  NNS  demonstrator       O  p00_d0018\n",
       "3           have  VBP          have       O  p00_d0018\n",
       "4        marched  VBN         march       O  p00_d0018"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data = pd.read_csv('D:\\Data\\gmb-2.2.0\\{}.csv'.format(subcorpus))\n",
    "voa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1Y2cJhli-BG",
    "outputId": "31c7858e-e9f0-45de-fd83-9c7ff746db38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average text length:  134.31646121959201\n"
     ]
    }
   ],
   "source": [
    "def average_text_length(text_id):\n",
    "    doc_lengths = list(dict(Counter(text_id)).values())\n",
    "    sum = 0\n",
    "    for length in doc_lengths:\n",
    "        sum += length\n",
    "    return sum/len(doc_lengths)\n",
    "\n",
    "print(\"average text length: \", average_text_length(voa_data['text_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ne_tags</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "      <td>1231279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>35154</td>\n",
       "      <td>48</td>\n",
       "      <td>27209</td>\n",
       "      <td>25</td>\n",
       "      <td>9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>p00_d0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>61398</td>\n",
       "      <td>168817</td>\n",
       "      <td>74941</td>\n",
       "      <td>1032479</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word      pos    lemma  ne_tags    text_id\n",
       "count   1231279  1231279  1231279  1231279    1231279\n",
       "unique    35154       48    27209       25       9167\n",
       "top         the       NN      the        O  p00_d0090\n",
       "freq      61398   168817    74941  1032479        388"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(df):\n",
    "    \"\"\"func to get the sentences in this format:\n",
    "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_n, Tag_n)]\"\"\"\n",
    "    \n",
    "    agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                       s[\"pos\"].values.tolist(),\n",
    "                                                       s[\"ne_tags\"].values.tolist())]\n",
    "    grouped = df.groupby(\"text_id\").apply(agg_func)\n",
    "    sentences = [s for s in grouped]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_pos_tag_sentences = get_sentences(voa_data)\n",
    "word_pos_tag_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:], #replace with BPE\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def get_sent_labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9167"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_pos_tag_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in word_pos_tag_sentences]\n",
    "y = [get_sent_labels(s) for s in word_pos_tag_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8APgvUyskaf"
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision_macro', 'recall_macro']\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf=CRF(algorithm='lbfgs',\n",
    "         c1=0.1,\n",
    "         c2=0.1,\n",
    "         max_iterations=100,\n",
    "         all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "Pickling array (shape=(5866,), dtype=int32).\n",
      "Pickling array (shape=(1467,), dtype=int32).\n",
      "Pickling array (shape=(5866,), dtype=int32).\n",
      "Pickling array (shape=(1467,), dtype=int32).\n",
      "Pickling array (shape=(5866,), dtype=int32).\n",
      "Pickling array (shape=(1467,), dtype=int32).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling array (shape=(5867,), dtype=int32).\n",
      "Pickling array (shape=(1466,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  6.4min remaining:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  6.4min remaining:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.4min remaining:    0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 556, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 599, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 629, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 97, in __call__\n    **self._kwargs)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 1569, in precision_score\n    sample_weight=sample_weight)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 1415, in precision_recall_fscore_support\n    pos_label)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 1239, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 72, in _check_targets\n    type_true = type_of_target(y_true)\n  File \"D:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 260, in type_of_target\n    raise ValueError('You appear to be using a legacy multi-label data'\nValueError: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-f0b2af3462b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m scores = cross_validate(crf, X_train, y_train, cv=5, n_jobs=-1, \n\u001b[1;32m----> 2\u001b[1;33m                          scoring=scoring, verbose=100)\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 232\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\IDE_and_for_programming\\Anaconda\\envs\\tf-gpu\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "scores = cross_validate(crf, X_train, y_train, cv=5, n_jobs=-1, \n",
    "                         scoring=scoring, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97032539, 0.97388456, 0.97253039, 0.97323582, 0.97233593])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "HW1. NER.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
